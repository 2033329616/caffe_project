I1130 10:22:07.695163  3078 caffe.cpp:218] Using GPUs 0
I1130 10:22:07.973076  3078 caffe.cpp:223] GPU 0: GeForce GTX 1050
I1130 10:22:08.559944  3078 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.001
display: 200
max_iter: 60000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 10000
snapshot_prefix: "/home/david/caffe-master/cifar10/model/cifar10_full"
solver_mode: GPU
device_id: 0
net: "/home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1130 10:22:08.560247  3078 solver.cpp:87] Creating training net from net file: /home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt
I1130 10:22:08.582293  3078 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1130 10:22:08.582365  3078 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1130 10:22:08.582686  3078 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/david/caffe-master/cifar10/data/lmdb/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1130 10:22:08.582856  3078 layer_factory.hpp:77] Creating layer cifar
I1130 10:22:08.583109  3078 db_lmdb.cpp:35] Opened lmdb /home/david/caffe-master/cifar10/data/lmdb/cifar10_train_lmdb
I1130 10:22:08.583180  3078 net.cpp:84] Creating Layer cifar
I1130 10:22:08.583230  3078 net.cpp:380] cifar -> data
I1130 10:22:08.583331  3078 net.cpp:380] cifar -> label
I1130 10:22:08.583369  3078 data_transformer.cpp:25] Loading mean file from: /home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto
I1130 10:22:08.587954  3078 data_layer.cpp:45] output data size: 100,3,32,32
I1130 10:22:08.601879  3078 net.cpp:122] Setting up cifar
I1130 10:22:08.601928  3078 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1130 10:22:08.601943  3078 net.cpp:129] Top shape: 100 (100)
I1130 10:22:08.601949  3078 net.cpp:137] Memory required for data: 1229200
I1130 10:22:08.601968  3078 layer_factory.hpp:77] Creating layer conv1
I1130 10:22:08.602011  3078 net.cpp:84] Creating Layer conv1
I1130 10:22:08.602025  3078 net.cpp:406] conv1 <- data
I1130 10:22:08.602054  3078 net.cpp:380] conv1 -> conv1
I1130 10:22:13.508635  3078 net.cpp:122] Setting up conv1
I1130 10:22:13.508697  3078 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1130 10:22:13.508708  3078 net.cpp:137] Memory required for data: 14336400
I1130 10:22:13.508759  3078 layer_factory.hpp:77] Creating layer pool1
I1130 10:22:13.508785  3078 net.cpp:84] Creating Layer pool1
I1130 10:22:13.508795  3078 net.cpp:406] pool1 <- conv1
I1130 10:22:13.508810  3078 net.cpp:380] pool1 -> pool1
I1130 10:22:13.521636  3078 net.cpp:122] Setting up pool1
I1130 10:22:13.521708  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.521725  3078 net.cpp:137] Memory required for data: 17613200
I1130 10:22:13.521744  3078 layer_factory.hpp:77] Creating layer relu1
I1130 10:22:13.521767  3078 net.cpp:84] Creating Layer relu1
I1130 10:22:13.521780  3078 net.cpp:406] relu1 <- pool1
I1130 10:22:13.521797  3078 net.cpp:367] relu1 -> pool1 (in-place)
I1130 10:22:13.522563  3078 net.cpp:122] Setting up relu1
I1130 10:22:13.522594  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.522603  3078 net.cpp:137] Memory required for data: 20890000
I1130 10:22:13.522610  3078 layer_factory.hpp:77] Creating layer norm1
I1130 10:22:13.522636  3078 net.cpp:84] Creating Layer norm1
I1130 10:22:13.522645  3078 net.cpp:406] norm1 <- pool1
I1130 10:22:13.522660  3078 net.cpp:380] norm1 -> norm1
I1130 10:22:13.525238  3078 net.cpp:122] Setting up norm1
I1130 10:22:13.525305  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.525323  3078 net.cpp:137] Memory required for data: 24166800
I1130 10:22:13.525343  3078 layer_factory.hpp:77] Creating layer conv2
I1130 10:22:13.525394  3078 net.cpp:84] Creating Layer conv2
I1130 10:22:13.525409  3078 net.cpp:406] conv2 <- norm1
I1130 10:22:13.525440  3078 net.cpp:380] conv2 -> conv2
I1130 10:22:13.532775  3078 net.cpp:122] Setting up conv2
I1130 10:22:13.532825  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.532835  3078 net.cpp:137] Memory required for data: 27443600
I1130 10:22:13.532862  3078 layer_factory.hpp:77] Creating layer relu2
I1130 10:22:13.532884  3078 net.cpp:84] Creating Layer relu2
I1130 10:22:13.532894  3078 net.cpp:406] relu2 <- conv2
I1130 10:22:13.532910  3078 net.cpp:367] relu2 -> conv2 (in-place)
I1130 10:22:13.534214  3078 net.cpp:122] Setting up relu2
I1130 10:22:13.534247  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.534256  3078 net.cpp:137] Memory required for data: 30720400
I1130 10:22:13.534265  3078 layer_factory.hpp:77] Creating layer pool2
I1130 10:22:13.534281  3078 net.cpp:84] Creating Layer pool2
I1130 10:22:13.534289  3078 net.cpp:406] pool2 <- conv2
I1130 10:22:13.534306  3078 net.cpp:380] pool2 -> pool2
I1130 10:22:13.534984  3078 net.cpp:122] Setting up pool2
I1130 10:22:13.535012  3078 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 10:22:13.535020  3078 net.cpp:137] Memory required for data: 31539600
I1130 10:22:13.535028  3078 layer_factory.hpp:77] Creating layer norm2
I1130 10:22:13.535050  3078 net.cpp:84] Creating Layer norm2
I1130 10:22:13.535059  3078 net.cpp:406] norm2 <- pool2
I1130 10:22:13.535073  3078 net.cpp:380] norm2 -> norm2
I1130 10:22:13.536098  3078 net.cpp:122] Setting up norm2
I1130 10:22:13.536134  3078 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 10:22:13.536180  3078 net.cpp:137] Memory required for data: 32358800
I1130 10:22:13.536190  3078 layer_factory.hpp:77] Creating layer conv3
I1130 10:22:13.536219  3078 net.cpp:84] Creating Layer conv3
I1130 10:22:13.536229  3078 net.cpp:406] conv3 <- norm2
I1130 10:22:13.536244  3078 net.cpp:380] conv3 -> conv3
I1130 10:22:13.541504  3078 net.cpp:122] Setting up conv3
I1130 10:22:13.541553  3078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 10:22:13.541563  3078 net.cpp:137] Memory required for data: 33997200
I1130 10:22:13.541589  3078 layer_factory.hpp:77] Creating layer relu3
I1130 10:22:13.541623  3078 net.cpp:84] Creating Layer relu3
I1130 10:22:13.541633  3078 net.cpp:406] relu3 <- conv3
I1130 10:22:13.541654  3078 net.cpp:367] relu3 -> conv3 (in-place)
I1130 10:22:13.543658  3078 net.cpp:122] Setting up relu3
I1130 10:22:13.543709  3078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 10:22:13.543720  3078 net.cpp:137] Memory required for data: 35635600
I1130 10:22:13.543730  3078 layer_factory.hpp:77] Creating layer pool3
I1130 10:22:13.543751  3078 net.cpp:84] Creating Layer pool3
I1130 10:22:13.543761  3078 net.cpp:406] pool3 <- conv3
I1130 10:22:13.543781  3078 net.cpp:380] pool3 -> pool3
I1130 10:22:13.544481  3078 net.cpp:122] Setting up pool3
I1130 10:22:13.544508  3078 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1130 10:22:13.544517  3078 net.cpp:137] Memory required for data: 36045200
I1130 10:22:13.544525  3078 layer_factory.hpp:77] Creating layer ip1
I1130 10:22:13.544545  3078 net.cpp:84] Creating Layer ip1
I1130 10:22:13.544553  3078 net.cpp:406] ip1 <- pool3
I1130 10:22:13.544574  3078 net.cpp:380] ip1 -> ip1
I1130 10:22:13.547327  3078 net.cpp:122] Setting up ip1
I1130 10:22:13.547361  3078 net.cpp:129] Top shape: 100 10 (1000)
I1130 10:22:13.547369  3078 net.cpp:137] Memory required for data: 36049200
I1130 10:22:13.547387  3078 layer_factory.hpp:77] Creating layer loss
I1130 10:22:13.547420  3078 net.cpp:84] Creating Layer loss
I1130 10:22:13.547430  3078 net.cpp:406] loss <- ip1
I1130 10:22:13.547442  3078 net.cpp:406] loss <- label
I1130 10:22:13.547461  3078 net.cpp:380] loss -> loss
I1130 10:22:13.547495  3078 layer_factory.hpp:77] Creating layer loss
I1130 10:22:13.548434  3078 net.cpp:122] Setting up loss
I1130 10:22:13.548461  3078 net.cpp:129] Top shape: (1)
I1130 10:22:13.548470  3078 net.cpp:132]     with loss weight 1
I1130 10:22:13.548511  3078 net.cpp:137] Memory required for data: 36049204
I1130 10:22:13.548521  3078 net.cpp:198] loss needs backward computation.
I1130 10:22:13.548537  3078 net.cpp:198] ip1 needs backward computation.
I1130 10:22:13.548547  3078 net.cpp:198] pool3 needs backward computation.
I1130 10:22:13.548554  3078 net.cpp:198] relu3 needs backward computation.
I1130 10:22:13.548563  3078 net.cpp:198] conv3 needs backward computation.
I1130 10:22:13.548570  3078 net.cpp:198] norm2 needs backward computation.
I1130 10:22:13.548579  3078 net.cpp:198] pool2 needs backward computation.
I1130 10:22:13.548588  3078 net.cpp:198] relu2 needs backward computation.
I1130 10:22:13.548594  3078 net.cpp:198] conv2 needs backward computation.
I1130 10:22:13.548602  3078 net.cpp:198] norm1 needs backward computation.
I1130 10:22:13.548610  3078 net.cpp:198] relu1 needs backward computation.
I1130 10:22:13.548619  3078 net.cpp:198] pool1 needs backward computation.
I1130 10:22:13.548629  3078 net.cpp:198] conv1 needs backward computation.
I1130 10:22:13.548640  3078 net.cpp:200] cifar does not need backward computation.
I1130 10:22:13.548653  3078 net.cpp:242] This network produces output loss
I1130 10:22:13.548683  3078 net.cpp:255] Network initialization done.
I1130 10:22:13.549162  3078 solver.cpp:172] Creating test net (#0) specified by net file: /home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt
I1130 10:22:13.549229  3078 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1130 10:22:13.549525  3078 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/david/caffe-master/cifar10/data/lmdb/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1130 10:22:13.549758  3078 layer_factory.hpp:77] Creating layer cifar
I1130 10:22:13.549892  3078 db_lmdb.cpp:35] Opened lmdb /home/david/caffe-master/cifar10/data/lmdb/cifar10_test_lmdb
I1130 10:22:13.549932  3078 net.cpp:84] Creating Layer cifar
I1130 10:22:13.549949  3078 net.cpp:380] cifar -> data
I1130 10:22:13.549970  3078 net.cpp:380] cifar -> label
I1130 10:22:13.549988  3078 data_transformer.cpp:25] Loading mean file from: /home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto
I1130 10:22:13.550454  3078 data_layer.cpp:45] output data size: 100,3,32,32
I1130 10:22:13.559228  3078 net.cpp:122] Setting up cifar
I1130 10:22:13.559267  3078 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1130 10:22:13.559278  3078 net.cpp:129] Top shape: 100 (100)
I1130 10:22:13.559285  3078 net.cpp:137] Memory required for data: 1229200
I1130 10:22:13.559294  3078 layer_factory.hpp:77] Creating layer label_cifar_1_split
I1130 10:22:13.559321  3078 net.cpp:84] Creating Layer label_cifar_1_split
I1130 10:22:13.559331  3078 net.cpp:406] label_cifar_1_split <- label
I1130 10:22:13.559346  3078 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1130 10:22:13.559362  3078 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1130 10:22:13.559584  3078 net.cpp:122] Setting up label_cifar_1_split
I1130 10:22:13.559608  3078 net.cpp:129] Top shape: 100 (100)
I1130 10:22:13.559614  3078 net.cpp:129] Top shape: 100 (100)
I1130 10:22:13.559618  3078 net.cpp:137] Memory required for data: 1230000
I1130 10:22:13.559623  3078 layer_factory.hpp:77] Creating layer conv1
I1130 10:22:13.559643  3078 net.cpp:84] Creating Layer conv1
I1130 10:22:13.559648  3078 net.cpp:406] conv1 <- data
I1130 10:22:13.559658  3078 net.cpp:380] conv1 -> conv1
I1130 10:22:13.561890  3078 net.cpp:122] Setting up conv1
I1130 10:22:13.561911  3078 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1130 10:22:13.561916  3078 net.cpp:137] Memory required for data: 14337200
I1130 10:22:13.561929  3078 layer_factory.hpp:77] Creating layer pool1
I1130 10:22:13.561939  3078 net.cpp:84] Creating Layer pool1
I1130 10:22:13.561944  3078 net.cpp:406] pool1 <- conv1
I1130 10:22:13.561949  3078 net.cpp:380] pool1 -> pool1
I1130 10:22:13.562005  3078 net.cpp:122] Setting up pool1
I1130 10:22:13.562014  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.562017  3078 net.cpp:137] Memory required for data: 17614000
I1130 10:22:13.562021  3078 layer_factory.hpp:77] Creating layer relu1
I1130 10:22:13.562028  3078 net.cpp:84] Creating Layer relu1
I1130 10:22:13.562031  3078 net.cpp:406] relu1 <- pool1
I1130 10:22:13.562038  3078 net.cpp:367] relu1 -> pool1 (in-place)
I1130 10:22:13.562330  3078 net.cpp:122] Setting up relu1
I1130 10:22:13.562341  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.562345  3078 net.cpp:137] Memory required for data: 20890800
I1130 10:22:13.562348  3078 layer_factory.hpp:77] Creating layer norm1
I1130 10:22:13.562361  3078 net.cpp:84] Creating Layer norm1
I1130 10:22:13.562366  3078 net.cpp:406] norm1 <- pool1
I1130 10:22:13.562371  3078 net.cpp:380] norm1 -> norm1
I1130 10:22:13.564043  3078 net.cpp:122] Setting up norm1
I1130 10:22:13.564064  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.564070  3078 net.cpp:137] Memory required for data: 24167600
I1130 10:22:13.564075  3078 layer_factory.hpp:77] Creating layer conv2
I1130 10:22:13.564086  3078 net.cpp:84] Creating Layer conv2
I1130 10:22:13.564091  3078 net.cpp:406] conv2 <- norm1
I1130 10:22:13.564100  3078 net.cpp:380] conv2 -> conv2
I1130 10:22:13.566175  3078 net.cpp:122] Setting up conv2
I1130 10:22:13.566191  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.566195  3078 net.cpp:137] Memory required for data: 27444400
I1130 10:22:13.566205  3078 layer_factory.hpp:77] Creating layer relu2
I1130 10:22:13.566210  3078 net.cpp:84] Creating Layer relu2
I1130 10:22:13.566215  3078 net.cpp:406] relu2 <- conv2
I1130 10:22:13.566220  3078 net.cpp:367] relu2 -> conv2 (in-place)
I1130 10:22:13.566478  3078 net.cpp:122] Setting up relu2
I1130 10:22:13.566489  3078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 10:22:13.566493  3078 net.cpp:137] Memory required for data: 30721200
I1130 10:22:13.566495  3078 layer_factory.hpp:77] Creating layer pool2
I1130 10:22:13.566503  3078 net.cpp:84] Creating Layer pool2
I1130 10:22:13.566504  3078 net.cpp:406] pool2 <- conv2
I1130 10:22:13.566511  3078 net.cpp:380] pool2 -> pool2
I1130 10:22:13.566764  3078 net.cpp:122] Setting up pool2
I1130 10:22:13.566774  3078 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 10:22:13.566778  3078 net.cpp:137] Memory required for data: 31540400
I1130 10:22:13.566781  3078 layer_factory.hpp:77] Creating layer norm2
I1130 10:22:13.566787  3078 net.cpp:84] Creating Layer norm2
I1130 10:22:13.566790  3078 net.cpp:406] norm2 <- pool2
I1130 10:22:13.566797  3078 net.cpp:380] norm2 -> norm2
I1130 10:22:13.567545  3078 net.cpp:122] Setting up norm2
I1130 10:22:13.567561  3078 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 10:22:13.567565  3078 net.cpp:137] Memory required for data: 32359600
I1130 10:22:13.567569  3078 layer_factory.hpp:77] Creating layer conv3
I1130 10:22:13.567579  3078 net.cpp:84] Creating Layer conv3
I1130 10:22:13.567582  3078 net.cpp:406] conv3 <- norm2
I1130 10:22:13.567601  3078 net.cpp:380] conv3 -> conv3
I1130 10:22:13.569597  3078 net.cpp:122] Setting up conv3
I1130 10:22:13.569617  3078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 10:22:13.569619  3078 net.cpp:137] Memory required for data: 33998000
I1130 10:22:13.569631  3078 layer_factory.hpp:77] Creating layer relu3
I1130 10:22:13.569638  3078 net.cpp:84] Creating Layer relu3
I1130 10:22:13.569643  3078 net.cpp:406] relu3 <- conv3
I1130 10:22:13.569648  3078 net.cpp:367] relu3 -> conv3 (in-place)
I1130 10:22:13.569895  3078 net.cpp:122] Setting up relu3
I1130 10:22:13.569905  3078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 10:22:13.569908  3078 net.cpp:137] Memory required for data: 35636400
I1130 10:22:13.569911  3078 layer_factory.hpp:77] Creating layer pool3
I1130 10:22:13.569917  3078 net.cpp:84] Creating Layer pool3
I1130 10:22:13.569921  3078 net.cpp:406] pool3 <- conv3
I1130 10:22:13.569926  3078 net.cpp:380] pool3 -> pool3
I1130 10:22:13.570170  3078 net.cpp:122] Setting up pool3
I1130 10:22:13.570180  3078 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1130 10:22:13.570183  3078 net.cpp:137] Memory required for data: 36046000
I1130 10:22:13.570186  3078 layer_factory.hpp:77] Creating layer ip1
I1130 10:22:13.570194  3078 net.cpp:84] Creating Layer ip1
I1130 10:22:13.570196  3078 net.cpp:406] ip1 <- pool3
I1130 10:22:13.570201  3078 net.cpp:380] ip1 -> ip1
I1130 10:22:13.570432  3078 net.cpp:122] Setting up ip1
I1130 10:22:13.570438  3078 net.cpp:129] Top shape: 100 10 (1000)
I1130 10:22:13.570441  3078 net.cpp:137] Memory required for data: 36050000
I1130 10:22:13.570447  3078 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I1130 10:22:13.570453  3078 net.cpp:84] Creating Layer ip1_ip1_0_split
I1130 10:22:13.570456  3078 net.cpp:406] ip1_ip1_0_split <- ip1
I1130 10:22:13.570461  3078 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1130 10:22:13.570466  3078 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1130 10:22:13.570508  3078 net.cpp:122] Setting up ip1_ip1_0_split
I1130 10:22:13.570514  3078 net.cpp:129] Top shape: 100 10 (1000)
I1130 10:22:13.570518  3078 net.cpp:129] Top shape: 100 10 (1000)
I1130 10:22:13.570519  3078 net.cpp:137] Memory required for data: 36058000
I1130 10:22:13.570523  3078 layer_factory.hpp:77] Creating layer accuracy
I1130 10:22:13.570528  3078 net.cpp:84] Creating Layer accuracy
I1130 10:22:13.570531  3078 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1130 10:22:13.570535  3078 net.cpp:406] accuracy <- label_cifar_1_split_0
I1130 10:22:13.570540  3078 net.cpp:380] accuracy -> accuracy
I1130 10:22:13.570547  3078 net.cpp:122] Setting up accuracy
I1130 10:22:13.570550  3078 net.cpp:129] Top shape: (1)
I1130 10:22:13.570554  3078 net.cpp:137] Memory required for data: 36058004
I1130 10:22:13.570555  3078 layer_factory.hpp:77] Creating layer loss
I1130 10:22:13.570564  3078 net.cpp:84] Creating Layer loss
I1130 10:22:13.570567  3078 net.cpp:406] loss <- ip1_ip1_0_split_1
I1130 10:22:13.570571  3078 net.cpp:406] loss <- label_cifar_1_split_1
I1130 10:22:13.570575  3078 net.cpp:380] loss -> loss
I1130 10:22:13.570588  3078 layer_factory.hpp:77] Creating layer loss
I1130 10:22:13.571234  3078 net.cpp:122] Setting up loss
I1130 10:22:13.571246  3078 net.cpp:129] Top shape: (1)
I1130 10:22:13.571249  3078 net.cpp:132]     with loss weight 1
I1130 10:22:13.571256  3078 net.cpp:137] Memory required for data: 36058008
I1130 10:22:13.571259  3078 net.cpp:198] loss needs backward computation.
I1130 10:22:13.571264  3078 net.cpp:200] accuracy does not need backward computation.
I1130 10:22:13.571266  3078 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1130 10:22:13.571269  3078 net.cpp:198] ip1 needs backward computation.
I1130 10:22:13.571272  3078 net.cpp:198] pool3 needs backward computation.
I1130 10:22:13.571275  3078 net.cpp:198] relu3 needs backward computation.
I1130 10:22:13.571277  3078 net.cpp:198] conv3 needs backward computation.
I1130 10:22:13.571281  3078 net.cpp:198] norm2 needs backward computation.
I1130 10:22:13.571283  3078 net.cpp:198] pool2 needs backward computation.
I1130 10:22:13.571305  3078 net.cpp:198] relu2 needs backward computation.
I1130 10:22:13.571313  3078 net.cpp:198] conv2 needs backward computation.
I1130 10:22:13.571317  3078 net.cpp:198] norm1 needs backward computation.
I1130 10:22:13.571321  3078 net.cpp:198] relu1 needs backward computation.
I1130 10:22:13.571324  3078 net.cpp:198] pool1 needs backward computation.
I1130 10:22:13.571328  3078 net.cpp:198] conv1 needs backward computation.
I1130 10:22:13.571331  3078 net.cpp:200] label_cifar_1_split does not need backward computation.
I1130 10:22:13.571336  3078 net.cpp:200] cifar does not need backward computation.
I1130 10:22:13.571338  3078 net.cpp:242] This network produces output accuracy
I1130 10:22:13.571344  3078 net.cpp:242] This network produces output loss
I1130 10:22:13.571358  3078 net.cpp:255] Network initialization done.
I1130 10:22:13.571604  3078 solver.cpp:56] Solver scaffolding done.
I1130 10:22:13.571939  3078 caffe.cpp:248] Starting Optimization
I1130 10:22:13.571944  3078 solver.cpp:272] Solving CIFAR10_full
I1130 10:22:13.571947  3078 solver.cpp:273] Learning Rate Policy: fixed
I1130 10:22:13.572386  3078 solver.cpp:330] Iteration 0, Testing net (#0)
I1130 10:22:13.900234  3078 blocking_queue.cpp:49] Waiting for data
I1130 10:22:14.379281  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:22:14.394531  3078 solver.cpp:397]     Test net output #0: accuracy = 0.0772
I1130 10:22:14.394562  3078 solver.cpp:397]     Test net output #1: loss = 2.30258 (* 1 = 2.30258 loss)
I1130 10:22:14.469753  3078 solver.cpp:218] Iteration 0 (0 iter/s, 0.897788s/200 iters), loss = 2.30261
I1130 10:22:14.469801  3078 solver.cpp:237]     Train net output #0: loss = 2.30261 (* 1 = 2.30261 loss)
I1130 10:22:14.469807  3078 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I1130 10:22:22.853581  3078 solver.cpp:218] Iteration 200 (23.8554 iter/s, 8.38383s/200 iters), loss = 1.77323
I1130 10:22:22.853606  3078 solver.cpp:237]     Train net output #0: loss = 1.77323 (* 1 = 1.77323 loss)
I1130 10:22:22.853611  3078 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I1130 10:22:31.242544  3078 solver.cpp:218] Iteration 400 (23.8408 iter/s, 8.38899s/200 iters), loss = 1.50084
I1130 10:22:31.242589  3078 solver.cpp:237]     Train net output #0: loss = 1.50084 (* 1 = 1.50084 loss)
I1130 10:22:31.242594  3078 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I1130 10:22:35.225663  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:22:39.624861  3078 solver.cpp:218] Iteration 600 (23.8597 iter/s, 8.38232s/200 iters), loss = 1.59378
I1130 10:22:39.624913  3078 solver.cpp:237]     Train net output #0: loss = 1.59378 (* 1 = 1.59378 loss)
I1130 10:22:39.624936  3078 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I1130 10:22:48.007544  3078 solver.cpp:218] Iteration 800 (23.8587 iter/s, 8.38268s/200 iters), loss = 1.37458
I1130 10:22:48.007570  3078 solver.cpp:237]     Train net output #0: loss = 1.37458 (* 1 = 1.37458 loss)
I1130 10:22:48.007575  3078 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I1130 10:22:56.192858  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:22:56.325983  3078 solver.cpp:330] Iteration 1000, Testing net (#0)
I1130 10:22:57.136482  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:22:57.159729  3078 solver.cpp:397]     Test net output #0: accuracy = 0.4981
I1130 10:22:57.159767  3078 solver.cpp:397]     Test net output #1: loss = 1.3782 (* 1 = 1.3782 loss)
I1130 10:22:57.202169  3078 solver.cpp:218] Iteration 1000 (21.7518 iter/s, 9.19464s/200 iters), loss = 1.3676
I1130 10:22:57.202219  3078 solver.cpp:237]     Train net output #0: loss = 1.3676 (* 1 = 1.3676 loss)
I1130 10:22:57.202224  3078 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I1130 10:23:05.592896  3078 solver.cpp:218] Iteration 1200 (23.8359 iter/s, 8.39072s/200 iters), loss = 1.26304
I1130 10:23:05.592922  3078 solver.cpp:237]     Train net output #0: loss = 1.26304 (* 1 = 1.26304 loss)
I1130 10:23:05.592945  3078 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I1130 10:23:13.996527  3078 solver.cpp:218] Iteration 1400 (23.7992 iter/s, 8.40365s/200 iters), loss = 1.23963
I1130 10:23:13.996719  3078 solver.cpp:237]     Train net output #0: loss = 1.23963 (* 1 = 1.23963 loss)
I1130 10:23:13.996744  3078 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I1130 10:23:17.996807  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:23:22.413774  3078 solver.cpp:218] Iteration 1600 (23.7612 iter/s, 8.41709s/200 iters), loss = 1.35508
I1130 10:23:22.413827  3078 solver.cpp:237]     Train net output #0: loss = 1.35508 (* 1 = 1.35508 loss)
I1130 10:23:22.413833  3078 sgd_solver.cpp:105] Iteration 1600, lr = 0.001
I1130 10:23:30.861865  3078 solver.cpp:218] Iteration 1800 (23.674 iter/s, 8.44807s/200 iters), loss = 1.10039
I1130 10:23:30.861923  3078 solver.cpp:237]     Train net output #0: loss = 1.10039 (* 1 = 1.10039 loss)
I1130 10:23:30.861929  3078 sgd_solver.cpp:105] Iteration 1800, lr = 0.001
I1130 10:23:39.090245  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:23:39.223850  3078 solver.cpp:330] Iteration 2000, Testing net (#0)
I1130 10:23:40.044347  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:23:40.059706  3078 solver.cpp:397]     Test net output #0: accuracy = 0.5717
I1130 10:23:40.059751  3078 solver.cpp:397]     Test net output #1: loss = 1.21026 (* 1 = 1.21026 loss)
I1130 10:23:40.102155  3078 solver.cpp:218] Iteration 2000 (21.6444 iter/s, 9.24027s/200 iters), loss = 1.1418
I1130 10:23:40.102212  3078 solver.cpp:237]     Train net output #0: loss = 1.1418 (* 1 = 1.1418 loss)
I1130 10:23:40.102218  3078 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I1130 10:23:48.523030  3078 solver.cpp:218] Iteration 2200 (23.7505 iter/s, 8.42086s/200 iters), loss = 1.13954
I1130 10:23:48.523174  3078 solver.cpp:237]     Train net output #0: loss = 1.13954 (* 1 = 1.13954 loss)
I1130 10:23:48.523200  3078 sgd_solver.cpp:105] Iteration 2200, lr = 0.001
I1130 10:23:56.944963  3078 solver.cpp:218] Iteration 2400 (23.7478 iter/s, 8.42184s/200 iters), loss = 1.05969
I1130 10:23:56.945016  3078 solver.cpp:237]     Train net output #0: loss = 1.05969 (* 1 = 1.05969 loss)
I1130 10:23:56.945020  3078 sgd_solver.cpp:105] Iteration 2400, lr = 0.001
I1130 10:24:00.942605  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:24:05.363487  3078 solver.cpp:218] Iteration 2600 (23.7571 iter/s, 8.41852s/200 iters), loss = 1.19244
I1130 10:24:05.363530  3078 solver.cpp:237]     Train net output #0: loss = 1.19244 (* 1 = 1.19244 loss)
I1130 10:24:05.363535  3078 sgd_solver.cpp:105] Iteration 2600, lr = 0.001
I1130 10:24:13.791312  3078 solver.cpp:218] Iteration 2800 (23.7309 iter/s, 8.42783s/200 iters), loss = 1.00546
I1130 10:24:13.791357  3078 solver.cpp:237]     Train net output #0: loss = 1.00546 (* 1 = 1.00546 loss)
I1130 10:24:13.791362  3078 sgd_solver.cpp:105] Iteration 2800, lr = 0.001
I1130 10:24:22.011286  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:24:22.144424  3078 solver.cpp:330] Iteration 3000, Testing net (#0)
I1130 10:24:22.962492  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:24:22.977349  3078 solver.cpp:397]     Test net output #0: accuracy = 0.6196
I1130 10:24:22.977375  3078 solver.cpp:397]     Test net output #1: loss = 1.08467 (* 1 = 1.08467 loss)
I1130 10:24:23.019678  3078 solver.cpp:218] Iteration 3000 (21.6723 iter/s, 9.22836s/200 iters), loss = 1.00028
I1130 10:24:23.019716  3078 solver.cpp:237]     Train net output #0: loss = 1.00028 (* 1 = 1.00028 loss)
I1130 10:24:23.019721  3078 sgd_solver.cpp:105] Iteration 3000, lr = 0.001
I1130 10:24:31.442733  3078 solver.cpp:218] Iteration 3200 (23.7443 iter/s, 8.42306s/200 iters), loss = 1.05861
I1130 10:24:31.442781  3078 solver.cpp:237]     Train net output #0: loss = 1.05861 (* 1 = 1.05861 loss)
I1130 10:24:31.442787  3078 sgd_solver.cpp:105] Iteration 3200, lr = 0.001
I1130 10:24:39.864601  3078 solver.cpp:218] Iteration 3400 (23.7477 iter/s, 8.42188s/200 iters), loss = 0.960529
I1130 10:24:39.864639  3078 solver.cpp:237]     Train net output #0: loss = 0.960529 (* 1 = 0.960529 loss)
I1130 10:24:39.864665  3078 sgd_solver.cpp:105] Iteration 3400, lr = 0.001
I1130 10:24:43.871821  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:24:48.297276  3078 solver.cpp:218] Iteration 3600 (23.7172 iter/s, 8.43268s/200 iters), loss = 1.10805
I1130 10:24:48.297304  3078 solver.cpp:237]     Train net output #0: loss = 1.10805 (* 1 = 1.10805 loss)
I1130 10:24:48.297310  3078 sgd_solver.cpp:105] Iteration 3600, lr = 0.001
I1130 10:24:56.717089  3078 solver.cpp:218] Iteration 3800 (23.7535 iter/s, 8.41983s/200 iters), loss = 0.960044
I1130 10:24:56.717188  3078 solver.cpp:237]     Train net output #0: loss = 0.960044 (* 1 = 0.960044 loss)
I1130 10:24:56.717206  3078 sgd_solver.cpp:105] Iteration 3800, lr = 0.001
I1130 10:25:04.927605  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:25:05.060436  3078 solver.cpp:330] Iteration 4000, Testing net (#0)
I1130 10:25:05.882266  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:25:05.897642  3078 solver.cpp:397]     Test net output #0: accuracy = 0.6423
I1130 10:25:05.897686  3078 solver.cpp:397]     Test net output #1: loss = 1.00829 (* 1 = 1.00829 loss)
I1130 10:25:05.940340  3078 solver.cpp:218] Iteration 4000 (21.6845 iter/s, 9.22319s/200 iters), loss = 0.87915
I1130 10:25:05.940418  3078 solver.cpp:237]     Train net output #0: loss = 0.87915 (* 1 = 0.87915 loss)
I1130 10:25:05.940424  3078 sgd_solver.cpp:105] Iteration 4000, lr = 0.001
I1130 10:25:14.363178  3078 solver.cpp:218] Iteration 4200 (23.745 iter/s, 8.42281s/200 iters), loss = 0.975381
I1130 10:25:14.363221  3078 solver.cpp:237]     Train net output #0: loss = 0.975381 (* 1 = 0.975381 loss)
I1130 10:25:14.363226  3078 sgd_solver.cpp:105] Iteration 4200, lr = 0.001
I1130 10:25:22.808506  3078 solver.cpp:218] Iteration 4400 (23.6817 iter/s, 8.44532s/200 iters), loss = 0.894491
I1130 10:25:22.808562  3078 solver.cpp:237]     Train net output #0: loss = 0.894491 (* 1 = 0.894491 loss)
I1130 10:25:22.808567  3078 sgd_solver.cpp:105] Iteration 4400, lr = 0.001
I1130 10:25:26.821907  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:25:31.234519  3078 solver.cpp:218] Iteration 4600 (23.736 iter/s, 8.426s/200 iters), loss = 1.04177
I1130 10:25:31.234565  3078 solver.cpp:237]     Train net output #0: loss = 1.04177 (* 1 = 1.04177 loss)
I1130 10:25:31.234568  3078 sgd_solver.cpp:105] Iteration 4600, lr = 0.001
I1130 10:25:39.641422  3078 solver.cpp:218] Iteration 4800 (23.79 iter/s, 8.4069s/200 iters), loss = 0.856891
I1130 10:25:39.641466  3078 solver.cpp:237]     Train net output #0: loss = 0.856891 (* 1 = 0.856891 loss)
I1130 10:25:39.641470  3078 sgd_solver.cpp:105] Iteration 4800, lr = 0.001
I1130 10:25:47.850983  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:25:47.978626  3078 solver.cpp:330] Iteration 5000, Testing net (#0)
I1130 10:25:48.806579  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:25:48.821916  3078 solver.cpp:397]     Test net output #0: accuracy = 0.6643
I1130 10:25:48.821962  3078 solver.cpp:397]     Test net output #1: loss = 0.959105 (* 1 = 0.959105 loss)
I1130 10:25:48.864075  3078 solver.cpp:218] Iteration 5000 (21.6857 iter/s, 9.22265s/200 iters), loss = 0.808893
I1130 10:25:48.864135  3078 solver.cpp:237]     Train net output #0: loss = 0.808893 (* 1 = 0.808893 loss)
I1130 10:25:48.864140  3078 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1130 10:25:57.292749  3078 solver.cpp:218] Iteration 5200 (23.7286 iter/s, 8.42866s/200 iters), loss = 0.902391
I1130 10:25:57.292910  3078 solver.cpp:237]     Train net output #0: loss = 0.902391 (* 1 = 0.902391 loss)
I1130 10:25:57.292937  3078 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I1130 10:26:05.719434  3078 solver.cpp:218] Iteration 5400 (23.7344 iter/s, 8.42657s/200 iters), loss = 0.866337
I1130 10:26:05.719492  3078 solver.cpp:237]     Train net output #0: loss = 0.866337 (* 1 = 0.866337 loss)
I1130 10:26:05.719496  3078 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I1130 10:26:09.719949  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:26:14.136509  3078 solver.cpp:218] Iteration 5600 (23.7612 iter/s, 8.41707s/200 iters), loss = 0.969958
I1130 10:26:14.136553  3078 solver.cpp:237]     Train net output #0: loss = 0.969958 (* 1 = 0.969958 loss)
I1130 10:26:14.136557  3078 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I1130 10:26:22.560256  3078 solver.cpp:218] Iteration 5800 (23.7424 iter/s, 8.42375s/200 iters), loss = 0.777974
I1130 10:26:22.560288  3078 solver.cpp:237]     Train net output #0: loss = 0.777974 (* 1 = 0.777974 loss)
I1130 10:26:22.560315  3078 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I1130 10:26:30.760816  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:26:30.894269  3078 solver.cpp:330] Iteration 6000, Testing net (#0)
I1130 10:26:31.710508  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:26:31.725800  3078 solver.cpp:397]     Test net output #0: accuracy = 0.6744
I1130 10:26:31.725828  3078 solver.cpp:397]     Test net output #1: loss = 0.926561 (* 1 = 0.926561 loss)
I1130 10:26:31.768121  3078 solver.cpp:218] Iteration 6000 (21.7205 iter/s, 9.20788s/200 iters), loss = 0.770874
I1130 10:26:31.768177  3078 solver.cpp:237]     Train net output #0: loss = 0.770874 (* 1 = 0.770874 loss)
I1130 10:26:31.768201  3078 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1130 10:26:40.181439  3078 solver.cpp:218] Iteration 6200 (23.7719 iter/s, 8.41331s/200 iters), loss = 0.853987
I1130 10:26:40.181484  3078 solver.cpp:237]     Train net output #0: loss = 0.853987 (* 1 = 0.853987 loss)
I1130 10:26:40.181489  3078 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I1130 10:26:48.613150  3078 solver.cpp:218] Iteration 6400 (23.72 iter/s, 8.43171s/200 iters), loss = 0.858612
I1130 10:26:48.613193  3078 solver.cpp:237]     Train net output #0: loss = 0.858612 (* 1 = 0.858612 loss)
I1130 10:26:48.613198  3078 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I1130 10:26:52.619966  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:26:57.045871  3078 solver.cpp:218] Iteration 6600 (23.7171 iter/s, 8.43274s/200 iters), loss = 0.921401
I1130 10:26:57.045920  3078 solver.cpp:237]     Train net output #0: loss = 0.921401 (* 1 = 0.921401 loss)
I1130 10:26:57.045925  3078 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I1130 10:27:05.479885  3078 solver.cpp:218] Iteration 6800 (23.7135 iter/s, 8.43401s/200 iters), loss = 0.746628
I1130 10:27:05.479990  3078 solver.cpp:237]     Train net output #0: loss = 0.746628 (* 1 = 0.746628 loss)
I1130 10:27:05.480007  3078 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I1130 10:27:13.702097  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:27:13.835564  3078 solver.cpp:330] Iteration 7000, Testing net (#0)
I1130 10:27:14.652107  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:27:14.667369  3078 solver.cpp:397]     Test net output #0: accuracy = 0.6838
I1130 10:27:14.667433  3078 solver.cpp:397]     Test net output #1: loss = 0.901212 (* 1 = 0.901212 loss)
I1130 10:27:14.709769  3078 solver.cpp:218] Iteration 7000 (21.6689 iter/s, 9.22981s/200 iters), loss = 0.755225
I1130 10:27:14.709837  3078 solver.cpp:237]     Train net output #0: loss = 0.755225 (* 1 = 0.755225 loss)
I1130 10:27:14.709843  3078 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1130 10:27:23.134910  3078 solver.cpp:218] Iteration 7200 (23.7385 iter/s, 8.42513s/200 iters), loss = 0.844456
I1130 10:27:23.134953  3078 solver.cpp:237]     Train net output #0: loss = 0.844456 (* 1 = 0.844456 loss)
I1130 10:27:23.134958  3078 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I1130 10:27:31.570559  3078 solver.cpp:218] Iteration 7400 (23.7089 iter/s, 8.43565s/200 iters), loss = 0.836657
I1130 10:27:31.570611  3078 solver.cpp:237]     Train net output #0: loss = 0.836657 (* 1 = 0.836657 loss)
I1130 10:27:31.570616  3078 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I1130 10:27:35.569344  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:27:39.986173  3078 solver.cpp:218] Iteration 7600 (23.7654 iter/s, 8.41561s/200 iters), loss = 0.906915
I1130 10:27:39.986219  3078 solver.cpp:237]     Train net output #0: loss = 0.906915 (* 1 = 0.906915 loss)
I1130 10:27:39.986223  3078 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I1130 10:27:48.397317  3078 solver.cpp:218] Iteration 7800 (23.778 iter/s, 8.41115s/200 iters), loss = 0.735503
I1130 10:27:48.397344  3078 solver.cpp:237]     Train net output #0: loss = 0.735503 (* 1 = 0.735503 loss)
I1130 10:27:48.397348  3078 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I1130 10:27:56.593859  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:27:56.727139  3078 solver.cpp:330] Iteration 8000, Testing net (#0)
I1130 10:27:57.547368  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:27:57.562636  3078 solver.cpp:397]     Test net output #0: accuracy = 0.6937
I1130 10:27:57.562680  3078 solver.cpp:397]     Test net output #1: loss = 0.872851 (* 1 = 0.872851 loss)
I1130 10:27:57.604718  3078 solver.cpp:218] Iteration 8000 (21.7216 iter/s, 9.20742s/200 iters), loss = 0.735662
I1130 10:27:57.604775  3078 solver.cpp:237]     Train net output #0: loss = 0.735662 (* 1 = 0.735662 loss)
I1130 10:27:57.604799  3078 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1130 10:28:06.004122  3078 solver.cpp:218] Iteration 8200 (23.8112 iter/s, 8.3994s/200 iters), loss = 0.831267
I1130 10:28:06.004199  3078 solver.cpp:237]     Train net output #0: loss = 0.831267 (* 1 = 0.831267 loss)
I1130 10:28:06.004204  3078 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I1130 10:28:14.402850  3078 solver.cpp:218] Iteration 8400 (23.8132 iter/s, 8.3987s/200 iters), loss = 0.819849
I1130 10:28:14.402894  3078 solver.cpp:237]     Train net output #0: loss = 0.819849 (* 1 = 0.819849 loss)
I1130 10:28:14.402899  3078 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I1130 10:28:18.393088  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:28:22.803349  3078 solver.cpp:218] Iteration 8600 (23.8081 iter/s, 8.40049s/200 iters), loss = 0.898152
I1130 10:28:22.803397  3078 solver.cpp:237]     Train net output #0: loss = 0.898152 (* 1 = 0.898152 loss)
I1130 10:28:22.803402  3078 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I1130 10:28:31.205425  3078 solver.cpp:218] Iteration 8800 (23.8036 iter/s, 8.40208s/200 iters), loss = 0.715619
I1130 10:28:31.205467  3078 solver.cpp:237]     Train net output #0: loss = 0.715619 (* 1 = 0.715619 loss)
I1130 10:28:31.205472  3078 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I1130 10:28:39.400795  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:28:39.528018  3078 solver.cpp:330] Iteration 9000, Testing net (#0)
I1130 10:28:40.342828  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:28:40.358021  3078 solver.cpp:397]     Test net output #0: accuracy = 0.703
I1130 10:28:40.358043  3078 solver.cpp:397]     Test net output #1: loss = 0.848767 (* 1 = 0.848767 loss)
I1130 10:28:40.400241  3078 solver.cpp:218] Iteration 9000 (21.7514 iter/s, 9.19482s/200 iters), loss = 0.717039
I1130 10:28:40.400322  3078 solver.cpp:237]     Train net output #0: loss = 0.717039 (* 1 = 0.717039 loss)
I1130 10:28:40.400329  3078 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1130 10:28:48.804805  3078 solver.cpp:218] Iteration 9200 (23.7966 iter/s, 8.40455s/200 iters), loss = 0.807668
I1130 10:28:48.804850  3078 solver.cpp:237]     Train net output #0: loss = 0.807668 (* 1 = 0.807668 loss)
I1130 10:28:48.804854  3078 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I1130 10:28:57.211195  3078 solver.cpp:218] Iteration 9400 (23.7914 iter/s, 8.4064s/200 iters), loss = 0.810952
I1130 10:28:57.211239  3078 solver.cpp:237]     Train net output #0: loss = 0.810952 (* 1 = 0.810952 loss)
I1130 10:28:57.211243  3078 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I1130 10:29:01.205651  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:29:05.616904  3078 solver.cpp:218] Iteration 9600 (23.7933 iter/s, 8.40573s/200 iters), loss = 0.885237
I1130 10:29:05.616947  3078 solver.cpp:237]     Train net output #0: loss = 0.885237 (* 1 = 0.885237 loss)
I1130 10:29:05.616951  3078 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1130 10:29:14.031579  3078 solver.cpp:218] Iteration 9800 (23.768 iter/s, 8.41468s/200 iters), loss = 0.705253
I1130 10:29:14.031764  3078 solver.cpp:237]     Train net output #0: loss = 0.705253 (* 1 = 0.705253 loss)
I1130 10:29:14.031770  3078 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1130 10:29:22.248744  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:29:22.376293  3078 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_10000.caffemodel
I1130 10:29:22.411222  3078 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_10000.solverstate
I1130 10:29:22.411840  3078 solver.cpp:330] Iteration 10000, Testing net (#0)
I1130 10:29:23.190413  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:29:23.213718  3078 solver.cpp:397]     Test net output #0: accuracy = 0.71
I1130 10:29:23.213743  3078 solver.cpp:397]     Test net output #1: loss = 0.834648 (* 1 = 0.834648 loss)
I1130 10:29:23.256211  3078 solver.cpp:218] Iteration 10000 (21.6814 iter/s, 9.22451s/200 iters), loss = 0.700334
I1130 10:29:23.256242  3078 solver.cpp:237]     Train net output #0: loss = 0.700334 (* 1 = 0.700334 loss)
I1130 10:29:23.256268  3078 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1130 10:29:31.663413  3078 solver.cpp:218] Iteration 10200 (23.7891 iter/s, 8.40722s/200 iters), loss = 0.788898
I1130 10:29:31.663458  3078 solver.cpp:237]     Train net output #0: loss = 0.788898 (* 1 = 0.788898 loss)
I1130 10:29:31.663463  3078 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1130 10:29:40.080962  3078 solver.cpp:218] Iteration 10400 (23.7599 iter/s, 8.41754s/200 iters), loss = 0.79426
I1130 10:29:40.081009  3078 solver.cpp:237]     Train net output #0: loss = 0.79426 (* 1 = 0.79426 loss)
I1130 10:29:40.081013  3078 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1130 10:29:44.080620  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:29:48.502308  3078 solver.cpp:218] Iteration 10600 (23.7492 iter/s, 8.42135s/200 iters), loss = 0.872884
I1130 10:29:48.502353  3078 solver.cpp:237]     Train net output #0: loss = 0.872884 (* 1 = 0.872884 loss)
I1130 10:29:48.502357  3078 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1130 10:29:56.921824  3078 solver.cpp:218] Iteration 10800 (23.7543 iter/s, 8.41952s/200 iters), loss = 0.688495
I1130 10:29:56.921851  3078 solver.cpp:237]     Train net output #0: loss = 0.688495 (* 1 = 0.688495 loss)
I1130 10:29:56.921855  3078 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1130 10:30:05.133766  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:30:05.267347  3078 solver.cpp:330] Iteration 11000, Testing net (#0)
I1130 10:30:06.084017  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:30:06.099171  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7122
I1130 10:30:06.099225  3078 solver.cpp:397]     Test net output #1: loss = 0.821578 (* 1 = 0.821578 loss)
I1130 10:30:06.141820  3078 solver.cpp:218] Iteration 11000 (21.6919 iter/s, 9.22001s/200 iters), loss = 0.684671
I1130 10:30:06.141877  3078 solver.cpp:237]     Train net output #0: loss = 0.684671 (* 1 = 0.684671 loss)
I1130 10:30:06.141885  3078 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1130 10:30:14.574337  3078 solver.cpp:218] Iteration 11200 (23.7177 iter/s, 8.43251s/200 iters), loss = 0.763158
I1130 10:30:14.574398  3078 solver.cpp:237]     Train net output #0: loss = 0.763158 (* 1 = 0.763158 loss)
I1130 10:30:14.574403  3078 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1130 10:30:22.991161  3078 solver.cpp:218] Iteration 11400 (23.762 iter/s, 8.41681s/200 iters), loss = 0.780256
I1130 10:30:22.991189  3078 solver.cpp:237]     Train net output #0: loss = 0.780256 (* 1 = 0.780256 loss)
I1130 10:30:22.991192  3078 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1130 10:30:26.984625  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:30:31.409529  3078 solver.cpp:218] Iteration 11600 (23.7575 iter/s, 8.41839s/200 iters), loss = 0.871816
I1130 10:30:31.409576  3078 solver.cpp:237]     Train net output #0: loss = 0.871816 (* 1 = 0.871816 loss)
I1130 10:30:31.409581  3078 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1130 10:30:39.836206  3078 solver.cpp:218] Iteration 11800 (23.7341 iter/s, 8.42668s/200 iters), loss = 0.679325
I1130 10:30:39.836251  3078 solver.cpp:237]     Train net output #0: loss = 0.679325 (* 1 = 0.679325 loss)
I1130 10:30:39.836254  3078 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1130 10:30:48.059180  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:30:48.191812  3078 solver.cpp:330] Iteration 12000, Testing net (#0)
I1130 10:30:48.999382  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:30:49.022501  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7155
I1130 10:30:49.022557  3078 solver.cpp:397]     Test net output #1: loss = 0.81421 (* 1 = 0.81421 loss)
I1130 10:30:49.065261  3078 solver.cpp:218] Iteration 12000 (21.6707 iter/s, 9.22907s/200 iters), loss = 0.676863
I1130 10:30:49.065311  3078 solver.cpp:237]     Train net output #0: loss = 0.676863 (* 1 = 0.676863 loss)
I1130 10:30:49.065317  3078 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1130 10:30:57.507133  3078 solver.cpp:218] Iteration 12200 (23.6914 iter/s, 8.44187s/200 iters), loss = 0.74011
I1130 10:30:57.507177  3078 solver.cpp:237]     Train net output #0: loss = 0.74011 (* 1 = 0.74011 loss)
I1130 10:30:57.507181  3078 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1130 10:31:05.930866  3078 solver.cpp:218] Iteration 12400 (23.7424 iter/s, 8.42374s/200 iters), loss = 0.761608
I1130 10:31:05.930898  3078 solver.cpp:237]     Train net output #0: loss = 0.761608 (* 1 = 0.761608 loss)
I1130 10:31:05.930925  3078 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1130 10:31:09.941731  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:31:14.373378  3078 solver.cpp:218] Iteration 12600 (23.6896 iter/s, 8.44253s/200 iters), loss = 0.852749
I1130 10:31:14.373422  3078 solver.cpp:237]     Train net output #0: loss = 0.852749 (* 1 = 0.852749 loss)
I1130 10:31:14.373427  3078 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1130 10:31:22.806679  3078 solver.cpp:218] Iteration 12800 (23.7155 iter/s, 8.43331s/200 iters), loss = 0.658492
I1130 10:31:22.806830  3078 solver.cpp:237]     Train net output #0: loss = 0.658492 (* 1 = 0.658492 loss)
I1130 10:31:22.806850  3078 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1130 10:31:31.023959  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:31:31.157434  3078 solver.cpp:330] Iteration 13000, Testing net (#0)
I1130 10:31:31.972499  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:31:31.987784  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7175
I1130 10:31:31.987828  3078 solver.cpp:397]     Test net output #1: loss = 0.801373 (* 1 = 0.801373 loss)
I1130 10:31:32.029959  3078 solver.cpp:218] Iteration 13000 (21.6845 iter/s, 9.22318s/200 iters), loss = 0.66692
I1130 10:31:32.029996  3078 solver.cpp:237]     Train net output #0: loss = 0.66692 (* 1 = 0.66692 loss)
I1130 10:31:32.030020  3078 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1130 10:31:40.451007  3078 solver.cpp:218] Iteration 13200 (23.75 iter/s, 8.42107s/200 iters), loss = 0.725042
I1130 10:31:40.451051  3078 solver.cpp:237]     Train net output #0: loss = 0.725042 (* 1 = 0.725042 loss)
I1130 10:31:40.451056  3078 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1130 10:31:48.866497  3078 solver.cpp:218] Iteration 13400 (23.7656 iter/s, 8.41552s/200 iters), loss = 0.751056
I1130 10:31:48.866525  3078 solver.cpp:237]     Train net output #0: loss = 0.751056 (* 1 = 0.751056 loss)
I1130 10:31:48.866529  3078 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1130 10:31:52.865607  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:31:57.283164  3078 solver.cpp:218] Iteration 13600 (23.7623 iter/s, 8.41669s/200 iters), loss = 0.843011
I1130 10:31:57.283191  3078 solver.cpp:237]     Train net output #0: loss = 0.843011 (* 1 = 0.843011 loss)
I1130 10:31:57.283195  3078 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1130 10:32:05.711102  3078 solver.cpp:218] Iteration 13800 (23.7305 iter/s, 8.42796s/200 iters), loss = 0.641115
I1130 10:32:05.711129  3078 solver.cpp:237]     Train net output #0: loss = 0.641115 (* 1 = 0.641115 loss)
I1130 10:32:05.711134  3078 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1130 10:32:13.932083  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:32:14.064955  3078 solver.cpp:330] Iteration 14000, Testing net (#0)
I1130 10:32:14.873917  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:32:14.897164  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7176
I1130 10:32:14.897209  3078 solver.cpp:397]     Test net output #1: loss = 0.794398 (* 1 = 0.794398 loss)
I1130 10:32:14.939857  3078 solver.cpp:218] Iteration 14000 (21.6713 iter/s, 9.22878s/200 iters), loss = 0.655887
I1130 10:32:14.939908  3078 solver.cpp:237]     Train net output #0: loss = 0.655887 (* 1 = 0.655887 loss)
I1130 10:32:14.939913  3078 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1130 10:32:23.350741  3078 solver.cpp:218] Iteration 14200 (23.7787 iter/s, 8.41089s/200 iters), loss = 0.712562
I1130 10:32:23.350901  3078 solver.cpp:237]     Train net output #0: loss = 0.712562 (* 1 = 0.712562 loss)
I1130 10:32:23.350926  3078 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1130 10:32:31.765631  3078 solver.cpp:218] Iteration 14400 (23.7677 iter/s, 8.4148s/200 iters), loss = 0.744102
I1130 10:32:31.765657  3078 solver.cpp:237]     Train net output #0: loss = 0.744102 (* 1 = 0.744102 loss)
I1130 10:32:31.765662  3078 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1130 10:32:35.764654  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:32:40.183158  3078 solver.cpp:218] Iteration 14600 (23.7599 iter/s, 8.41755s/200 iters), loss = 0.830817
I1130 10:32:40.183203  3078 solver.cpp:237]     Train net output #0: loss = 0.830817 (* 1 = 0.830817 loss)
I1130 10:32:40.183207  3078 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1130 10:32:48.602320  3078 solver.cpp:218] Iteration 14800 (23.7553 iter/s, 8.41917s/200 iters), loss = 0.623984
I1130 10:32:48.602365  3078 solver.cpp:237]     Train net output #0: loss = 0.623984 (* 1 = 0.623984 loss)
I1130 10:32:48.602368  3078 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1130 10:32:56.804425  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:32:56.937172  3078 solver.cpp:330] Iteration 15000, Testing net (#0)
I1130 10:32:57.749711  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:32:57.772851  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7207
I1130 10:32:57.772897  3078 solver.cpp:397]     Test net output #1: loss = 0.787377 (* 1 = 0.787377 loss)
I1130 10:32:57.815119  3078 solver.cpp:218] Iteration 15000 (21.7089 iter/s, 9.21281s/200 iters), loss = 0.646721
I1130 10:32:57.815167  3078 solver.cpp:237]     Train net output #0: loss = 0.646721 (* 1 = 0.646721 loss)
I1130 10:32:57.815172  3078 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1130 10:33:06.228664  3078 solver.cpp:218] Iteration 15200 (23.7712 iter/s, 8.41355s/200 iters), loss = 0.693781
I1130 10:33:06.228709  3078 solver.cpp:237]     Train net output #0: loss = 0.693781 (* 1 = 0.693781 loss)
I1130 10:33:06.228713  3078 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1130 10:33:14.639228  3078 solver.cpp:218] Iteration 15400 (23.7796 iter/s, 8.41057s/200 iters), loss = 0.727804
I1130 10:33:14.639273  3078 solver.cpp:237]     Train net output #0: loss = 0.727804 (* 1 = 0.727804 loss)
I1130 10:33:14.639278  3078 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I1130 10:33:18.636771  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:33:23.060505  3078 solver.cpp:218] Iteration 15600 (23.7493 iter/s, 8.42128s/200 iters), loss = 0.826513
I1130 10:33:23.060550  3078 solver.cpp:237]     Train net output #0: loss = 0.826513 (* 1 = 0.826513 loss)
I1130 10:33:23.060555  3078 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I1130 10:33:31.486510  3078 solver.cpp:218] Iteration 15800 (23.736 iter/s, 8.42601s/200 iters), loss = 0.614151
I1130 10:33:31.486747  3078 solver.cpp:237]     Train net output #0: loss = 0.614151 (* 1 = 0.614151 loss)
I1130 10:33:31.486753  3078 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I1130 10:33:39.716181  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:33:39.849383  3078 solver.cpp:330] Iteration 16000, Testing net (#0)
I1130 10:33:40.657256  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:33:40.680222  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7206
I1130 10:33:40.680268  3078 solver.cpp:397]     Test net output #1: loss = 0.785783 (* 1 = 0.785783 loss)
I1130 10:33:40.723011  3078 solver.cpp:218] Iteration 16000 (21.6536 iter/s, 9.23634s/200 iters), loss = 0.633594
I1130 10:33:40.723062  3078 solver.cpp:237]     Train net output #0: loss = 0.633594 (* 1 = 0.633594 loss)
I1130 10:33:40.723068  3078 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I1130 10:33:49.155078  3078 solver.cpp:218] Iteration 16200 (23.719 iter/s, 8.43207s/200 iters), loss = 0.681169
I1130 10:33:49.155103  3078 solver.cpp:237]     Train net output #0: loss = 0.681169 (* 1 = 0.681169 loss)
I1130 10:33:49.155107  3078 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I1130 10:33:57.583770  3078 solver.cpp:218] Iteration 16400 (23.7284 iter/s, 8.42872s/200 iters), loss = 0.714847
I1130 10:33:57.583834  3078 solver.cpp:237]     Train net output #0: loss = 0.714847 (* 1 = 0.714847 loss)
I1130 10:33:57.583839  3078 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I1130 10:34:01.587615  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:34:06.013876  3078 solver.cpp:218] Iteration 16600 (23.7245 iter/s, 8.4301s/200 iters), loss = 0.822271
I1130 10:34:06.013921  3078 solver.cpp:237]     Train net output #0: loss = 0.822271 (* 1 = 0.822271 loss)
I1130 10:34:06.013926  3078 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I1130 10:34:14.445303  3078 solver.cpp:218] Iteration 16800 (23.7208 iter/s, 8.43144s/200 iters), loss = 0.609013
I1130 10:34:14.445330  3078 solver.cpp:237]     Train net output #0: loss = 0.609013 (* 1 = 0.609013 loss)
I1130 10:34:14.445334  3078 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I1130 10:34:22.674671  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:34:22.799811  3078 solver.cpp:330] Iteration 17000, Testing net (#0)
I1130 10:34:23.606570  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:34:23.629760  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7242
I1130 10:34:23.629801  3078 solver.cpp:397]     Test net output #1: loss = 0.777107 (* 1 = 0.777107 loss)
I1130 10:34:23.672044  3078 solver.cpp:218] Iteration 17000 (21.6761 iter/s, 9.22677s/200 iters), loss = 0.626581
I1130 10:34:23.672096  3078 solver.cpp:237]     Train net output #0: loss = 0.626581 (* 1 = 0.626581 loss)
I1130 10:34:23.672101  3078 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I1130 10:34:32.099601  3078 solver.cpp:218] Iteration 17200 (23.7317 iter/s, 8.42756s/200 iters), loss = 0.67165
I1130 10:34:32.099700  3078 solver.cpp:237]     Train net output #0: loss = 0.67165 (* 1 = 0.67165 loss)
I1130 10:34:32.099705  3078 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I1130 10:34:40.522356  3078 solver.cpp:218] Iteration 17400 (23.7453 iter/s, 8.42271s/200 iters), loss = 0.702314
I1130 10:34:40.522406  3078 solver.cpp:237]     Train net output #0: loss = 0.702314 (* 1 = 0.702314 loss)
I1130 10:34:40.522433  3078 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I1130 10:34:44.516885  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:34:48.934357  3078 solver.cpp:218] Iteration 17600 (23.7755 iter/s, 8.412s/200 iters), loss = 0.812164
I1130 10:34:48.934402  3078 solver.cpp:237]     Train net output #0: loss = 0.812164 (* 1 = 0.812164 loss)
I1130 10:34:48.934407  3078 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I1130 10:34:57.365207  3078 solver.cpp:218] Iteration 17800 (23.7224 iter/s, 8.43086s/200 iters), loss = 0.601406
I1130 10:34:57.365234  3078 solver.cpp:237]     Train net output #0: loss = 0.601406 (* 1 = 0.601406 loss)
I1130 10:34:57.365239  3078 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I1130 10:35:05.620224  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:35:05.749313  3078 solver.cpp:330] Iteration 18000, Testing net (#0)
I1130 10:35:06.599627  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:35:06.615434  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7247
I1130 10:35:06.615507  3078 solver.cpp:397]     Test net output #1: loss = 0.774603 (* 1 = 0.774603 loss)
I1130 10:35:06.658156  3078 solver.cpp:218] Iteration 18000 (21.5216 iter/s, 9.29297s/200 iters), loss = 0.624532
I1130 10:35:06.658219  3078 solver.cpp:237]     Train net output #0: loss = 0.624532 (* 1 = 0.624532 loss)
I1130 10:35:06.658226  3078 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I1130 10:35:15.084595  3078 solver.cpp:218] Iteration 18200 (23.7348 iter/s, 8.42643s/200 iters), loss = 0.659508
I1130 10:35:15.084622  3078 solver.cpp:237]     Train net output #0: loss = 0.659508 (* 1 = 0.659508 loss)
I1130 10:35:15.084626  3078 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I1130 10:35:23.493664  3078 solver.cpp:218] Iteration 18400 (23.7838 iter/s, 8.4091s/200 iters), loss = 0.691092
I1130 10:35:23.493707  3078 solver.cpp:237]     Train net output #0: loss = 0.691092 (* 1 = 0.691092 loss)
I1130 10:35:23.493711  3078 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I1130 10:35:27.496909  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:35:31.911128  3078 solver.cpp:218] Iteration 18600 (23.76 iter/s, 8.41749s/200 iters), loss = 0.801337
I1130 10:35:31.911172  3078 solver.cpp:237]     Train net output #0: loss = 0.801337 (* 1 = 0.801337 loss)
I1130 10:35:31.911176  3078 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I1130 10:35:40.319208  3078 solver.cpp:218] Iteration 18800 (23.7866 iter/s, 8.40809s/200 iters), loss = 0.591387
I1130 10:35:40.319372  3078 solver.cpp:237]     Train net output #0: loss = 0.591387 (* 1 = 0.591387 loss)
I1130 10:35:40.319407  3078 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I1130 10:35:48.518707  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:35:48.651967  3078 solver.cpp:330] Iteration 19000, Testing net (#0)
I1130 10:35:49.468564  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:35:49.484608  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7272
I1130 10:35:49.484688  3078 solver.cpp:397]     Test net output #1: loss = 0.769411 (* 1 = 0.769411 loss)
I1130 10:35:49.527195  3078 solver.cpp:218] Iteration 19000 (21.7205 iter/s, 9.20789s/200 iters), loss = 0.617176
I1130 10:35:49.527254  3078 solver.cpp:237]     Train net output #0: loss = 0.617176 (* 1 = 0.617176 loss)
I1130 10:35:49.527261  3078 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I1130 10:35:57.934703  3078 solver.cpp:218] Iteration 19200 (23.7883 iter/s, 8.40751s/200 iters), loss = 0.651637
I1130 10:35:57.934748  3078 solver.cpp:237]     Train net output #0: loss = 0.651637 (* 1 = 0.651637 loss)
I1130 10:35:57.934752  3078 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I1130 10:36:06.345831  3078 solver.cpp:218] Iteration 19400 (23.778 iter/s, 8.41114s/200 iters), loss = 0.688812
I1130 10:36:06.345857  3078 solver.cpp:237]     Train net output #0: loss = 0.688812 (* 1 = 0.688812 loss)
I1130 10:36:06.345862  3078 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I1130 10:36:10.348626  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:36:14.776633  3078 solver.cpp:218] Iteration 19600 (23.7225 iter/s, 8.43083s/200 iters), loss = 0.79395
I1130 10:36:14.776659  3078 solver.cpp:237]     Train net output #0: loss = 0.79395 (* 1 = 0.79395 loss)
I1130 10:36:14.776664  3078 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I1130 10:36:23.198698  3078 solver.cpp:218] Iteration 19800 (23.7471 iter/s, 8.42209s/200 iters), loss = 0.585162
I1130 10:36:23.198742  3078 solver.cpp:237]     Train net output #0: loss = 0.585162 (* 1 = 0.585162 loss)
I1130 10:36:23.198747  3078 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I1130 10:36:31.408836  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:36:31.541360  3078 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_20000.caffemodel
I1130 10:36:31.576143  3078 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_20000.solverstate
I1130 10:36:31.576653  3078 solver.cpp:330] Iteration 20000, Testing net (#0)
I1130 10:36:32.357733  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:36:32.373649  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7275
I1130 10:36:32.373731  3078 solver.cpp:397]     Test net output #1: loss = 0.769449 (* 1 = 0.769449 loss)
I1130 10:36:32.416326  3078 solver.cpp:218] Iteration 20000 (21.6975 iter/s, 9.21764s/200 iters), loss = 0.608056
I1130 10:36:32.416388  3078 solver.cpp:237]     Train net output #0: loss = 0.608056 (* 1 = 0.608056 loss)
I1130 10:36:32.416414  3078 sgd_solver.cpp:105] Iteration 20000, lr = 0.001
I1130 10:36:40.839640  3078 solver.cpp:218] Iteration 20200 (23.7436 iter/s, 8.42331s/200 iters), loss = 0.644705
I1130 10:36:40.839761  3078 solver.cpp:237]     Train net output #0: loss = 0.644705 (* 1 = 0.644705 loss)
I1130 10:36:40.839766  3078 sgd_solver.cpp:105] Iteration 20200, lr = 0.001
I1130 10:36:49.252403  3078 solver.cpp:218] Iteration 20400 (23.7735 iter/s, 8.41271s/200 iters), loss = 0.679937
I1130 10:36:49.252447  3078 solver.cpp:237]     Train net output #0: loss = 0.679937 (* 1 = 0.679937 loss)
I1130 10:36:49.252452  3078 sgd_solver.cpp:105] Iteration 20400, lr = 0.001
I1130 10:36:53.259021  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:36:57.671649  3078 solver.cpp:218] Iteration 20600 (23.7551 iter/s, 8.41926s/200 iters), loss = 0.779899
I1130 10:36:57.671675  3078 solver.cpp:237]     Train net output #0: loss = 0.779899 (* 1 = 0.779899 loss)
I1130 10:36:57.671680  3078 sgd_solver.cpp:105] Iteration 20600, lr = 0.001
I1130 10:37:06.101830  3078 solver.cpp:218] Iteration 20800 (23.7242 iter/s, 8.43021s/200 iters), loss = 0.575395
I1130 10:37:06.101857  3078 solver.cpp:237]     Train net output #0: loss = 0.575395 (* 1 = 0.575395 loss)
I1130 10:37:06.101881  3078 sgd_solver.cpp:105] Iteration 20800, lr = 0.001
I1130 10:37:14.310514  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:37:14.438937  3078 solver.cpp:330] Iteration 21000, Testing net (#0)
I1130 10:37:15.246434  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:37:15.270489  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7283
I1130 10:37:15.270534  3078 solver.cpp:397]     Test net output #1: loss = 0.76685 (* 1 = 0.76685 loss)
I1130 10:37:15.312562  3078 solver.cpp:218] Iteration 21000 (21.7137 iter/s, 9.21076s/200 iters), loss = 0.601437
I1130 10:37:15.312615  3078 solver.cpp:237]     Train net output #0: loss = 0.601437 (* 1 = 0.601437 loss)
I1130 10:37:15.312621  3078 sgd_solver.cpp:105] Iteration 21000, lr = 0.001
I1130 10:37:23.730062  3078 solver.cpp:218] Iteration 21200 (23.76 iter/s, 8.41752s/200 iters), loss = 0.636028
I1130 10:37:23.730103  3078 solver.cpp:237]     Train net output #0: loss = 0.636028 (* 1 = 0.636028 loss)
I1130 10:37:23.730108  3078 sgd_solver.cpp:105] Iteration 21200, lr = 0.001
I1130 10:37:32.138897  3078 solver.cpp:218] Iteration 21400 (23.7845 iter/s, 8.40885s/200 iters), loss = 0.668572
I1130 10:37:32.138941  3078 solver.cpp:237]     Train net output #0: loss = 0.668572 (* 1 = 0.668572 loss)
I1130 10:37:32.138944  3078 sgd_solver.cpp:105] Iteration 21400, lr = 0.001
I1130 10:37:36.134498  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:37:40.551470  3078 solver.cpp:218] Iteration 21600 (23.7739 iter/s, 8.41259s/200 iters), loss = 0.771147
I1130 10:37:40.551497  3078 solver.cpp:237]     Train net output #0: loss = 0.771147 (* 1 = 0.771147 loss)
I1130 10:37:40.551501  3078 sgd_solver.cpp:105] Iteration 21600, lr = 0.001
I1130 10:37:48.986562  3078 solver.cpp:218] Iteration 21800 (23.7104 iter/s, 8.43512s/200 iters), loss = 0.570545
I1130 10:37:48.986753  3078 solver.cpp:237]     Train net output #0: loss = 0.570545 (* 1 = 0.570545 loss)
I1130 10:37:48.986778  3078 sgd_solver.cpp:105] Iteration 21800, lr = 0.001
I1130 10:37:57.220535  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:37:57.348438  3078 solver.cpp:330] Iteration 22000, Testing net (#0)
I1130 10:37:58.146642  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:37:58.178504  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7297
I1130 10:37:58.178535  3078 solver.cpp:397]     Test net output #1: loss = 0.765825 (* 1 = 0.765825 loss)
I1130 10:37:58.220861  3078 solver.cpp:218] Iteration 22000 (21.6587 iter/s, 9.23416s/200 iters), loss = 0.590506
I1130 10:37:58.220927  3078 solver.cpp:237]     Train net output #0: loss = 0.590506 (* 1 = 0.590506 loss)
I1130 10:37:58.220934  3078 sgd_solver.cpp:105] Iteration 22000, lr = 0.001
I1130 10:38:06.662580  3078 solver.cpp:218] Iteration 22200 (23.6918 iter/s, 8.44173s/200 iters), loss = 0.627029
I1130 10:38:06.662606  3078 solver.cpp:237]     Train net output #0: loss = 0.627029 (* 1 = 0.627029 loss)
I1130 10:38:06.662611  3078 sgd_solver.cpp:105] Iteration 22200, lr = 0.001
I1130 10:38:15.070739  3078 solver.cpp:218] Iteration 22400 (23.7863 iter/s, 8.40819s/200 iters), loss = 0.659417
I1130 10:38:15.070765  3078 solver.cpp:237]     Train net output #0: loss = 0.659417 (* 1 = 0.659417 loss)
I1130 10:38:15.070770  3078 sgd_solver.cpp:105] Iteration 22400, lr = 0.001
I1130 10:38:19.069474  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:38:23.489373  3078 solver.cpp:218] Iteration 22600 (23.7567 iter/s, 8.41866s/200 iters), loss = 0.7591
I1130 10:38:23.489418  3078 solver.cpp:237]     Train net output #0: loss = 0.7591 (* 1 = 0.7591 loss)
I1130 10:38:23.489423  3078 sgd_solver.cpp:105] Iteration 22600, lr = 0.001
I1130 10:38:31.914171  3078 solver.cpp:218] Iteration 22800 (23.7394 iter/s, 8.42481s/200 iters), loss = 0.566689
I1130 10:38:31.914216  3078 solver.cpp:237]     Train net output #0: loss = 0.566689 (* 1 = 0.566689 loss)
I1130 10:38:31.914219  3078 sgd_solver.cpp:105] Iteration 22800, lr = 0.001
I1130 10:38:40.107677  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:38:40.240775  3078 solver.cpp:330] Iteration 23000, Testing net (#0)
I1130 10:38:41.038858  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:38:41.070384  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7311
I1130 10:38:41.070431  3078 solver.cpp:397]     Test net output #1: loss = 0.761889 (* 1 = 0.761889 loss)
I1130 10:38:41.112507  3078 solver.cpp:218] Iteration 23000 (21.743 iter/s, 9.19834s/200 iters), loss = 0.580134
I1130 10:38:41.112566  3078 solver.cpp:237]     Train net output #0: loss = 0.580134 (* 1 = 0.580134 loss)
I1130 10:38:41.112572  3078 sgd_solver.cpp:105] Iteration 23000, lr = 0.001
I1130 10:38:49.542078  3078 solver.cpp:218] Iteration 23200 (23.726 iter/s, 8.42957s/200 iters), loss = 0.620733
I1130 10:38:49.542153  3078 solver.cpp:237]     Train net output #0: loss = 0.620733 (* 1 = 0.620733 loss)
I1130 10:38:49.542172  3078 sgd_solver.cpp:105] Iteration 23200, lr = 0.001
I1130 10:38:57.951946  3078 solver.cpp:218] Iteration 23400 (23.7816 iter/s, 8.40985s/200 iters), loss = 0.655867
I1130 10:38:57.951990  3078 solver.cpp:237]     Train net output #0: loss = 0.655867 (* 1 = 0.655867 loss)
I1130 10:38:57.951994  3078 sgd_solver.cpp:105] Iteration 23400, lr = 0.001
I1130 10:39:01.948443  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:39:06.362983  3078 solver.cpp:218] Iteration 23600 (23.7782 iter/s, 8.41105s/200 iters), loss = 0.747751
I1130 10:39:06.363029  3078 solver.cpp:237]     Train net output #0: loss = 0.747751 (* 1 = 0.747751 loss)
I1130 10:39:06.363034  3078 sgd_solver.cpp:105] Iteration 23600, lr = 0.001
I1130 10:39:14.779256  3078 solver.cpp:218] Iteration 23800 (23.7635 iter/s, 8.41629s/200 iters), loss = 0.562154
I1130 10:39:14.779301  3078 solver.cpp:237]     Train net output #0: loss = 0.562154 (* 1 = 0.562154 loss)
I1130 10:39:14.779305  3078 sgd_solver.cpp:105] Iteration 23800, lr = 0.001
I1130 10:39:22.987242  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:39:23.120136  3078 solver.cpp:330] Iteration 24000, Testing net (#0)
I1130 10:39:23.926039  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:39:23.949662  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7344
I1130 10:39:23.949707  3078 solver.cpp:397]     Test net output #1: loss = 0.759514 (* 1 = 0.759514 loss)
I1130 10:39:23.992027  3078 solver.cpp:218] Iteration 24000 (21.709 iter/s, 9.21278s/200 iters), loss = 0.568001
I1130 10:39:23.992084  3078 solver.cpp:237]     Train net output #0: loss = 0.568001 (* 1 = 0.568001 loss)
I1130 10:39:23.992089  3078 sgd_solver.cpp:105] Iteration 24000, lr = 0.001
I1130 10:39:32.404688  3078 solver.cpp:218] Iteration 24200 (23.7737 iter/s, 8.41266s/200 iters), loss = 0.614975
I1130 10:39:32.404716  3078 solver.cpp:237]     Train net output #0: loss = 0.614975 (* 1 = 0.614975 loss)
I1130 10:39:32.404719  3078 sgd_solver.cpp:105] Iteration 24200, lr = 0.001
I1130 10:39:40.815644  3078 solver.cpp:218] Iteration 24400 (23.7784 iter/s, 8.41098s/200 iters), loss = 0.647474
I1130 10:39:40.815688  3078 solver.cpp:237]     Train net output #0: loss = 0.647474 (* 1 = 0.647474 loss)
I1130 10:39:40.815692  3078 sgd_solver.cpp:105] Iteration 24400, lr = 0.001
I1130 10:39:44.810029  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:39:49.223356  3078 solver.cpp:218] Iteration 24600 (23.7876 iter/s, 8.40772s/200 iters), loss = 0.7387
I1130 10:39:49.223400  3078 solver.cpp:237]     Train net output #0: loss = 0.7387 (* 1 = 0.7387 loss)
I1130 10:39:49.223405  3078 sgd_solver.cpp:105] Iteration 24600, lr = 0.001
I1130 10:39:57.651528  3078 solver.cpp:218] Iteration 24800 (23.7299 iter/s, 8.42818s/200 iters), loss = 0.557159
I1130 10:39:57.651674  3078 solver.cpp:237]     Train net output #0: loss = 0.557159 (* 1 = 0.557159 loss)
I1130 10:39:57.651695  3078 sgd_solver.cpp:105] Iteration 24800, lr = 0.001
I1130 10:40:05.857782  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:40:05.991240  3078 solver.cpp:330] Iteration 25000, Testing net (#0)
I1130 10:40:06.800106  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:40:06.823415  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7359
I1130 10:40:06.823457  3078 solver.cpp:397]     Test net output #1: loss = 0.75875 (* 1 = 0.75875 loss)
I1130 10:40:06.865898  3078 solver.cpp:218] Iteration 25000 (21.7054 iter/s, 9.21429s/200 iters), loss = 0.562438
I1130 10:40:06.865949  3078 solver.cpp:237]     Train net output #0: loss = 0.562438 (* 1 = 0.562438 loss)
I1130 10:40:06.865955  3078 sgd_solver.cpp:105] Iteration 25000, lr = 0.001
I1130 10:40:15.287673  3078 solver.cpp:218] Iteration 25200 (23.748 iter/s, 8.42178s/200 iters), loss = 0.606728
I1130 10:40:15.287701  3078 solver.cpp:237]     Train net output #0: loss = 0.606728 (* 1 = 0.606728 loss)
I1130 10:40:15.287708  3078 sgd_solver.cpp:105] Iteration 25200, lr = 0.001
I1130 10:40:23.709895  3078 solver.cpp:218] Iteration 25400 (23.7466 iter/s, 8.42225s/200 iters), loss = 0.640777
I1130 10:40:23.709923  3078 solver.cpp:237]     Train net output #0: loss = 0.640777 (* 1 = 0.640777 loss)
I1130 10:40:23.709946  3078 sgd_solver.cpp:105] Iteration 25400, lr = 0.001
I1130 10:40:27.710424  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:40:32.129909  3078 solver.cpp:218] Iteration 25600 (23.7528 iter/s, 8.42004s/200 iters), loss = 0.723881
I1130 10:40:32.129953  3078 solver.cpp:237]     Train net output #0: loss = 0.723881 (* 1 = 0.723881 loss)
I1130 10:40:32.129958  3078 sgd_solver.cpp:105] Iteration 25600, lr = 0.001
I1130 10:40:40.549015  3078 solver.cpp:218] Iteration 25800 (23.7555 iter/s, 8.41912s/200 iters), loss = 0.550645
I1130 10:40:40.549060  3078 solver.cpp:237]     Train net output #0: loss = 0.550645 (* 1 = 0.550645 loss)
I1130 10:40:40.549064  3078 sgd_solver.cpp:105] Iteration 25800, lr = 0.001
I1130 10:40:48.761564  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:40:48.894523  3078 solver.cpp:330] Iteration 26000, Testing net (#0)
I1130 10:40:49.696414  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:40:49.727740  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7358
I1130 10:40:49.727795  3078 solver.cpp:397]     Test net output #1: loss = 0.759396 (* 1 = 0.759396 loss)
I1130 10:40:49.770014  3078 solver.cpp:218] Iteration 26000 (21.6897 iter/s, 9.22098s/200 iters), loss = 0.557765
I1130 10:40:49.770069  3078 solver.cpp:237]     Train net output #0: loss = 0.557765 (* 1 = 0.557765 loss)
I1130 10:40:49.770076  3078 sgd_solver.cpp:105] Iteration 26000, lr = 0.001
I1130 10:40:58.191635  3078 solver.cpp:218] Iteration 26200 (23.7484 iter/s, 8.42162s/200 iters), loss = 0.60122
I1130 10:40:58.191776  3078 solver.cpp:237]     Train net output #0: loss = 0.60122 (* 1 = 0.60122 loss)
I1130 10:40:58.191781  3078 sgd_solver.cpp:105] Iteration 26200, lr = 0.001
I1130 10:41:06.598150  3078 solver.cpp:218] Iteration 26400 (23.7913 iter/s, 8.40643s/200 iters), loss = 0.628202
I1130 10:41:06.598194  3078 solver.cpp:237]     Train net output #0: loss = 0.628202 (* 1 = 0.628202 loss)
I1130 10:41:06.598199  3078 sgd_solver.cpp:105] Iteration 26400, lr = 0.001
I1130 10:41:10.590692  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:41:14.999935  3078 solver.cpp:218] Iteration 26600 (23.8044 iter/s, 8.4018s/200 iters), loss = 0.711201
I1130 10:41:14.999981  3078 solver.cpp:237]     Train net output #0: loss = 0.711201 (* 1 = 0.711201 loss)
I1130 10:41:14.999985  3078 sgd_solver.cpp:105] Iteration 26600, lr = 0.001
I1130 10:41:23.403589  3078 solver.cpp:218] Iteration 26800 (23.7992 iter/s, 8.40366s/200 iters), loss = 0.547561
I1130 10:41:23.403633  3078 solver.cpp:237]     Train net output #0: loss = 0.547561 (* 1 = 0.547561 loss)
I1130 10:41:23.403638  3078 sgd_solver.cpp:105] Iteration 26800, lr = 0.001
I1130 10:41:31.614753  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:41:31.748165  3078 solver.cpp:330] Iteration 27000, Testing net (#0)
I1130 10:41:32.558431  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:41:32.581768  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7356
I1130 10:41:32.581794  3078 solver.cpp:397]     Test net output #1: loss = 0.757524 (* 1 = 0.757524 loss)
I1130 10:41:32.624271  3078 solver.cpp:218] Iteration 27000 (21.6903 iter/s, 9.2207s/200 iters), loss = 0.551146
I1130 10:41:32.624305  3078 solver.cpp:237]     Train net output #0: loss = 0.551146 (* 1 = 0.551146 loss)
I1130 10:41:32.624330  3078 sgd_solver.cpp:105] Iteration 27000, lr = 0.001
I1130 10:41:41.046717  3078 solver.cpp:218] Iteration 27200 (23.746 iter/s, 8.42247s/200 iters), loss = 0.596485
I1130 10:41:41.046768  3078 solver.cpp:237]     Train net output #0: loss = 0.596485 (* 1 = 0.596485 loss)
I1130 10:41:41.046773  3078 sgd_solver.cpp:105] Iteration 27200, lr = 0.001
I1130 10:41:49.455788  3078 solver.cpp:218] Iteration 27400 (23.7838 iter/s, 8.40907s/200 iters), loss = 0.618266
I1130 10:41:49.455816  3078 solver.cpp:237]     Train net output #0: loss = 0.618266 (* 1 = 0.618266 loss)
I1130 10:41:49.455821  3078 sgd_solver.cpp:105] Iteration 27400, lr = 0.001
I1130 10:41:53.451701  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:41:57.863643  3078 solver.cpp:218] Iteration 27600 (23.7872 iter/s, 8.40788s/200 iters), loss = 0.70476
I1130 10:41:57.863689  3078 solver.cpp:237]     Train net output #0: loss = 0.70476 (* 1 = 0.70476 loss)
I1130 10:41:57.863693  3078 sgd_solver.cpp:105] Iteration 27600, lr = 0.001
I1130 10:42:06.271625  3078 solver.cpp:218] Iteration 27800 (23.7869 iter/s, 8.40799s/200 iters), loss = 0.542298
I1130 10:42:06.271724  3078 solver.cpp:237]     Train net output #0: loss = 0.542298 (* 1 = 0.542298 loss)
I1130 10:42:06.271730  3078 sgd_solver.cpp:105] Iteration 27800, lr = 0.001
I1130 10:42:14.480199  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:42:14.613389  3078 solver.cpp:330] Iteration 28000, Testing net (#0)
I1130 10:42:15.422533  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:42:15.445781  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7365
I1130 10:42:15.445806  3078 solver.cpp:397]     Test net output #1: loss = 0.757387 (* 1 = 0.757387 loss)
I1130 10:42:15.488116  3078 solver.cpp:218] Iteration 28000 (21.7003 iter/s, 9.21645s/200 iters), loss = 0.544549
I1130 10:42:15.488164  3078 solver.cpp:237]     Train net output #0: loss = 0.544549 (* 1 = 0.544549 loss)
I1130 10:42:15.488170  3078 sgd_solver.cpp:105] Iteration 28000, lr = 0.001
I1130 10:42:23.916338  3078 solver.cpp:218] Iteration 28200 (23.7298 iter/s, 8.42823s/200 iters), loss = 0.589045
I1130 10:42:23.916366  3078 solver.cpp:237]     Train net output #0: loss = 0.589045 (* 1 = 0.589045 loss)
I1130 10:42:23.916370  3078 sgd_solver.cpp:105] Iteration 28200, lr = 0.001
I1130 10:42:32.334079  3078 solver.cpp:218] Iteration 28400 (23.7593 iter/s, 8.41777s/200 iters), loss = 0.611493
I1130 10:42:32.334123  3078 solver.cpp:237]     Train net output #0: loss = 0.611493 (* 1 = 0.611493 loss)
I1130 10:42:32.334127  3078 sgd_solver.cpp:105] Iteration 28400, lr = 0.001
I1130 10:42:36.334708  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:42:40.748215  3078 solver.cpp:218] Iteration 28600 (23.7695 iter/s, 8.41415s/200 iters), loss = 0.696913
I1130 10:42:40.748261  3078 solver.cpp:237]     Train net output #0: loss = 0.696913 (* 1 = 0.696913 loss)
I1130 10:42:40.748266  3078 sgd_solver.cpp:105] Iteration 28600, lr = 0.001
I1130 10:42:49.162261  3078 solver.cpp:218] Iteration 28800 (23.7697 iter/s, 8.41407s/200 iters), loss = 0.539362
I1130 10:42:49.162304  3078 solver.cpp:237]     Train net output #0: loss = 0.539362 (* 1 = 0.539362 loss)
I1130 10:42:49.162310  3078 sgd_solver.cpp:105] Iteration 28800, lr = 0.001
I1130 10:42:57.391602  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:42:57.524619  3078 solver.cpp:330] Iteration 29000, Testing net (#0)
I1130 10:42:58.334846  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:42:58.357992  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7366
I1130 10:42:58.358019  3078 solver.cpp:397]     Test net output #1: loss = 0.755234 (* 1 = 0.755234 loss)
I1130 10:42:58.400584  3078 solver.cpp:218] Iteration 29000 (21.6489 iter/s, 9.23834s/200 iters), loss = 0.534997
I1130 10:42:58.400635  3078 solver.cpp:237]     Train net output #0: loss = 0.534997 (* 1 = 0.534997 loss)
I1130 10:42:58.400640  3078 sgd_solver.cpp:105] Iteration 29000, lr = 0.001
I1130 10:43:06.837777  3078 solver.cpp:218] Iteration 29200 (23.7045 iter/s, 8.4372s/200 iters), loss = 0.581871
I1130 10:43:06.837878  3078 solver.cpp:237]     Train net output #0: loss = 0.581871 (* 1 = 0.581871 loss)
I1130 10:43:06.837896  3078 sgd_solver.cpp:105] Iteration 29200, lr = 0.001
I1130 10:43:15.274724  3078 solver.cpp:218] Iteration 29400 (23.7054 iter/s, 8.4369s/200 iters), loss = 0.602337
I1130 10:43:15.274775  3078 solver.cpp:237]     Train net output #0: loss = 0.602337 (* 1 = 0.602337 loss)
I1130 10:43:15.274781  3078 sgd_solver.cpp:105] Iteration 29400, lr = 0.001
I1130 10:43:19.284237  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:43:23.712519  3078 solver.cpp:218] Iteration 29600 (23.7029 iter/s, 8.4378s/200 iters), loss = 0.685965
I1130 10:43:23.712565  3078 solver.cpp:237]     Train net output #0: loss = 0.685965 (* 1 = 0.685965 loss)
I1130 10:43:23.712570  3078 sgd_solver.cpp:105] Iteration 29600, lr = 0.001
I1130 10:43:32.147558  3078 solver.cpp:218] Iteration 29800 (23.7106 iter/s, 8.43505s/200 iters), loss = 0.532018
I1130 10:43:32.147603  3078 solver.cpp:237]     Train net output #0: loss = 0.532018 (* 1 = 0.532018 loss)
I1130 10:43:32.147606  3078 sgd_solver.cpp:105] Iteration 29800, lr = 0.001
I1130 10:43:40.370185  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:43:40.503340  3078 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_30000.caffemodel
I1130 10:43:40.537936  3078 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_30000.solverstate
I1130 10:43:40.538458  3078 solver.cpp:330] Iteration 30000, Testing net (#0)
I1130 10:43:41.303508  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:43:41.334952  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7377
I1130 10:43:41.335005  3078 solver.cpp:397]     Test net output #1: loss = 0.754333 (* 1 = 0.754333 loss)
I1130 10:43:41.376941  3078 solver.cpp:218] Iteration 30000 (21.6699 iter/s, 9.22939s/200 iters), loss = 0.533557
I1130 10:43:41.377003  3078 solver.cpp:237]     Train net output #0: loss = 0.533557 (* 1 = 0.533557 loss)
I1130 10:43:41.377027  3078 sgd_solver.cpp:105] Iteration 30000, lr = 0.001
I1130 10:43:49.783183  3078 solver.cpp:218] Iteration 30200 (23.7919 iter/s, 8.40624s/200 iters), loss = 0.572251
I1130 10:43:49.783228  3078 solver.cpp:237]     Train net output #0: loss = 0.572251 (* 1 = 0.572251 loss)
I1130 10:43:49.783232  3078 sgd_solver.cpp:105] Iteration 30200, lr = 0.001
I1130 10:43:58.194458  3078 solver.cpp:218] Iteration 30400 (23.7776 iter/s, 8.41128s/200 iters), loss = 0.59664
I1130 10:43:58.194502  3078 solver.cpp:237]     Train net output #0: loss = 0.59664 (* 1 = 0.59664 loss)
I1130 10:43:58.194507  3078 sgd_solver.cpp:105] Iteration 30400, lr = 0.001
I1130 10:44:02.193486  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:44:06.611439  3078 solver.cpp:218] Iteration 30600 (23.7615 iter/s, 8.41698s/200 iters), loss = 0.678775
I1130 10:44:06.611485  3078 solver.cpp:237]     Train net output #0: loss = 0.678775 (* 1 = 0.678775 loss)
I1130 10:44:06.611490  3078 sgd_solver.cpp:105] Iteration 30600, lr = 0.001
I1130 10:44:15.028924  3078 solver.cpp:218] Iteration 30800 (23.76 iter/s, 8.41749s/200 iters), loss = 0.526188
I1130 10:44:15.028977  3078 solver.cpp:237]     Train net output #0: loss = 0.526188 (* 1 = 0.526188 loss)
I1130 10:44:15.028982  3078 sgd_solver.cpp:105] Iteration 30800, lr = 0.001
I1130 10:44:23.230079  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:44:23.362418  3078 solver.cpp:330] Iteration 31000, Testing net (#0)
I1130 10:44:24.165259  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:44:24.196571  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7373
I1130 10:44:24.196622  3078 solver.cpp:397]     Test net output #1: loss = 0.754556 (* 1 = 0.754556 loss)
I1130 10:44:24.238450  3078 solver.cpp:218] Iteration 31000 (21.7167 iter/s, 9.20952s/200 iters), loss = 0.528022
I1130 10:44:24.238557  3078 solver.cpp:237]     Train net output #0: loss = 0.528022 (* 1 = 0.528022 loss)
I1130 10:44:24.238564  3078 sgd_solver.cpp:105] Iteration 31000, lr = 0.001
I1130 10:44:32.642102  3078 solver.cpp:218] Iteration 31200 (23.7993 iter/s, 8.40362s/200 iters), loss = 0.567797
I1130 10:44:32.642128  3078 solver.cpp:237]     Train net output #0: loss = 0.567797 (* 1 = 0.567797 loss)
I1130 10:44:32.642133  3078 sgd_solver.cpp:105] Iteration 31200, lr = 0.001
I1130 10:44:41.061755  3078 solver.cpp:218] Iteration 31400 (23.7539 iter/s, 8.41968s/200 iters), loss = 0.589512
I1130 10:44:41.061800  3078 solver.cpp:237]     Train net output #0: loss = 0.589512 (* 1 = 0.589512 loss)
I1130 10:44:41.061805  3078 sgd_solver.cpp:105] Iteration 31400, lr = 0.001
I1130 10:44:45.053907  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:44:49.462556  3078 solver.cpp:218] Iteration 31600 (23.8072 iter/s, 8.40082s/200 iters), loss = 0.67132
I1130 10:44:49.462584  3078 solver.cpp:237]     Train net output #0: loss = 0.67132 (* 1 = 0.67132 loss)
I1130 10:44:49.462589  3078 sgd_solver.cpp:105] Iteration 31600, lr = 0.001
I1130 10:44:57.863874  3078 solver.cpp:218] Iteration 31800 (23.8057 iter/s, 8.40135s/200 iters), loss = 0.519185
I1130 10:44:57.863903  3078 solver.cpp:237]     Train net output #0: loss = 0.519185 (* 1 = 0.519185 loss)
I1130 10:44:57.863906  3078 sgd_solver.cpp:105] Iteration 31800, lr = 0.001
I1130 10:45:06.086189  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:45:06.220166  3078 solver.cpp:330] Iteration 32000, Testing net (#0)
I1130 10:45:07.028908  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:45:07.051924  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7377
I1130 10:45:07.051968  3078 solver.cpp:397]     Test net output #1: loss = 0.754251 (* 1 = 0.754251 loss)
I1130 10:45:07.094681  3078 solver.cpp:218] Iteration 32000 (21.6665 iter/s, 9.23084s/200 iters), loss = 0.526708
I1130 10:45:07.094715  3078 solver.cpp:237]     Train net output #0: loss = 0.526708 (* 1 = 0.526708 loss)
I1130 10:45:07.094722  3078 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I1130 10:45:15.511085  3078 solver.cpp:218] Iteration 32200 (23.7631 iter/s, 8.41642s/200 iters), loss = 0.557695
I1130 10:45:15.511203  3078 solver.cpp:237]     Train net output #0: loss = 0.557695 (* 1 = 0.557695 loss)
I1130 10:45:15.511207  3078 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I1130 10:45:23.918855  3078 solver.cpp:218] Iteration 32400 (23.7876 iter/s, 8.40772s/200 iters), loss = 0.585228
I1130 10:45:23.918900  3078 solver.cpp:237]     Train net output #0: loss = 0.585228 (* 1 = 0.585228 loss)
I1130 10:45:23.918905  3078 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I1130 10:45:27.915388  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:45:32.330709  3078 solver.cpp:218] Iteration 32600 (23.7759 iter/s, 8.41187s/200 iters), loss = 0.667297
I1130 10:45:32.330736  3078 solver.cpp:237]     Train net output #0: loss = 0.667297 (* 1 = 0.667297 loss)
I1130 10:45:32.330741  3078 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I1130 10:45:40.743937  3078 solver.cpp:218] Iteration 32800 (23.772 iter/s, 8.41326s/200 iters), loss = 0.515017
I1130 10:45:40.743983  3078 solver.cpp:237]     Train net output #0: loss = 0.515017 (* 1 = 0.515017 loss)
I1130 10:45:40.743988  3078 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I1130 10:45:48.949246  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:45:49.082746  3078 solver.cpp:330] Iteration 33000, Testing net (#0)
I1130 10:45:49.890419  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:45:49.913754  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7386
I1130 10:45:49.913796  3078 solver.cpp:397]     Test net output #1: loss = 0.753648 (* 1 = 0.753648 loss)
I1130 10:45:49.956192  3078 solver.cpp:218] Iteration 33000 (21.7102 iter/s, 9.21228s/200 iters), loss = 0.520215
I1130 10:45:49.956243  3078 solver.cpp:237]     Train net output #0: loss = 0.520215 (* 1 = 0.520215 loss)
I1130 10:45:49.956248  3078 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I1130 10:45:58.379802  3078 solver.cpp:218] Iteration 33200 (23.7428 iter/s, 8.42362s/200 iters), loss = 0.553464
I1130 10:45:58.379848  3078 solver.cpp:237]     Train net output #0: loss = 0.553464 (* 1 = 0.553464 loss)
I1130 10:45:58.379853  3078 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I1130 10:46:06.809015  3078 solver.cpp:218] Iteration 33400 (23.727 iter/s, 8.42922s/200 iters), loss = 0.578096
I1130 10:46:06.809065  3078 solver.cpp:237]     Train net output #0: loss = 0.578096 (* 1 = 0.578096 loss)
I1130 10:46:06.809070  3078 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I1130 10:46:10.814226  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:46:15.244200  3078 solver.cpp:218] Iteration 33600 (23.7102 iter/s, 8.43519s/200 iters), loss = 0.662769
I1130 10:46:15.244246  3078 solver.cpp:237]     Train net output #0: loss = 0.662769 (* 1 = 0.662769 loss)
I1130 10:46:15.244251  3078 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I1130 10:46:23.672207  3078 solver.cpp:218] Iteration 33800 (23.7304 iter/s, 8.42802s/200 iters), loss = 0.51143
I1130 10:46:23.672353  3078 solver.cpp:237]     Train net output #0: loss = 0.51143 (* 1 = 0.51143 loss)
I1130 10:46:23.672358  3078 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I1130 10:46:31.895561  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:46:32.028733  3078 solver.cpp:330] Iteration 34000, Testing net (#0)
I1130 10:46:32.834324  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:46:32.865695  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7391
I1130 10:46:32.865748  3078 solver.cpp:397]     Test net output #1: loss = 0.752975 (* 1 = 0.752975 loss)
I1130 10:46:32.907784  3078 solver.cpp:218] Iteration 34000 (21.6556 iter/s, 9.2355s/200 iters), loss = 0.517512
I1130 10:46:32.907841  3078 solver.cpp:237]     Train net output #0: loss = 0.517512 (* 1 = 0.517512 loss)
I1130 10:46:32.907847  3078 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I1130 10:46:41.356453  3078 solver.cpp:218] Iteration 34200 (23.6724 iter/s, 8.44867s/200 iters), loss = 0.548308
I1130 10:46:41.356498  3078 solver.cpp:237]     Train net output #0: loss = 0.548308 (* 1 = 0.548308 loss)
I1130 10:46:41.356503  3078 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I1130 10:46:49.801347  3078 solver.cpp:218] Iteration 34400 (23.6829 iter/s, 8.4449s/200 iters), loss = 0.569482
I1130 10:46:49.801410  3078 solver.cpp:237]     Train net output #0: loss = 0.569482 (* 1 = 0.569482 loss)
I1130 10:46:49.801416  3078 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I1130 10:46:53.831887  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:46:58.281020  3078 solver.cpp:218] Iteration 34600 (23.5858 iter/s, 8.47966s/200 iters), loss = 0.653767
I1130 10:46:58.281085  3078 solver.cpp:237]     Train net output #0: loss = 0.653767 (* 1 = 0.653767 loss)
I1130 10:46:58.281091  3078 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I1130 10:47:06.723577  3078 solver.cpp:218] Iteration 34800 (23.6895 iter/s, 8.44255s/200 iters), loss = 0.505946
I1130 10:47:06.723623  3078 solver.cpp:237]     Train net output #0: loss = 0.505946 (* 1 = 0.505946 loss)
I1130 10:47:06.723628  3078 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I1130 10:47:14.948350  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:47:15.081176  3078 solver.cpp:330] Iteration 35000, Testing net (#0)
I1130 10:47:15.879169  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:47:15.911026  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7384
I1130 10:47:15.911135  3078 solver.cpp:397]     Test net output #1: loss = 0.753529 (* 1 = 0.753529 loss)
I1130 10:47:15.953476  3078 solver.cpp:218] Iteration 35000 (21.6687 iter/s, 9.22991s/200 iters), loss = 0.51594
I1130 10:47:15.953536  3078 solver.cpp:237]     Train net output #0: loss = 0.51594 (* 1 = 0.51594 loss)
I1130 10:47:15.953541  3078 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I1130 10:47:24.392534  3078 solver.cpp:218] Iteration 35200 (23.6993 iter/s, 8.43906s/200 iters), loss = 0.544903
I1130 10:47:24.392714  3078 solver.cpp:237]     Train net output #0: loss = 0.544903 (* 1 = 0.544903 loss)
I1130 10:47:24.392720  3078 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I1130 10:47:32.841264  3078 solver.cpp:218] Iteration 35400 (23.6725 iter/s, 8.44861s/200 iters), loss = 0.564014
I1130 10:47:32.841308  3078 solver.cpp:237]     Train net output #0: loss = 0.564014 (* 1 = 0.564014 loss)
I1130 10:47:32.841313  3078 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I1130 10:47:36.860066  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:47:41.296794  3078 solver.cpp:218] Iteration 35600 (23.6531 iter/s, 8.45554s/200 iters), loss = 0.64847
I1130 10:47:41.296839  3078 solver.cpp:237]     Train net output #0: loss = 0.64847 (* 1 = 0.64847 loss)
I1130 10:47:41.296844  3078 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I1130 10:47:49.727916  3078 solver.cpp:218] Iteration 35800 (23.7216 iter/s, 8.43113s/200 iters), loss = 0.503981
I1130 10:47:49.727960  3078 solver.cpp:237]     Train net output #0: loss = 0.503981 (* 1 = 0.503981 loss)
I1130 10:47:49.727965  3078 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I1130 10:47:57.951159  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:47:58.084978  3078 solver.cpp:330] Iteration 36000, Testing net (#0)
I1130 10:47:58.902364  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:47:58.917870  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7382
I1130 10:47:58.918036  3078 solver.cpp:397]     Test net output #1: loss = 0.752637 (* 1 = 0.752637 loss)
I1130 10:47:58.960556  3078 solver.cpp:218] Iteration 36000 (21.6623 iter/s, 9.23265s/200 iters), loss = 0.513603
I1130 10:47:58.960614  3078 solver.cpp:237]     Train net output #0: loss = 0.513603 (* 1 = 0.513603 loss)
I1130 10:47:58.960620  3078 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I1130 10:48:07.409207  3078 solver.cpp:218] Iteration 36200 (23.6724 iter/s, 8.44865s/200 iters), loss = 0.540717
I1130 10:48:07.409252  3078 solver.cpp:237]     Train net output #0: loss = 0.540717 (* 1 = 0.540717 loss)
I1130 10:48:07.409256  3078 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I1130 10:48:15.845027  3078 solver.cpp:218] Iteration 36400 (23.7084 iter/s, 8.43583s/200 iters), loss = 0.560299
I1130 10:48:15.845072  3078 solver.cpp:237]     Train net output #0: loss = 0.560299 (* 1 = 0.560299 loss)
I1130 10:48:15.845077  3078 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I1130 10:48:19.850198  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:48:24.279407  3078 solver.cpp:218] Iteration 36600 (23.7124 iter/s, 8.43439s/200 iters), loss = 0.644622
I1130 10:48:24.279451  3078 solver.cpp:237]     Train net output #0: loss = 0.644622 (* 1 = 0.644622 loss)
I1130 10:48:24.279455  3078 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I1130 10:48:32.721439  3078 solver.cpp:218] Iteration 36800 (23.6909 iter/s, 8.44204s/200 iters), loss = 0.500182
I1130 10:48:32.721485  3078 solver.cpp:237]     Train net output #0: loss = 0.500182 (* 1 = 0.500182 loss)
I1130 10:48:32.721490  3078 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I1130 10:48:40.947041  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:48:41.079947  3078 solver.cpp:330] Iteration 37000, Testing net (#0)
I1130 10:48:41.888272  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:48:41.911947  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7388
I1130 10:48:41.911995  3078 solver.cpp:397]     Test net output #1: loss = 0.751405 (* 1 = 0.751405 loss)
I1130 10:48:41.954495  3078 solver.cpp:218] Iteration 37000 (21.6613 iter/s, 9.23307s/200 iters), loss = 0.510231
I1130 10:48:41.954535  3078 solver.cpp:237]     Train net output #0: loss = 0.510231 (* 1 = 0.510231 loss)
I1130 10:48:41.954541  3078 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I1130 10:48:50.387264  3078 solver.cpp:218] Iteration 37200 (23.717 iter/s, 8.43279s/200 iters), loss = 0.535949
I1130 10:48:50.387310  3078 solver.cpp:237]     Train net output #0: loss = 0.535949 (* 1 = 0.535949 loss)
I1130 10:48:50.387315  3078 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I1130 10:48:58.826820  3078 solver.cpp:218] Iteration 37400 (23.6979 iter/s, 8.43957s/200 iters), loss = 0.555489
I1130 10:48:58.826865  3078 solver.cpp:237]     Train net output #0: loss = 0.555489 (* 1 = 0.555489 loss)
I1130 10:48:58.826870  3078 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I1130 10:49:02.827853  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:49:07.249547  3078 solver.cpp:218] Iteration 37600 (23.7452 iter/s, 8.42274s/200 iters), loss = 0.638024
I1130 10:49:07.249593  3078 solver.cpp:237]     Train net output #0: loss = 0.638024 (* 1 = 0.638024 loss)
I1130 10:49:07.249598  3078 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I1130 10:49:15.674114  3078 solver.cpp:218] Iteration 37800 (23.7401 iter/s, 8.42458s/200 iters), loss = 0.498537
I1130 10:49:15.674157  3078 solver.cpp:237]     Train net output #0: loss = 0.498537 (* 1 = 0.498537 loss)
I1130 10:49:15.674162  3078 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I1130 10:49:23.894629  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:49:24.027616  3078 solver.cpp:330] Iteration 38000, Testing net (#0)
I1130 10:49:24.836393  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:49:24.859704  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7384
I1130 10:49:24.859742  3078 solver.cpp:397]     Test net output #1: loss = 0.753005 (* 1 = 0.753005 loss)
I1130 10:49:24.901952  3078 solver.cpp:218] Iteration 38000 (21.6735 iter/s, 9.22787s/200 iters), loss = 0.509594
I1130 10:49:24.902004  3078 solver.cpp:237]     Train net output #0: loss = 0.509594 (* 1 = 0.509594 loss)
I1130 10:49:24.902009  3078 sgd_solver.cpp:105] Iteration 38000, lr = 0.001
I1130 10:49:33.340694  3078 solver.cpp:218] Iteration 38200 (23.7002 iter/s, 8.43875s/200 iters), loss = 0.533034
I1130 10:49:33.340817  3078 solver.cpp:237]     Train net output #0: loss = 0.533034 (* 1 = 0.533034 loss)
I1130 10:49:33.340823  3078 sgd_solver.cpp:105] Iteration 38200, lr = 0.001
I1130 10:49:41.793418  3078 solver.cpp:218] Iteration 38400 (23.6612 iter/s, 8.45267s/200 iters), loss = 0.549212
I1130 10:49:41.793447  3078 solver.cpp:237]     Train net output #0: loss = 0.549212 (* 1 = 0.549212 loss)
I1130 10:49:41.793469  3078 sgd_solver.cpp:105] Iteration 38400, lr = 0.001
I1130 10:49:45.802413  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:49:50.232401  3078 solver.cpp:218] Iteration 38600 (23.6995 iter/s, 8.43901s/200 iters), loss = 0.633255
I1130 10:49:50.232446  3078 solver.cpp:237]     Train net output #0: loss = 0.633255 (* 1 = 0.633255 loss)
I1130 10:49:50.232451  3078 sgd_solver.cpp:105] Iteration 38600, lr = 0.001
I1130 10:49:58.671937  3078 solver.cpp:218] Iteration 38800 (23.6979 iter/s, 8.43955s/200 iters), loss = 0.496896
I1130 10:49:58.671983  3078 solver.cpp:237]     Train net output #0: loss = 0.496896 (* 1 = 0.496896 loss)
I1130 10:49:58.671988  3078 sgd_solver.cpp:105] Iteration 38800, lr = 0.001
I1130 10:50:06.911298  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:50:07.045594  3078 solver.cpp:330] Iteration 39000, Testing net (#0)
I1130 10:50:07.853826  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:50:07.876991  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7379
I1130 10:50:07.877010  3078 solver.cpp:397]     Test net output #1: loss = 0.755585 (* 1 = 0.755585 loss)
I1130 10:50:07.919303  3078 solver.cpp:218] Iteration 39000 (21.6277 iter/s, 9.2474s/200 iters), loss = 0.511735
I1130 10:50:07.919355  3078 solver.cpp:237]     Train net output #0: loss = 0.511735 (* 1 = 0.511735 loss)
I1130 10:50:07.919361  3078 sgd_solver.cpp:105] Iteration 39000, lr = 0.001
I1130 10:50:16.377503  3078 solver.cpp:218] Iteration 39200 (23.6457 iter/s, 8.45821s/200 iters), loss = 0.529583
I1130 10:50:16.377549  3078 solver.cpp:237]     Train net output #0: loss = 0.529583 (* 1 = 0.529583 loss)
I1130 10:50:16.377553  3078 sgd_solver.cpp:105] Iteration 39200, lr = 0.001
I1130 10:50:24.829725  3078 solver.cpp:218] Iteration 39400 (23.6624 iter/s, 8.45223s/200 iters), loss = 0.544428
I1130 10:50:24.829769  3078 solver.cpp:237]     Train net output #0: loss = 0.544428 (* 1 = 0.544428 loss)
I1130 10:50:24.829774  3078 sgd_solver.cpp:105] Iteration 39400, lr = 0.001
I1130 10:50:28.839296  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:50:33.275336  3078 solver.cpp:218] Iteration 39600 (23.6809 iter/s, 8.44562s/200 iters), loss = 0.627974
I1130 10:50:33.275382  3078 solver.cpp:237]     Train net output #0: loss = 0.627974 (* 1 = 0.627974 loss)
I1130 10:50:33.275385  3078 sgd_solver.cpp:105] Iteration 39600, lr = 0.001
I1130 10:50:41.726456  3078 solver.cpp:218] Iteration 39800 (23.6655 iter/s, 8.45113s/200 iters), loss = 0.494827
I1130 10:50:41.726585  3078 solver.cpp:237]     Train net output #0: loss = 0.494827 (* 1 = 0.494827 loss)
I1130 10:50:41.726603  3078 sgd_solver.cpp:105] Iteration 39800, lr = 0.001
I1130 10:50:49.968516  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:50:50.102488  3078 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_40000.caffemodel
I1130 10:50:50.137363  3078 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_40000.solverstate
I1130 10:50:50.137889  3078 solver.cpp:330] Iteration 40000, Testing net (#0)
I1130 10:50:50.903739  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:50:50.936038  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7386
I1130 10:50:50.936142  3078 solver.cpp:397]     Test net output #1: loss = 0.755094 (* 1 = 0.755094 loss)
I1130 10:50:50.978746  3078 solver.cpp:218] Iteration 40000 (21.6164 iter/s, 9.25221s/200 iters), loss = 0.514329
I1130 10:50:50.978806  3078 solver.cpp:237]     Train net output #0: loss = 0.514329 (* 1 = 0.514329 loss)
I1130 10:50:50.978811  3078 sgd_solver.cpp:105] Iteration 40000, lr = 0.001
I1130 10:50:59.424161  3078 solver.cpp:218] Iteration 40200 (23.6815 iter/s, 8.44541s/200 iters), loss = 0.528043
I1130 10:50:59.424204  3078 solver.cpp:237]     Train net output #0: loss = 0.528043 (* 1 = 0.528043 loss)
I1130 10:50:59.424208  3078 sgd_solver.cpp:105] Iteration 40200, lr = 0.001
I1130 10:51:07.843545  3078 solver.cpp:218] Iteration 40400 (23.7547 iter/s, 8.4194s/200 iters), loss = 0.535324
I1130 10:51:07.843590  3078 solver.cpp:237]     Train net output #0: loss = 0.535324 (* 1 = 0.535324 loss)
I1130 10:51:07.843595  3078 sgd_solver.cpp:105] Iteration 40400, lr = 0.001
I1130 10:51:11.848661  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:51:16.276348  3078 solver.cpp:218] Iteration 40600 (23.7169 iter/s, 8.43281s/200 iters), loss = 0.623225
I1130 10:51:16.276393  3078 solver.cpp:237]     Train net output #0: loss = 0.623225 (* 1 = 0.623225 loss)
I1130 10:51:16.276398  3078 sgd_solver.cpp:105] Iteration 40600, lr = 0.001
I1130 10:51:24.709589  3078 solver.cpp:218] Iteration 40800 (23.7156 iter/s, 8.43325s/200 iters), loss = 0.491704
I1130 10:51:24.709633  3078 solver.cpp:237]     Train net output #0: loss = 0.491704 (* 1 = 0.491704 loss)
I1130 10:51:24.709638  3078 sgd_solver.cpp:105] Iteration 40800, lr = 0.001
I1130 10:51:32.928612  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:51:33.062547  3078 solver.cpp:330] Iteration 41000, Testing net (#0)
I1130 10:51:33.872675  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:51:33.896126  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7382
I1130 10:51:33.896167  3078 solver.cpp:397]     Test net output #1: loss = 0.75702 (* 1 = 0.75702 loss)
I1130 10:51:33.938480  3078 solver.cpp:218] Iteration 41000 (21.671 iter/s, 9.22891s/200 iters), loss = 0.517521
I1130 10:51:33.938519  3078 solver.cpp:237]     Train net output #0: loss = 0.517521 (* 1 = 0.517521 loss)
I1130 10:51:33.938524  3078 sgd_solver.cpp:105] Iteration 41000, lr = 0.001
I1130 10:51:42.367744  3078 solver.cpp:218] Iteration 41200 (23.7268 iter/s, 8.42928s/200 iters), loss = 0.526051
I1130 10:51:42.367787  3078 solver.cpp:237]     Train net output #0: loss = 0.526051 (* 1 = 0.526051 loss)
I1130 10:51:42.367792  3078 sgd_solver.cpp:105] Iteration 41200, lr = 0.001
I1130 10:51:50.805613  3078 solver.cpp:218] Iteration 41400 (23.7026 iter/s, 8.43788s/200 iters), loss = 0.530553
I1130 10:51:50.805658  3078 solver.cpp:237]     Train net output #0: loss = 0.530553 (* 1 = 0.530553 loss)
I1130 10:51:50.805663  3078 sgd_solver.cpp:105] Iteration 41400, lr = 0.001
I1130 10:51:54.818218  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:51:59.242856  3078 solver.cpp:218] Iteration 41600 (23.7044 iter/s, 8.43725s/200 iters), loss = 0.61836
I1130 10:51:59.242902  3078 solver.cpp:237]     Train net output #0: loss = 0.61836 (* 1 = 0.61836 loss)
I1130 10:51:59.242907  3078 sgd_solver.cpp:105] Iteration 41600, lr = 0.001
I1130 10:52:07.671223  3078 solver.cpp:218] Iteration 41800 (23.7294 iter/s, 8.42838s/200 iters), loss = 0.488829
I1130 10:52:07.671267  3078 solver.cpp:237]     Train net output #0: loss = 0.488829 (* 1 = 0.488829 loss)
I1130 10:52:07.671272  3078 sgd_solver.cpp:105] Iteration 41800, lr = 0.001
I1130 10:52:15.907003  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:52:16.033432  3078 solver.cpp:330] Iteration 42000, Testing net (#0)
I1130 10:52:16.853209  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:52:16.868602  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7394
I1130 10:52:16.868640  3078 solver.cpp:397]     Test net output #1: loss = 0.757371 (* 1 = 0.757371 loss)
I1130 10:52:16.911027  3078 solver.cpp:218] Iteration 42000 (21.6455 iter/s, 9.23981s/200 iters), loss = 0.514568
I1130 10:52:16.911092  3078 solver.cpp:237]     Train net output #0: loss = 0.514568 (* 1 = 0.514568 loss)
I1130 10:52:16.911098  3078 sgd_solver.cpp:105] Iteration 42000, lr = 0.001
I1130 10:52:25.340785  3078 solver.cpp:218] Iteration 42200 (23.7255 iter/s, 8.42975s/200 iters), loss = 0.52341
I1130 10:52:25.340812  3078 solver.cpp:237]     Train net output #0: loss = 0.52341 (* 1 = 0.52341 loss)
I1130 10:52:25.340816  3078 sgd_solver.cpp:105] Iteration 42200, lr = 0.001
I1130 10:52:33.773360  3078 solver.cpp:218] Iteration 42400 (23.7175 iter/s, 8.4326s/200 iters), loss = 0.528449
I1130 10:52:33.773386  3078 solver.cpp:237]     Train net output #0: loss = 0.528449 (* 1 = 0.528449 loss)
I1130 10:52:33.773391  3078 sgd_solver.cpp:105] Iteration 42400, lr = 0.001
I1130 10:52:37.783092  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:52:42.208695  3078 solver.cpp:218] Iteration 42600 (23.7097 iter/s, 8.43536s/200 iters), loss = 0.614405
I1130 10:52:42.208750  3078 solver.cpp:237]     Train net output #0: loss = 0.614405 (* 1 = 0.614405 loss)
I1130 10:52:42.208755  3078 sgd_solver.cpp:105] Iteration 42600, lr = 0.001
I1130 10:52:50.637533  3078 solver.cpp:218] Iteration 42800 (23.7281 iter/s, 8.42884s/200 iters), loss = 0.48438
I1130 10:52:50.637630  3078 solver.cpp:237]     Train net output #0: loss = 0.48438 (* 1 = 0.48438 loss)
I1130 10:52:50.637652  3078 sgd_solver.cpp:105] Iteration 42800, lr = 0.001
I1130 10:52:58.844449  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:52:58.978132  3078 solver.cpp:330] Iteration 43000, Testing net (#0)
I1130 10:52:59.777895  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:52:59.808933  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7396
I1130 10:52:59.808982  3078 solver.cpp:397]     Test net output #1: loss = 0.756936 (* 1 = 0.756936 loss)
I1130 10:52:59.851078  3078 solver.cpp:218] Iteration 43000 (21.7073 iter/s, 9.2135s/200 iters), loss = 0.510783
I1130 10:52:59.851141  3078 solver.cpp:237]     Train net output #0: loss = 0.510783 (* 1 = 0.510783 loss)
I1130 10:52:59.851148  3078 sgd_solver.cpp:105] Iteration 43000, lr = 0.001
I1130 10:53:08.266419  3078 solver.cpp:218] Iteration 43200 (23.7661 iter/s, 8.41533s/200 iters), loss = 0.523181
I1130 10:53:08.266445  3078 solver.cpp:237]     Train net output #0: loss = 0.523181 (* 1 = 0.523181 loss)
I1130 10:53:08.266469  3078 sgd_solver.cpp:105] Iteration 43200, lr = 0.001
I1130 10:53:16.698312  3078 solver.cpp:218] Iteration 43400 (23.7194 iter/s, 8.43192s/200 iters), loss = 0.523972
I1130 10:53:16.698357  3078 solver.cpp:237]     Train net output #0: loss = 0.523972 (* 1 = 0.523972 loss)
I1130 10:53:16.698361  3078 sgd_solver.cpp:105] Iteration 43400, lr = 0.001
I1130 10:53:20.713135  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:53:25.137686  3078 solver.cpp:218] Iteration 43600 (23.6984 iter/s, 8.43938s/200 iters), loss = 0.610115
I1130 10:53:25.137732  3078 solver.cpp:237]     Train net output #0: loss = 0.610115 (* 1 = 0.610115 loss)
I1130 10:53:25.137737  3078 sgd_solver.cpp:105] Iteration 43600, lr = 0.001
I1130 10:53:33.567001  3078 solver.cpp:218] Iteration 43800 (23.7267 iter/s, 8.42933s/200 iters), loss = 0.48114
I1130 10:53:33.567047  3078 solver.cpp:237]     Train net output #0: loss = 0.48114 (* 1 = 0.48114 loss)
I1130 10:53:33.567052  3078 sgd_solver.cpp:105] Iteration 43800, lr = 0.001
I1130 10:53:41.786527  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:53:41.920269  3078 solver.cpp:330] Iteration 44000, Testing net (#0)
I1130 10:53:42.733386  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:53:42.757410  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7396
I1130 10:53:42.757455  3078 solver.cpp:397]     Test net output #1: loss = 0.756935 (* 1 = 0.756935 loss)
I1130 10:53:42.799978  3078 solver.cpp:218] Iteration 44000 (21.6615 iter/s, 9.23299s/200 iters), loss = 0.508691
I1130 10:53:42.800034  3078 solver.cpp:237]     Train net output #0: loss = 0.508691 (* 1 = 0.508691 loss)
I1130 10:53:42.800040  3078 sgd_solver.cpp:105] Iteration 44000, lr = 0.001
I1130 10:53:51.242023  3078 solver.cpp:218] Iteration 44200 (23.6909 iter/s, 8.44205s/200 iters), loss = 0.519338
I1130 10:53:51.242175  3078 solver.cpp:237]     Train net output #0: loss = 0.519338 (* 1 = 0.519338 loss)
I1130 10:53:51.242194  3078 sgd_solver.cpp:105] Iteration 44200, lr = 0.001
I1130 10:53:59.685827  3078 solver.cpp:218] Iteration 44400 (23.6863 iter/s, 8.44371s/200 iters), loss = 0.518312
I1130 10:53:59.685873  3078 solver.cpp:237]     Train net output #0: loss = 0.518312 (* 1 = 0.518312 loss)
I1130 10:53:59.685878  3078 sgd_solver.cpp:105] Iteration 44400, lr = 0.001
I1130 10:54:03.698503  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:54:08.129142  3078 solver.cpp:218] Iteration 44600 (23.6874 iter/s, 8.44332s/200 iters), loss = 0.605504
I1130 10:54:08.129185  3078 solver.cpp:237]     Train net output #0: loss = 0.605504 (* 1 = 0.605504 loss)
I1130 10:54:08.129190  3078 sgd_solver.cpp:105] Iteration 44600, lr = 0.001
I1130 10:54:16.567936  3078 solver.cpp:218] Iteration 44800 (23.7 iter/s, 8.43881s/200 iters), loss = 0.480375
I1130 10:54:16.567981  3078 solver.cpp:237]     Train net output #0: loss = 0.480375 (* 1 = 0.480375 loss)
I1130 10:54:16.567986  3078 sgd_solver.cpp:105] Iteration 44800, lr = 0.001
I1130 10:54:24.796591  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:54:24.929306  3078 solver.cpp:330] Iteration 45000, Testing net (#0)
I1130 10:54:25.738229  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:54:25.761617  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7403
I1130 10:54:25.761659  3078 solver.cpp:397]     Test net output #1: loss = 0.756788 (* 1 = 0.756788 loss)
I1130 10:54:25.803997  3078 solver.cpp:218] Iteration 45000 (21.6542 iter/s, 9.23608s/200 iters), loss = 0.504322
I1130 10:54:25.804045  3078 solver.cpp:237]     Train net output #0: loss = 0.504322 (* 1 = 0.504322 loss)
I1130 10:54:25.804051  3078 sgd_solver.cpp:105] Iteration 45000, lr = 0.001
I1130 10:54:34.219616  3078 solver.cpp:218] Iteration 45200 (23.7653 iter/s, 8.41562s/200 iters), loss = 0.51712
I1130 10:54:34.219660  3078 solver.cpp:237]     Train net output #0: loss = 0.51712 (* 1 = 0.51712 loss)
I1130 10:54:34.219666  3078 sgd_solver.cpp:105] Iteration 45200, lr = 0.001
I1130 10:54:42.638073  3078 solver.cpp:218] Iteration 45400 (23.7572 iter/s, 8.41849s/200 iters), loss = 0.515703
I1130 10:54:42.638118  3078 solver.cpp:237]     Train net output #0: loss = 0.515703 (* 1 = 0.515703 loss)
I1130 10:54:42.638123  3078 sgd_solver.cpp:105] Iteration 45400, lr = 0.001
I1130 10:54:46.638377  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:54:51.058149  3078 solver.cpp:218] Iteration 45600 (23.7527 iter/s, 8.42009s/200 iters), loss = 0.603669
I1130 10:54:51.058193  3078 solver.cpp:237]     Train net output #0: loss = 0.603669 (* 1 = 0.603669 loss)
I1130 10:54:51.058198  3078 sgd_solver.cpp:105] Iteration 45600, lr = 0.001
I1130 10:54:59.477285  3078 solver.cpp:218] Iteration 45800 (23.7554 iter/s, 8.41915s/200 iters), loss = 0.482035
I1130 10:54:59.477502  3078 solver.cpp:237]     Train net output #0: loss = 0.482035 (* 1 = 0.482035 loss)
I1130 10:54:59.477509  3078 sgd_solver.cpp:105] Iteration 45800, lr = 0.001
I1130 10:55:07.701197  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:55:07.834468  3078 solver.cpp:330] Iteration 46000, Testing net (#0)
I1130 10:55:08.655339  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:55:08.670553  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7386
I1130 10:55:08.670601  3078 solver.cpp:397]     Test net output #1: loss = 0.75898 (* 1 = 0.75898 loss)
I1130 10:55:08.713109  3078 solver.cpp:218] Iteration 46000 (21.6552 iter/s, 9.23566s/200 iters), loss = 0.502795
I1130 10:55:08.713167  3078 solver.cpp:237]     Train net output #0: loss = 0.502795 (* 1 = 0.502795 loss)
I1130 10:55:08.713192  3078 sgd_solver.cpp:105] Iteration 46000, lr = 0.001
I1130 10:55:17.156533  3078 solver.cpp:218] Iteration 46200 (23.6871 iter/s, 8.44342s/200 iters), loss = 0.515473
I1130 10:55:17.156579  3078 solver.cpp:237]     Train net output #0: loss = 0.515473 (* 1 = 0.515473 loss)
I1130 10:55:17.156582  3078 sgd_solver.cpp:105] Iteration 46200, lr = 0.001
I1130 10:55:25.610587  3078 solver.cpp:218] Iteration 46400 (23.6573 iter/s, 8.45406s/200 iters), loss = 0.511703
I1130 10:55:25.610636  3078 solver.cpp:237]     Train net output #0: loss = 0.511703 (* 1 = 0.511703 loss)
I1130 10:55:25.610641  3078 sgd_solver.cpp:105] Iteration 46400, lr = 0.001
I1130 10:55:29.626648  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:55:34.051367  3078 solver.cpp:218] Iteration 46600 (23.6945 iter/s, 8.44078s/200 iters), loss = 0.596992
I1130 10:55:34.051411  3078 solver.cpp:237]     Train net output #0: loss = 0.596992 (* 1 = 0.596992 loss)
I1130 10:55:34.051416  3078 sgd_solver.cpp:105] Iteration 46600, lr = 0.001
I1130 10:55:42.485569  3078 solver.cpp:218] Iteration 46800 (23.7129 iter/s, 8.43421s/200 iters), loss = 0.481005
I1130 10:55:42.485615  3078 solver.cpp:237]     Train net output #0: loss = 0.481005 (* 1 = 0.481005 loss)
I1130 10:55:42.485618  3078 sgd_solver.cpp:105] Iteration 46800, lr = 0.001
I1130 10:55:50.708668  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:55:50.842612  3078 solver.cpp:330] Iteration 47000, Testing net (#0)
I1130 10:55:51.651938  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:55:51.675137  3078 solver.cpp:397]     Test net output #0: accuracy = 0.739
I1130 10:55:51.675181  3078 solver.cpp:397]     Test net output #1: loss = 0.761308 (* 1 = 0.761308 loss)
I1130 10:55:51.717900  3078 solver.cpp:218] Iteration 47000 (21.663 iter/s, 9.23235s/200 iters), loss = 0.502128
I1130 10:55:51.717931  3078 solver.cpp:237]     Train net output #0: loss = 0.502128 (* 1 = 0.502128 loss)
I1130 10:55:51.717938  3078 sgd_solver.cpp:105] Iteration 47000, lr = 0.001
I1130 10:56:00.151705  3078 solver.cpp:218] Iteration 47200 (23.714 iter/s, 8.43383s/200 iters), loss = 0.517203
I1130 10:56:00.151865  3078 solver.cpp:237]     Train net output #0: loss = 0.517203 (* 1 = 0.517203 loss)
I1130 10:56:00.151872  3078 sgd_solver.cpp:105] Iteration 47200, lr = 0.001
I1130 10:56:08.583825  3078 solver.cpp:218] Iteration 47400 (23.7191 iter/s, 8.43203s/200 iters), loss = 0.507176
I1130 10:56:08.583874  3078 solver.cpp:237]     Train net output #0: loss = 0.507176 (* 1 = 0.507176 loss)
I1130 10:56:08.583879  3078 sgd_solver.cpp:105] Iteration 47400, lr = 0.001
I1130 10:56:12.593225  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:56:17.020732  3078 solver.cpp:218] Iteration 47600 (23.7054 iter/s, 8.43691s/200 iters), loss = 0.59465
I1130 10:56:17.020787  3078 solver.cpp:237]     Train net output #0: loss = 0.59465 (* 1 = 0.59465 loss)
I1130 10:56:17.020792  3078 sgd_solver.cpp:105] Iteration 47600, lr = 0.001
I1130 10:56:25.449926  3078 solver.cpp:218] Iteration 47800 (23.7271 iter/s, 8.4292s/200 iters), loss = 0.475875
I1130 10:56:25.449970  3078 solver.cpp:237]     Train net output #0: loss = 0.475875 (* 1 = 0.475875 loss)
I1130 10:56:25.449975  3078 sgd_solver.cpp:105] Iteration 47800, lr = 0.001
I1130 10:56:33.670444  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:56:33.803387  3078 solver.cpp:330] Iteration 48000, Testing net (#0)
I1130 10:56:34.604641  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:56:34.636029  3078 solver.cpp:397]     Test net output #0: accuracy = 0.738
I1130 10:56:34.636085  3078 solver.cpp:397]     Test net output #1: loss = 0.763058 (* 1 = 0.763058 loss)
I1130 10:56:34.678377  3078 solver.cpp:218] Iteration 48000 (21.6721 iter/s, 9.22846s/200 iters), loss = 0.500265
I1130 10:56:34.678462  3078 solver.cpp:237]     Train net output #0: loss = 0.500265 (* 1 = 0.500265 loss)
I1130 10:56:34.678468  3078 sgd_solver.cpp:105] Iteration 48000, lr = 0.001
I1130 10:56:43.129657  3078 solver.cpp:218] Iteration 48200 (23.6651 iter/s, 8.45125s/200 iters), loss = 0.518743
I1130 10:56:43.129701  3078 solver.cpp:237]     Train net output #0: loss = 0.518743 (* 1 = 0.518743 loss)
I1130 10:56:43.129707  3078 sgd_solver.cpp:105] Iteration 48200, lr = 0.001
I1130 10:56:51.585602  3078 solver.cpp:218] Iteration 48400 (23.6519 iter/s, 8.45597s/200 iters), loss = 0.504815
I1130 10:56:51.585652  3078 solver.cpp:237]     Train net output #0: loss = 0.504815 (* 1 = 0.504815 loss)
I1130 10:56:51.585657  3078 sgd_solver.cpp:105] Iteration 48400, lr = 0.001
I1130 10:56:55.594511  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:57:00.020164  3078 solver.cpp:218] Iteration 48600 (23.712 iter/s, 8.43457s/200 iters), loss = 0.591771
I1130 10:57:00.020208  3078 solver.cpp:237]     Train net output #0: loss = 0.591771 (* 1 = 0.591771 loss)
I1130 10:57:00.020212  3078 sgd_solver.cpp:105] Iteration 48600, lr = 0.001
I1130 10:57:08.474411  3078 solver.cpp:218] Iteration 48800 (23.6567 iter/s, 8.45426s/200 iters), loss = 0.475886
I1130 10:57:08.474503  3078 solver.cpp:237]     Train net output #0: loss = 0.475886 (* 1 = 0.475886 loss)
I1130 10:57:08.474527  3078 sgd_solver.cpp:105] Iteration 48800, lr = 0.001
I1130 10:57:16.696339  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:57:16.829799  3078 solver.cpp:330] Iteration 49000, Testing net (#0)
I1130 10:57:17.648463  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:57:17.663590  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7375
I1130 10:57:17.663615  3078 solver.cpp:397]     Test net output #1: loss = 0.764388 (* 1 = 0.764388 loss)
I1130 10:57:17.705798  3078 solver.cpp:218] Iteration 49000 (21.6653 iter/s, 9.23136s/200 iters), loss = 0.496206
I1130 10:57:17.705855  3078 solver.cpp:237]     Train net output #0: loss = 0.496206 (* 1 = 0.496206 loss)
I1130 10:57:17.705862  3078 sgd_solver.cpp:105] Iteration 49000, lr = 0.001
I1130 10:57:26.128701  3078 solver.cpp:218] Iteration 49200 (23.7448 iter/s, 8.4229s/200 iters), loss = 0.517712
I1130 10:57:26.128744  3078 solver.cpp:237]     Train net output #0: loss = 0.517712 (* 1 = 0.517712 loss)
I1130 10:57:26.128749  3078 sgd_solver.cpp:105] Iteration 49200, lr = 0.001
I1130 10:57:34.551138  3078 solver.cpp:218] Iteration 49400 (23.7461 iter/s, 8.42245s/200 iters), loss = 0.501942
I1130 10:57:34.551188  3078 solver.cpp:237]     Train net output #0: loss = 0.501942 (* 1 = 0.501942 loss)
I1130 10:57:34.551193  3078 sgd_solver.cpp:105] Iteration 49400, lr = 0.001
I1130 10:57:38.554340  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:57:42.972559  3078 solver.cpp:218] Iteration 49600 (23.749 iter/s, 8.42142s/200 iters), loss = 0.592293
I1130 10:57:42.972589  3078 solver.cpp:237]     Train net output #0: loss = 0.592293 (* 1 = 0.592293 loss)
I1130 10:57:42.972592  3078 sgd_solver.cpp:105] Iteration 49600, lr = 0.001
I1130 10:57:51.395601  3078 solver.cpp:218] Iteration 49800 (23.7443 iter/s, 8.42306s/200 iters), loss = 0.47237
I1130 10:57:51.395627  3078 solver.cpp:237]     Train net output #0: loss = 0.47237 (* 1 = 0.47237 loss)
I1130 10:57:51.395630  3078 sgd_solver.cpp:105] Iteration 49800, lr = 0.001
I1130 10:57:59.612185  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:57:59.744729  3078 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_50000.caffemodel
I1130 10:57:59.779331  3078 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_50000.solverstate
I1130 10:57:59.779881  3078 solver.cpp:330] Iteration 50000, Testing net (#0)
I1130 10:58:00.568986  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:58:00.584383  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7371
I1130 10:58:00.584425  3078 solver.cpp:397]     Test net output #1: loss = 0.763704 (* 1 = 0.763704 loss)
I1130 10:58:00.626768  3078 solver.cpp:218] Iteration 50000 (21.6657 iter/s, 9.23119s/200 iters), loss = 0.493333
I1130 10:58:00.626828  3078 solver.cpp:237]     Train net output #0: loss = 0.493333 (* 1 = 0.493333 loss)
I1130 10:58:00.626834  3078 sgd_solver.cpp:105] Iteration 50000, lr = 0.001
I1130 10:58:09.050731  3078 solver.cpp:218] Iteration 50200 (23.7418 iter/s, 8.42396s/200 iters), loss = 0.517756
I1130 10:58:09.050884  3078 solver.cpp:237]     Train net output #0: loss = 0.517756 (* 1 = 0.517756 loss)
I1130 10:58:09.050892  3078 sgd_solver.cpp:105] Iteration 50200, lr = 0.001
I1130 10:58:17.489847  3078 solver.cpp:218] Iteration 50400 (23.6994 iter/s, 8.43904s/200 iters), loss = 0.500841
I1130 10:58:17.489879  3078 solver.cpp:237]     Train net output #0: loss = 0.500841 (* 1 = 0.500841 loss)
I1130 10:58:17.489884  3078 sgd_solver.cpp:105] Iteration 50400, lr = 0.001
I1130 10:58:21.500780  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:58:25.928925  3078 solver.cpp:218] Iteration 50600 (23.6992 iter/s, 8.4391s/200 iters), loss = 0.589779
I1130 10:58:25.928969  3078 solver.cpp:237]     Train net output #0: loss = 0.589779 (* 1 = 0.589779 loss)
I1130 10:58:25.928973  3078 sgd_solver.cpp:105] Iteration 50600, lr = 0.001
I1130 10:58:34.354566  3078 solver.cpp:218] Iteration 50800 (23.737 iter/s, 8.42567s/200 iters), loss = 0.47189
I1130 10:58:34.354610  3078 solver.cpp:237]     Train net output #0: loss = 0.47189 (* 1 = 0.47189 loss)
I1130 10:58:34.354615  3078 sgd_solver.cpp:105] Iteration 50800, lr = 0.001
I1130 10:58:42.606752  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:58:42.727100  3078 solver.cpp:330] Iteration 51000, Testing net (#0)
I1130 10:58:43.528373  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:58:43.560578  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7371
I1130 10:58:43.560631  3078 solver.cpp:397]     Test net output #1: loss = 0.765077 (* 1 = 0.765077 loss)
I1130 10:58:43.603085  3078 solver.cpp:218] Iteration 51000 (21.625 iter/s, 9.24854s/200 iters), loss = 0.492092
I1130 10:58:43.603129  3078 solver.cpp:237]     Train net output #0: loss = 0.492092 (* 1 = 0.492092 loss)
I1130 10:58:43.603135  3078 sgd_solver.cpp:105] Iteration 51000, lr = 0.001
I1130 10:58:52.052006  3078 solver.cpp:218] Iteration 51200 (23.6716 iter/s, 8.44893s/200 iters), loss = 0.518021
I1130 10:58:52.052065  3078 solver.cpp:237]     Train net output #0: loss = 0.518021 (* 1 = 0.518021 loss)
I1130 10:58:52.052073  3078 sgd_solver.cpp:105] Iteration 51200, lr = 0.001
I1130 10:59:00.487359  3078 solver.cpp:218] Iteration 51400 (23.7097 iter/s, 8.43537s/200 iters), loss = 0.496617
I1130 10:59:00.487419  3078 solver.cpp:237]     Train net output #0: loss = 0.496617 (* 1 = 0.496617 loss)
I1130 10:59:00.487424  3078 sgd_solver.cpp:105] Iteration 51400, lr = 0.001
I1130 10:59:04.490749  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:59:08.913053  3078 solver.cpp:218] Iteration 51600 (23.7369 iter/s, 8.42569s/200 iters), loss = 0.584895
I1130 10:59:08.913095  3078 solver.cpp:237]     Train net output #0: loss = 0.584895 (* 1 = 0.584895 loss)
I1130 10:59:08.913100  3078 sgd_solver.cpp:105] Iteration 51600, lr = 0.001
I1130 10:59:17.341924  3078 solver.cpp:218] Iteration 51800 (23.7279 iter/s, 8.42888s/200 iters), loss = 0.468174
I1130 10:59:17.342074  3078 solver.cpp:237]     Train net output #0: loss = 0.468174 (* 1 = 0.468174 loss)
I1130 10:59:17.342082  3078 sgd_solver.cpp:105] Iteration 51800, lr = 0.001
I1130 10:59:25.548403  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:59:25.681531  3078 solver.cpp:330] Iteration 52000, Testing net (#0)
I1130 10:59:26.484549  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:59:26.516132  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7377
I1130 10:59:26.516178  3078 solver.cpp:397]     Test net output #1: loss = 0.764497 (* 1 = 0.764497 loss)
I1130 10:59:26.558389  3078 solver.cpp:218] Iteration 52000 (21.7005 iter/s, 9.21638s/200 iters), loss = 0.487562
I1130 10:59:26.558449  3078 solver.cpp:237]     Train net output #0: loss = 0.487562 (* 1 = 0.487562 loss)
I1130 10:59:26.558473  3078 sgd_solver.cpp:105] Iteration 52000, lr = 0.001
I1130 10:59:34.980569  3078 solver.cpp:218] Iteration 52200 (23.7468 iter/s, 8.42218s/200 iters), loss = 0.51738
I1130 10:59:34.980614  3078 solver.cpp:237]     Train net output #0: loss = 0.51738 (* 1 = 0.51738 loss)
I1130 10:59:34.980619  3078 sgd_solver.cpp:105] Iteration 52200, lr = 0.001
I1130 10:59:43.429270  3078 solver.cpp:218] Iteration 52400 (23.6722 iter/s, 8.44871s/200 iters), loss = 0.494108
I1130 10:59:43.429316  3078 solver.cpp:237]     Train net output #0: loss = 0.494108 (* 1 = 0.494108 loss)
I1130 10:59:43.429321  3078 sgd_solver.cpp:105] Iteration 52400, lr = 0.001
I1130 10:59:47.439023  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 10:59:51.866372  3078 solver.cpp:218] Iteration 52600 (23.7048 iter/s, 8.43711s/200 iters), loss = 0.583926
I1130 10:59:51.866421  3078 solver.cpp:237]     Train net output #0: loss = 0.583926 (* 1 = 0.583926 loss)
I1130 10:59:51.866427  3078 sgd_solver.cpp:105] Iteration 52600, lr = 0.001
I1130 11:00:00.303530  3078 solver.cpp:218] Iteration 52800 (23.7046 iter/s, 8.43717s/200 iters), loss = 0.466652
I1130 11:00:00.303575  3078 solver.cpp:237]     Train net output #0: loss = 0.466652 (* 1 = 0.466652 loss)
I1130 11:00:00.303580  3078 sgd_solver.cpp:105] Iteration 52800, lr = 0.001
I1130 11:00:08.528324  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:00:08.662335  3078 solver.cpp:330] Iteration 53000, Testing net (#0)
I1130 11:00:09.474607  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:00:09.492920  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7384
I1130 11:00:09.492960  3078 solver.cpp:397]     Test net output #1: loss = 0.762178 (* 1 = 0.762178 loss)
I1130 11:00:09.535231  3078 solver.cpp:218] Iteration 53000 (21.6644 iter/s, 9.23172s/200 iters), loss = 0.481414
I1130 11:00:09.535287  3078 solver.cpp:237]     Train net output #0: loss = 0.481414 (* 1 = 0.481414 loss)
I1130 11:00:09.535293  3078 sgd_solver.cpp:105] Iteration 53000, lr = 0.001
I1130 11:00:17.959622  3078 solver.cpp:218] Iteration 53200 (23.7405 iter/s, 8.42441s/200 iters), loss = 0.517164
I1130 11:00:17.959740  3078 solver.cpp:237]     Train net output #0: loss = 0.517164 (* 1 = 0.517164 loss)
I1130 11:00:17.959746  3078 sgd_solver.cpp:105] Iteration 53200, lr = 0.001
I1130 11:00:26.386180  3078 solver.cpp:218] Iteration 53400 (23.7346 iter/s, 8.42651s/200 iters), loss = 0.494361
I1130 11:00:26.386212  3078 solver.cpp:237]     Train net output #0: loss = 0.494361 (* 1 = 0.494361 loss)
I1130 11:00:26.386236  3078 sgd_solver.cpp:105] Iteration 53400, lr = 0.001
I1130 11:00:30.389113  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:00:34.809890  3078 solver.cpp:218] Iteration 53600 (23.7424 iter/s, 8.42373s/200 iters), loss = 0.584337
I1130 11:00:34.809934  3078 solver.cpp:237]     Train net output #0: loss = 0.584337 (* 1 = 0.584337 loss)
I1130 11:00:34.809939  3078 sgd_solver.cpp:105] Iteration 53600, lr = 0.001
I1130 11:00:43.235313  3078 solver.cpp:218] Iteration 53800 (23.7377 iter/s, 8.42543s/200 iters), loss = 0.466931
I1130 11:00:43.235339  3078 solver.cpp:237]     Train net output #0: loss = 0.466931 (* 1 = 0.466931 loss)
I1130 11:00:43.235345  3078 sgd_solver.cpp:105] Iteration 53800, lr = 0.001
I1130 11:00:51.456766  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:00:51.590049  3078 solver.cpp:330] Iteration 54000, Testing net (#0)
I1130 11:00:52.394747  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:00:52.426075  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7376
I1130 11:00:52.426149  3078 solver.cpp:397]     Test net output #1: loss = 0.763224 (* 1 = 0.763224 loss)
I1130 11:00:52.468320  3078 solver.cpp:218] Iteration 54000 (21.6614 iter/s, 9.23303s/200 iters), loss = 0.479752
I1130 11:00:52.468377  3078 solver.cpp:237]     Train net output #0: loss = 0.479752 (* 1 = 0.479752 loss)
I1130 11:00:52.468401  3078 sgd_solver.cpp:105] Iteration 54000, lr = 0.001
I1130 11:01:00.903445  3078 solver.cpp:218] Iteration 54200 (23.7104 iter/s, 8.43513s/200 iters), loss = 0.517361
I1130 11:01:00.903484  3078 solver.cpp:237]     Train net output #0: loss = 0.517361 (* 1 = 0.517361 loss)
I1130 11:01:00.903507  3078 sgd_solver.cpp:105] Iteration 54200, lr = 0.001
I1130 11:01:09.342459  3078 solver.cpp:218] Iteration 54400 (23.6994 iter/s, 8.43902s/200 iters), loss = 0.489341
I1130 11:01:09.342509  3078 solver.cpp:237]     Train net output #0: loss = 0.489341 (* 1 = 0.489341 loss)
I1130 11:01:09.342514  3078 sgd_solver.cpp:105] Iteration 54400, lr = 0.001
I1130 11:01:13.357411  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:01:17.784591  3078 solver.cpp:218] Iteration 54600 (23.6907 iter/s, 8.44214s/200 iters), loss = 0.581184
I1130 11:01:17.784636  3078 solver.cpp:237]     Train net output #0: loss = 0.581184 (* 1 = 0.581184 loss)
I1130 11:01:17.784641  3078 sgd_solver.cpp:105] Iteration 54600, lr = 0.001
I1130 11:01:26.220268  3078 solver.cpp:218] Iteration 54800 (23.7088 iter/s, 8.4357s/200 iters), loss = 0.466337
I1130 11:01:26.220446  3078 solver.cpp:237]     Train net output #0: loss = 0.466337 (* 1 = 0.466337 loss)
I1130 11:01:26.220472  3078 sgd_solver.cpp:105] Iteration 54800, lr = 0.001
I1130 11:01:34.451328  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:01:34.580418  3078 solver.cpp:330] Iteration 55000, Testing net (#0)
I1130 11:01:35.382079  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:01:35.413278  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7378
I1130 11:01:35.413309  3078 solver.cpp:397]     Test net output #1: loss = 0.763741 (* 1 = 0.763741 loss)
I1130 11:01:35.455423  3078 solver.cpp:218] Iteration 55000 (21.6567 iter/s, 9.23501s/200 iters), loss = 0.482595
I1130 11:01:35.455494  3078 solver.cpp:237]     Train net output #0: loss = 0.482595 (* 1 = 0.482595 loss)
I1130 11:01:35.455502  3078 sgd_solver.cpp:105] Iteration 55000, lr = 0.001
I1130 11:01:43.883630  3078 solver.cpp:218] Iteration 55200 (23.7298 iter/s, 8.42821s/200 iters), loss = 0.518733
I1130 11:01:43.883677  3078 solver.cpp:237]     Train net output #0: loss = 0.518733 (* 1 = 0.518733 loss)
I1130 11:01:43.883682  3078 sgd_solver.cpp:105] Iteration 55200, lr = 0.001
I1130 11:01:52.309505  3078 solver.cpp:218] Iteration 55400 (23.7364 iter/s, 8.42588s/200 iters), loss = 0.490654
I1130 11:01:52.309556  3078 solver.cpp:237]     Train net output #0: loss = 0.490654 (* 1 = 0.490654 loss)
I1130 11:01:52.309561  3078 sgd_solver.cpp:105] Iteration 55400, lr = 0.001
I1130 11:01:56.314270  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:02:00.738062  3078 solver.cpp:218] Iteration 55600 (23.7288 iter/s, 8.42856s/200 iters), loss = 0.579299
I1130 11:02:00.738107  3078 solver.cpp:237]     Train net output #0: loss = 0.579299 (* 1 = 0.579299 loss)
I1130 11:02:00.738112  3078 sgd_solver.cpp:105] Iteration 55600, lr = 0.001
I1130 11:02:09.166563  3078 solver.cpp:218] Iteration 55800 (23.729 iter/s, 8.42851s/200 iters), loss = 0.466779
I1130 11:02:09.166609  3078 solver.cpp:237]     Train net output #0: loss = 0.466779 (* 1 = 0.466779 loss)
I1130 11:02:09.166612  3078 sgd_solver.cpp:105] Iteration 55800, lr = 0.001
I1130 11:02:17.385578  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:02:17.518828  3078 solver.cpp:330] Iteration 56000, Testing net (#0)
I1130 11:02:18.320971  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:02:18.352385  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7376
I1130 11:02:18.352488  3078 solver.cpp:397]     Test net output #1: loss = 0.765351 (* 1 = 0.765351 loss)
I1130 11:02:18.394749  3078 solver.cpp:218] Iteration 56000 (21.6727 iter/s, 9.22819s/200 iters), loss = 0.481885
I1130 11:02:18.394809  3078 solver.cpp:237]     Train net output #0: loss = 0.481885 (* 1 = 0.481885 loss)
I1130 11:02:18.394814  3078 sgd_solver.cpp:105] Iteration 56000, lr = 0.001
I1130 11:02:26.821697  3078 solver.cpp:218] Iteration 56200 (23.7334 iter/s, 8.42694s/200 iters), loss = 0.516251
I1130 11:02:26.821753  3078 solver.cpp:237]     Train net output #0: loss = 0.516251 (* 1 = 0.516251 loss)
I1130 11:02:26.821758  3078 sgd_solver.cpp:105] Iteration 56200, lr = 0.001
I1130 11:02:35.259491  3078 solver.cpp:218] Iteration 56400 (23.7029 iter/s, 8.43779s/200 iters), loss = 0.488232
I1130 11:02:35.259538  3078 solver.cpp:237]     Train net output #0: loss = 0.488232 (* 1 = 0.488232 loss)
I1130 11:02:35.259542  3078 sgd_solver.cpp:105] Iteration 56400, lr = 0.001
I1130 11:02:39.270357  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:02:43.694738  3078 solver.cpp:218] Iteration 56600 (23.71 iter/s, 8.43527s/200 iters), loss = 0.574394
I1130 11:02:43.694797  3078 solver.cpp:237]     Train net output #0: loss = 0.574394 (* 1 = 0.574394 loss)
I1130 11:02:43.694802  3078 sgd_solver.cpp:105] Iteration 56600, lr = 0.001
I1130 11:02:52.131018  3078 solver.cpp:218] Iteration 56800 (23.7072 iter/s, 8.43627s/200 iters), loss = 0.466592
I1130 11:02:52.131075  3078 solver.cpp:237]     Train net output #0: loss = 0.466592 (* 1 = 0.466592 loss)
I1130 11:02:52.131081  3078 sgd_solver.cpp:105] Iteration 56800, lr = 0.001
I1130 11:03:00.354915  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:03:00.488880  3078 solver.cpp:330] Iteration 57000, Testing net (#0)
I1130 11:03:01.308545  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:03:01.323926  3078 solver.cpp:397]     Test net output #0: accuracy = 0.736
I1130 11:03:01.323977  3078 solver.cpp:397]     Test net output #1: loss = 0.767478 (* 1 = 0.767478 loss)
I1130 11:03:01.366276  3078 solver.cpp:218] Iteration 57000 (21.6561 iter/s, 9.23525s/200 iters), loss = 0.482274
I1130 11:03:01.366336  3078 solver.cpp:237]     Train net output #0: loss = 0.482274 (* 1 = 0.482274 loss)
I1130 11:03:01.366343  3078 sgd_solver.cpp:105] Iteration 57000, lr = 0.001
I1130 11:03:09.805373  3078 solver.cpp:218] Iteration 57200 (23.6992 iter/s, 8.43909s/200 iters), loss = 0.519184
I1130 11:03:09.805399  3078 solver.cpp:237]     Train net output #0: loss = 0.519184 (* 1 = 0.519184 loss)
I1130 11:03:09.805404  3078 sgd_solver.cpp:105] Iteration 57200, lr = 0.001
I1130 11:03:18.243335  3078 solver.cpp:218] Iteration 57400 (23.7024 iter/s, 8.43798s/200 iters), loss = 0.485674
I1130 11:03:18.243378  3078 solver.cpp:237]     Train net output #0: loss = 0.485674 (* 1 = 0.485674 loss)
I1130 11:03:18.243382  3078 sgd_solver.cpp:105] Iteration 57400, lr = 0.001
I1130 11:03:22.256547  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:03:26.686753  3078 solver.cpp:218] Iteration 57600 (23.6871 iter/s, 8.44343s/200 iters), loss = 0.57124
I1130 11:03:26.686780  3078 solver.cpp:237]     Train net output #0: loss = 0.57124 (* 1 = 0.57124 loss)
I1130 11:03:26.686785  3078 sgd_solver.cpp:105] Iteration 57600, lr = 0.001
I1130 11:03:35.130631  3078 solver.cpp:218] Iteration 57800 (23.6857 iter/s, 8.4439s/200 iters), loss = 0.467085
I1130 11:03:35.130795  3078 solver.cpp:237]     Train net output #0: loss = 0.467085 (* 1 = 0.467085 loss)
I1130 11:03:35.130822  3078 sgd_solver.cpp:105] Iteration 57800, lr = 0.001
I1130 11:03:43.377167  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:03:43.510788  3078 solver.cpp:330] Iteration 58000, Testing net (#0)
I1130 11:03:44.312408  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:03:44.343946  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7358
I1130 11:03:44.343997  3078 solver.cpp:397]     Test net output #1: loss = 0.770056 (* 1 = 0.770056 loss)
I1130 11:03:44.385934  3078 solver.cpp:218] Iteration 58000 (21.6095 iter/s, 9.25519s/200 iters), loss = 0.480392
I1130 11:03:44.385994  3078 solver.cpp:237]     Train net output #0: loss = 0.480392 (* 1 = 0.480392 loss)
I1130 11:03:44.386000  3078 sgd_solver.cpp:105] Iteration 58000, lr = 0.001
I1130 11:03:52.809612  3078 solver.cpp:218] Iteration 58200 (23.7426 iter/s, 8.42367s/200 iters), loss = 0.517815
I1130 11:03:52.809654  3078 solver.cpp:237]     Train net output #0: loss = 0.517815 (* 1 = 0.517815 loss)
I1130 11:03:52.809659  3078 sgd_solver.cpp:105] Iteration 58200, lr = 0.001
I1130 11:04:01.258471  3078 solver.cpp:218] Iteration 58400 (23.6718 iter/s, 8.44887s/200 iters), loss = 0.486553
I1130 11:04:01.258497  3078 solver.cpp:237]     Train net output #0: loss = 0.486553 (* 1 = 0.486553 loss)
I1130 11:04:01.258502  3078 sgd_solver.cpp:105] Iteration 58400, lr = 0.001
I1130 11:04:05.271620  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:04:09.696064  3078 solver.cpp:218] Iteration 58600 (23.7034 iter/s, 8.4376s/200 iters), loss = 0.568979
I1130 11:04:09.696091  3078 solver.cpp:237]     Train net output #0: loss = 0.568979 (* 1 = 0.568979 loss)
I1130 11:04:09.696096  3078 sgd_solver.cpp:105] Iteration 58600, lr = 0.001
I1130 11:04:18.145911  3078 solver.cpp:218] Iteration 58800 (23.669 iter/s, 8.44988s/200 iters), loss = 0.465619
I1130 11:04:18.145937  3078 solver.cpp:237]     Train net output #0: loss = 0.465619 (* 1 = 0.465619 loss)
I1130 11:04:18.145942  3078 sgd_solver.cpp:105] Iteration 58800, lr = 0.001
I1130 11:04:26.368122  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:04:26.501781  3078 solver.cpp:330] Iteration 59000, Testing net (#0)
I1130 11:04:27.312541  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:04:27.335721  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7354
I1130 11:04:27.335773  3078 solver.cpp:397]     Test net output #1: loss = 0.771593 (* 1 = 0.771593 loss)
I1130 11:04:27.378437  3078 solver.cpp:218] Iteration 59000 (21.6625 iter/s, 9.23256s/200 iters), loss = 0.480601
I1130 11:04:27.378486  3078 solver.cpp:237]     Train net output #0: loss = 0.480601 (* 1 = 0.480601 loss)
I1130 11:04:27.378492  3078 sgd_solver.cpp:105] Iteration 59000, lr = 0.001
I1130 11:04:35.816511  3078 solver.cpp:218] Iteration 59200 (23.7021 iter/s, 8.43808s/200 iters), loss = 0.516191
I1130 11:04:35.816665  3078 solver.cpp:237]     Train net output #0: loss = 0.516191 (* 1 = 0.516191 loss)
I1130 11:04:35.816673  3078 sgd_solver.cpp:105] Iteration 59200, lr = 0.001
I1130 11:04:44.264222  3078 solver.cpp:218] Iteration 59400 (23.6753 iter/s, 8.44762s/200 iters), loss = 0.483583
I1130 11:04:44.264266  3078 solver.cpp:237]     Train net output #0: loss = 0.483583 (* 1 = 0.483583 loss)
I1130 11:04:44.264271  3078 sgd_solver.cpp:105] Iteration 59400, lr = 0.001
I1130 11:04:48.272696  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:04:52.699661  3078 solver.cpp:218] Iteration 59600 (23.7095 iter/s, 8.43545s/200 iters), loss = 0.567519
I1130 11:04:52.699686  3078 solver.cpp:237]     Train net output #0: loss = 0.567519 (* 1 = 0.567519 loss)
I1130 11:04:52.699708  3078 sgd_solver.cpp:105] Iteration 59600, lr = 0.001
I1130 11:05:01.136167  3078 solver.cpp:218] Iteration 59800 (23.7064 iter/s, 8.43654s/200 iters), loss = 0.462965
I1130 11:05:01.136210  3078 solver.cpp:237]     Train net output #0: loss = 0.462965 (* 1 = 0.462965 loss)
I1130 11:05:01.136214  3078 sgd_solver.cpp:105] Iteration 59800, lr = 0.001
I1130 11:05:09.364116  3093 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:05:09.498013  3078 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_60000.caffemodel
I1130 11:05:09.532858  3078 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_60000.solverstate
I1130 11:05:09.541406  3078 solver.cpp:310] Iteration 60000, loss = 0.480469
I1130 11:05:09.541420  3078 solver.cpp:330] Iteration 60000, Testing net (#0)
I1130 11:05:10.326382  3095 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:05:10.341719  3078 solver.cpp:397]     Test net output #0: accuracy = 0.7357
I1130 11:05:10.341751  3078 solver.cpp:397]     Test net output #1: loss = 0.771977 (* 1 = 0.771977 loss)
I1130 11:05:10.341755  3078 solver.cpp:315] Optimization Done.
I1130 11:05:10.341758  3078 caffe.cpp:259] Optimization Done.
I1130 11:05:10.696172  4120 caffe.cpp:218] Using GPUs 0
I1130 11:05:10.972214  4120 caffe.cpp:223] GPU 0: GeForce GTX 1050
I1130 11:05:11.168738  4120 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.0001
display: 200
max_iter: 65000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 5000
snapshot_prefix: "/home/david/caffe-master/cifar10/model/cifar10_full"
solver_mode: GPU
device_id: 0
net: "/home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1130 11:05:11.168926  4120 solver.cpp:87] Creating training net from net file: /home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt
I1130 11:05:11.169178  4120 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1130 11:05:11.169206  4120 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1130 11:05:11.169324  4120 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/david/caffe-master/cifar10/data/lmdb/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1130 11:05:11.169412  4120 layer_factory.hpp:77] Creating layer cifar
I1130 11:05:11.169531  4120 db_lmdb.cpp:35] Opened lmdb /home/david/caffe-master/cifar10/data/lmdb/cifar10_train_lmdb
I1130 11:05:11.169587  4120 net.cpp:84] Creating Layer cifar
I1130 11:05:11.169605  4120 net.cpp:380] cifar -> data
I1130 11:05:11.169663  4120 net.cpp:380] cifar -> label
I1130 11:05:11.169690  4120 data_transformer.cpp:25] Loading mean file from: /home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto
I1130 11:05:11.171077  4120 data_layer.cpp:45] output data size: 100,3,32,32
I1130 11:05:11.175185  4120 net.cpp:122] Setting up cifar
I1130 11:05:11.175227  4120 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1130 11:05:11.175231  4120 net.cpp:129] Top shape: 100 (100)
I1130 11:05:11.175233  4120 net.cpp:137] Memory required for data: 1229200
I1130 11:05:11.175241  4120 layer_factory.hpp:77] Creating layer conv1
I1130 11:05:11.175262  4120 net.cpp:84] Creating Layer conv1
I1130 11:05:11.175268  4120 net.cpp:406] conv1 <- data
I1130 11:05:11.175279  4120 net.cpp:380] conv1 -> conv1
I1130 11:05:11.605818  4120 net.cpp:122] Setting up conv1
I1130 11:05:11.605859  4120 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1130 11:05:11.605861  4120 net.cpp:137] Memory required for data: 14336400
I1130 11:05:11.605882  4120 layer_factory.hpp:77] Creating layer pool1
I1130 11:05:11.605912  4120 net.cpp:84] Creating Layer pool1
I1130 11:05:11.605917  4120 net.cpp:406] pool1 <- conv1
I1130 11:05:11.605922  4120 net.cpp:380] pool1 -> pool1
I1130 11:05:11.605979  4120 net.cpp:122] Setting up pool1
I1130 11:05:11.605984  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.605986  4120 net.cpp:137] Memory required for data: 17613200
I1130 11:05:11.605988  4120 layer_factory.hpp:77] Creating layer relu1
I1130 11:05:11.605991  4120 net.cpp:84] Creating Layer relu1
I1130 11:05:11.605994  4120 net.cpp:406] relu1 <- pool1
I1130 11:05:11.605998  4120 net.cpp:367] relu1 -> pool1 (in-place)
I1130 11:05:11.606240  4120 net.cpp:122] Setting up relu1
I1130 11:05:11.606245  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.606266  4120 net.cpp:137] Memory required for data: 20890000
I1130 11:05:11.606267  4120 layer_factory.hpp:77] Creating layer norm1
I1130 11:05:11.606276  4120 net.cpp:84] Creating Layer norm1
I1130 11:05:11.606278  4120 net.cpp:406] norm1 <- pool1
I1130 11:05:11.606300  4120 net.cpp:380] norm1 -> norm1
I1130 11:05:11.606922  4120 net.cpp:122] Setting up norm1
I1130 11:05:11.606930  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.606951  4120 net.cpp:137] Memory required for data: 24166800
I1130 11:05:11.606953  4120 layer_factory.hpp:77] Creating layer conv2
I1130 11:05:11.606961  4120 net.cpp:84] Creating Layer conv2
I1130 11:05:11.606963  4120 net.cpp:406] conv2 <- norm1
I1130 11:05:11.606986  4120 net.cpp:380] conv2 -> conv2
I1130 11:05:11.608911  4120 net.cpp:122] Setting up conv2
I1130 11:05:11.608922  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.608942  4120 net.cpp:137] Memory required for data: 27443600
I1130 11:05:11.608949  4120 layer_factory.hpp:77] Creating layer relu2
I1130 11:05:11.608954  4120 net.cpp:84] Creating Layer relu2
I1130 11:05:11.608956  4120 net.cpp:406] relu2 <- conv2
I1130 11:05:11.608978  4120 net.cpp:367] relu2 -> conv2 (in-place)
I1130 11:05:11.609333  4120 net.cpp:122] Setting up relu2
I1130 11:05:11.609342  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.609344  4120 net.cpp:137] Memory required for data: 30720400
I1130 11:05:11.609346  4120 layer_factory.hpp:77] Creating layer pool2
I1130 11:05:11.609369  4120 net.cpp:84] Creating Layer pool2
I1130 11:05:11.609372  4120 net.cpp:406] pool2 <- conv2
I1130 11:05:11.609376  4120 net.cpp:380] pool2 -> pool2
I1130 11:05:11.609552  4120 net.cpp:122] Setting up pool2
I1130 11:05:11.609560  4120 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:05:11.609561  4120 net.cpp:137] Memory required for data: 31539600
I1130 11:05:11.609582  4120 layer_factory.hpp:77] Creating layer norm2
I1130 11:05:11.609587  4120 net.cpp:84] Creating Layer norm2
I1130 11:05:11.609591  4120 net.cpp:406] norm2 <- pool2
I1130 11:05:11.609593  4120 net.cpp:380] norm2 -> norm2
I1130 11:05:11.609823  4120 net.cpp:122] Setting up norm2
I1130 11:05:11.609830  4120 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:05:11.609863  4120 net.cpp:137] Memory required for data: 32358800
I1130 11:05:11.609879  4120 layer_factory.hpp:77] Creating layer conv3
I1130 11:05:11.609884  4120 net.cpp:84] Creating Layer conv3
I1130 11:05:11.609905  4120 net.cpp:406] conv3 <- norm2
I1130 11:05:11.609910  4120 net.cpp:380] conv3 -> conv3
I1130 11:05:11.611166  4120 net.cpp:122] Setting up conv3
I1130 11:05:11.611176  4120 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:05:11.611178  4120 net.cpp:137] Memory required for data: 33997200
I1130 11:05:11.611203  4120 layer_factory.hpp:77] Creating layer relu3
I1130 11:05:11.611208  4120 net.cpp:84] Creating Layer relu3
I1130 11:05:11.611210  4120 net.cpp:406] relu3 <- conv3
I1130 11:05:11.611213  4120 net.cpp:367] relu3 -> conv3 (in-place)
I1130 11:05:11.611577  4120 net.cpp:122] Setting up relu3
I1130 11:05:11.611585  4120 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:05:11.611606  4120 net.cpp:137] Memory required for data: 35635600
I1130 11:05:11.611608  4120 layer_factory.hpp:77] Creating layer pool3
I1130 11:05:11.611613  4120 net.cpp:84] Creating Layer pool3
I1130 11:05:11.611614  4120 net.cpp:406] pool3 <- conv3
I1130 11:05:11.611618  4120 net.cpp:380] pool3 -> pool3
I1130 11:05:11.611815  4120 net.cpp:122] Setting up pool3
I1130 11:05:11.611821  4120 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1130 11:05:11.611842  4120 net.cpp:137] Memory required for data: 36045200
I1130 11:05:11.611845  4120 layer_factory.hpp:77] Creating layer ip1
I1130 11:05:11.611848  4120 net.cpp:84] Creating Layer ip1
I1130 11:05:11.611851  4120 net.cpp:406] ip1 <- pool3
I1130 11:05:11.611855  4120 net.cpp:380] ip1 -> ip1
I1130 11:05:11.612599  4120 net.cpp:122] Setting up ip1
I1130 11:05:11.612607  4120 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:05:11.612627  4120 net.cpp:137] Memory required for data: 36049200
I1130 11:05:11.612632  4120 layer_factory.hpp:77] Creating layer loss
I1130 11:05:11.612637  4120 net.cpp:84] Creating Layer loss
I1130 11:05:11.612638  4120 net.cpp:406] loss <- ip1
I1130 11:05:11.612643  4120 net.cpp:406] loss <- label
I1130 11:05:11.612664  4120 net.cpp:380] loss -> loss
I1130 11:05:11.612675  4120 layer_factory.hpp:77] Creating layer loss
I1130 11:05:11.612967  4120 net.cpp:122] Setting up loss
I1130 11:05:11.612973  4120 net.cpp:129] Top shape: (1)
I1130 11:05:11.612994  4120 net.cpp:132]     with loss weight 1
I1130 11:05:11.613028  4120 net.cpp:137] Memory required for data: 36049204
I1130 11:05:11.613030  4120 net.cpp:198] loss needs backward computation.
I1130 11:05:11.613035  4120 net.cpp:198] ip1 needs backward computation.
I1130 11:05:11.613037  4120 net.cpp:198] pool3 needs backward computation.
I1130 11:05:11.613040  4120 net.cpp:198] relu3 needs backward computation.
I1130 11:05:11.613042  4120 net.cpp:198] conv3 needs backward computation.
I1130 11:05:11.613044  4120 net.cpp:198] norm2 needs backward computation.
I1130 11:05:11.613046  4120 net.cpp:198] pool2 needs backward computation.
I1130 11:05:11.613049  4120 net.cpp:198] relu2 needs backward computation.
I1130 11:05:11.613050  4120 net.cpp:198] conv2 needs backward computation.
I1130 11:05:11.613052  4120 net.cpp:198] norm1 needs backward computation.
I1130 11:05:11.613054  4120 net.cpp:198] relu1 needs backward computation.
I1130 11:05:11.613056  4120 net.cpp:198] pool1 needs backward computation.
I1130 11:05:11.613059  4120 net.cpp:198] conv1 needs backward computation.
I1130 11:05:11.613061  4120 net.cpp:200] cifar does not need backward computation.
I1130 11:05:11.613062  4120 net.cpp:242] This network produces output loss
I1130 11:05:11.613070  4120 net.cpp:255] Network initialization done.
I1130 11:05:11.613222  4120 solver.cpp:172] Creating test net (#0) specified by net file: /home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt
I1130 11:05:11.613257  4120 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1130 11:05:11.613348  4120 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/david/caffe-master/cifar10/data/lmdb/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1130 11:05:11.613443  4120 layer_factory.hpp:77] Creating layer cifar
I1130 11:05:11.613548  4120 db_lmdb.cpp:35] Opened lmdb /home/david/caffe-master/cifar10/data/lmdb/cifar10_test_lmdb
I1130 11:05:11.613571  4120 net.cpp:84] Creating Layer cifar
I1130 11:05:11.613590  4120 net.cpp:380] cifar -> data
I1130 11:05:11.613613  4120 net.cpp:380] cifar -> label
I1130 11:05:11.613618  4120 data_transformer.cpp:25] Loading mean file from: /home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto
I1130 11:05:11.613783  4120 data_layer.cpp:45] output data size: 100,3,32,32
I1130 11:05:11.617964  4120 net.cpp:122] Setting up cifar
I1130 11:05:11.618001  4120 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1130 11:05:11.618006  4120 net.cpp:129] Top shape: 100 (100)
I1130 11:05:11.618010  4120 net.cpp:137] Memory required for data: 1229200
I1130 11:05:11.618018  4120 layer_factory.hpp:77] Creating layer label_cifar_1_split
I1130 11:05:11.618047  4120 net.cpp:84] Creating Layer label_cifar_1_split
I1130 11:05:11.618052  4120 net.cpp:406] label_cifar_1_split <- label
I1130 11:05:11.618062  4120 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1130 11:05:11.618113  4120 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1130 11:05:11.618180  4120 net.cpp:122] Setting up label_cifar_1_split
I1130 11:05:11.618186  4120 net.cpp:129] Top shape: 100 (100)
I1130 11:05:11.618191  4120 net.cpp:129] Top shape: 100 (100)
I1130 11:05:11.618194  4120 net.cpp:137] Memory required for data: 1230000
I1130 11:05:11.618197  4120 layer_factory.hpp:77] Creating layer conv1
I1130 11:05:11.618209  4120 net.cpp:84] Creating Layer conv1
I1130 11:05:11.618213  4120 net.cpp:406] conv1 <- data
I1130 11:05:11.618221  4120 net.cpp:380] conv1 -> conv1
I1130 11:05:11.619622  4120 net.cpp:122] Setting up conv1
I1130 11:05:11.619635  4120 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1130 11:05:11.619639  4120 net.cpp:137] Memory required for data: 14337200
I1130 11:05:11.619652  4120 layer_factory.hpp:77] Creating layer pool1
I1130 11:05:11.619663  4120 net.cpp:84] Creating Layer pool1
I1130 11:05:11.619668  4120 net.cpp:406] pool1 <- conv1
I1130 11:05:11.619695  4120 net.cpp:380] pool1 -> pool1
I1130 11:05:11.619774  4120 net.cpp:122] Setting up pool1
I1130 11:05:11.619781  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.619784  4120 net.cpp:137] Memory required for data: 17614000
I1130 11:05:11.619789  4120 layer_factory.hpp:77] Creating layer relu1
I1130 11:05:11.619807  4120 net.cpp:84] Creating Layer relu1
I1130 11:05:11.619813  4120 net.cpp:406] relu1 <- pool1
I1130 11:05:11.619819  4120 net.cpp:367] relu1 -> pool1 (in-place)
I1130 11:05:11.620057  4120 net.cpp:122] Setting up relu1
I1130 11:05:11.620065  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.620069  4120 net.cpp:137] Memory required for data: 20890800
I1130 11:05:11.620088  4120 layer_factory.hpp:77] Creating layer norm1
I1130 11:05:11.620100  4120 net.cpp:84] Creating Layer norm1
I1130 11:05:11.620105  4120 net.cpp:406] norm1 <- pool1
I1130 11:05:11.620110  4120 net.cpp:380] norm1 -> norm1
I1130 11:05:11.622184  4120 net.cpp:122] Setting up norm1
I1130 11:05:11.622205  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.622207  4120 net.cpp:137] Memory required for data: 24167600
I1130 11:05:11.622212  4120 layer_factory.hpp:77] Creating layer conv2
I1130 11:05:11.622252  4120 net.cpp:84] Creating Layer conv2
I1130 11:05:11.622258  4120 net.cpp:406] conv2 <- norm1
I1130 11:05:11.622270  4120 net.cpp:380] conv2 -> conv2
I1130 11:05:11.623785  4120 net.cpp:122] Setting up conv2
I1130 11:05:11.623795  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.623800  4120 net.cpp:137] Memory required for data: 27444400
I1130 11:05:11.623831  4120 layer_factory.hpp:77] Creating layer relu2
I1130 11:05:11.623841  4120 net.cpp:84] Creating Layer relu2
I1130 11:05:11.623845  4120 net.cpp:406] relu2 <- conv2
I1130 11:05:11.623852  4120 net.cpp:367] relu2 -> conv2 (in-place)
I1130 11:05:11.624039  4120 net.cpp:122] Setting up relu2
I1130 11:05:11.624048  4120 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:05:11.624073  4120 net.cpp:137] Memory required for data: 30721200
I1130 11:05:11.624076  4120 layer_factory.hpp:77] Creating layer pool2
I1130 11:05:11.624097  4120 net.cpp:84] Creating Layer pool2
I1130 11:05:11.624116  4120 net.cpp:406] pool2 <- conv2
I1130 11:05:11.624121  4120 net.cpp:380] pool2 -> pool2
I1130 11:05:11.624356  4120 net.cpp:122] Setting up pool2
I1130 11:05:11.624364  4120 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:05:11.624368  4120 net.cpp:137] Memory required for data: 31540400
I1130 11:05:11.624392  4120 layer_factory.hpp:77] Creating layer norm2
I1130 11:05:11.624400  4120 net.cpp:84] Creating Layer norm2
I1130 11:05:11.624405  4120 net.cpp:406] norm2 <- pool2
I1130 11:05:11.624411  4120 net.cpp:380] norm2 -> norm2
I1130 11:05:11.624933  4120 net.cpp:122] Setting up norm2
I1130 11:05:11.624943  4120 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:05:11.624945  4120 net.cpp:137] Memory required for data: 32359600
I1130 11:05:11.624949  4120 layer_factory.hpp:77] Creating layer conv3
I1130 11:05:11.624980  4120 net.cpp:84] Creating Layer conv3
I1130 11:05:11.624985  4120 net.cpp:406] conv3 <- norm2
I1130 11:05:11.625006  4120 net.cpp:380] conv3 -> conv3
I1130 11:05:11.626404  4120 net.cpp:122] Setting up conv3
I1130 11:05:11.626415  4120 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:05:11.626418  4120 net.cpp:137] Memory required for data: 33998000
I1130 11:05:11.626446  4120 layer_factory.hpp:77] Creating layer relu3
I1130 11:05:11.626452  4120 net.cpp:84] Creating Layer relu3
I1130 11:05:11.626456  4120 net.cpp:406] relu3 <- conv3
I1130 11:05:11.626463  4120 net.cpp:367] relu3 -> conv3 (in-place)
I1130 11:05:11.626646  4120 net.cpp:122] Setting up relu3
I1130 11:05:11.626654  4120 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:05:11.626657  4120 net.cpp:137] Memory required for data: 35636400
I1130 11:05:11.626674  4120 layer_factory.hpp:77] Creating layer pool3
I1130 11:05:11.626682  4120 net.cpp:84] Creating Layer pool3
I1130 11:05:11.626685  4120 net.cpp:406] pool3 <- conv3
I1130 11:05:11.626691  4120 net.cpp:380] pool3 -> pool3
I1130 11:05:11.626881  4120 net.cpp:122] Setting up pool3
I1130 11:05:11.626889  4120 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1130 11:05:11.626893  4120 net.cpp:137] Memory required for data: 36046000
I1130 11:05:11.626896  4120 layer_factory.hpp:77] Creating layer ip1
I1130 11:05:11.626917  4120 net.cpp:84] Creating Layer ip1
I1130 11:05:11.626921  4120 net.cpp:406] ip1 <- pool3
I1130 11:05:11.626929  4120 net.cpp:380] ip1 -> ip1
I1130 11:05:11.627138  4120 net.cpp:122] Setting up ip1
I1130 11:05:11.627146  4120 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:05:11.627148  4120 net.cpp:137] Memory required for data: 36050000
I1130 11:05:11.627167  4120 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I1130 11:05:11.627174  4120 net.cpp:84] Creating Layer ip1_ip1_0_split
I1130 11:05:11.627178  4120 net.cpp:406] ip1_ip1_0_split <- ip1
I1130 11:05:11.627184  4120 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1130 11:05:11.627192  4120 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1130 11:05:11.627252  4120 net.cpp:122] Setting up ip1_ip1_0_split
I1130 11:05:11.627259  4120 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:05:11.627262  4120 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:05:11.627265  4120 net.cpp:137] Memory required for data: 36058000
I1130 11:05:11.627269  4120 layer_factory.hpp:77] Creating layer accuracy
I1130 11:05:11.627276  4120 net.cpp:84] Creating Layer accuracy
I1130 11:05:11.627281  4120 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1130 11:05:11.627285  4120 net.cpp:406] accuracy <- label_cifar_1_split_0
I1130 11:05:11.627290  4120 net.cpp:380] accuracy -> accuracy
I1130 11:05:11.627298  4120 net.cpp:122] Setting up accuracy
I1130 11:05:11.627305  4120 net.cpp:129] Top shape: (1)
I1130 11:05:11.627308  4120 net.cpp:137] Memory required for data: 36058004
I1130 11:05:11.627311  4120 layer_factory.hpp:77] Creating layer loss
I1130 11:05:11.627321  4120 net.cpp:84] Creating Layer loss
I1130 11:05:11.627324  4120 net.cpp:406] loss <- ip1_ip1_0_split_1
I1130 11:05:11.627328  4120 net.cpp:406] loss <- label_cifar_1_split_1
I1130 11:05:11.627336  4120 net.cpp:380] loss -> loss
I1130 11:05:11.627346  4120 layer_factory.hpp:77] Creating layer loss
I1130 11:05:11.627859  4120 net.cpp:122] Setting up loss
I1130 11:05:11.627869  4120 net.cpp:129] Top shape: (1)
I1130 11:05:11.627873  4120 net.cpp:132]     with loss weight 1
I1130 11:05:11.627882  4120 net.cpp:137] Memory required for data: 36058008
I1130 11:05:11.627885  4120 net.cpp:198] loss needs backward computation.
I1130 11:05:11.627890  4120 net.cpp:200] accuracy does not need backward computation.
I1130 11:05:11.627895  4120 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1130 11:05:11.627899  4120 net.cpp:198] ip1 needs backward computation.
I1130 11:05:11.627904  4120 net.cpp:198] pool3 needs backward computation.
I1130 11:05:11.627908  4120 net.cpp:198] relu3 needs backward computation.
I1130 11:05:11.627912  4120 net.cpp:198] conv3 needs backward computation.
I1130 11:05:11.627915  4120 net.cpp:198] norm2 needs backward computation.
I1130 11:05:11.627919  4120 net.cpp:198] pool2 needs backward computation.
I1130 11:05:11.627939  4120 net.cpp:198] relu2 needs backward computation.
I1130 11:05:11.627943  4120 net.cpp:198] conv2 needs backward computation.
I1130 11:05:11.627948  4120 net.cpp:198] norm1 needs backward computation.
I1130 11:05:11.627952  4120 net.cpp:198] relu1 needs backward computation.
I1130 11:05:11.627956  4120 net.cpp:198] pool1 needs backward computation.
I1130 11:05:11.627959  4120 net.cpp:198] conv1 needs backward computation.
I1130 11:05:11.627964  4120 net.cpp:200] label_cifar_1_split does not need backward computation.
I1130 11:05:11.627967  4120 net.cpp:200] cifar does not need backward computation.
I1130 11:05:11.627971  4120 net.cpp:242] This network produces output accuracy
I1130 11:05:11.627975  4120 net.cpp:242] This network produces output loss
I1130 11:05:11.627988  4120 net.cpp:255] Network initialization done.
I1130 11:05:11.628026  4120 solver.cpp:56] Solver scaffolding done.
I1130 11:05:11.628269  4120 caffe.cpp:242] Resuming from /home/david/caffe-master/cifar10/model/cifar10_full_iter_60000.solverstate
I1130 11:05:11.628705  4120 sgd_solver.cpp:318] SGDSolver: restoring history
I1130 11:05:11.628868  4120 caffe.cpp:248] Starting Optimization
I1130 11:05:11.628875  4120 solver.cpp:272] Solving CIFAR10_full
I1130 11:05:11.628877  4120 solver.cpp:273] Learning Rate Policy: fixed
I1130 11:05:11.629222  4120 solver.cpp:330] Iteration 60000, Testing net (#0)
I1130 11:05:12.425899  4136 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:05:12.449096  4120 solver.cpp:397]     Test net output #0: accuracy = 0.7357
I1130 11:05:12.449122  4120 solver.cpp:397]     Test net output #1: loss = 0.771977 (* 1 = 0.771977 loss)
I1130 11:05:12.492491  4120 solver.cpp:218] Iteration 60000 (69476.8 iter/s, 0.863598s/200 iters), loss = 0.480469
I1130 11:05:12.492519  4120 solver.cpp:237]     Train net output #0: loss = 0.480469 (* 1 = 0.480469 loss)
I1130 11:05:12.492545  4120 sgd_solver.cpp:105] Iteration 60000, lr = 0.0001
I1130 11:05:20.930683  4120 solver.cpp:218] Iteration 60200 (23.7017 iter/s, 8.43822s/200 iters), loss = 0.500768
I1130 11:05:20.930712  4120 solver.cpp:237]     Train net output #0: loss = 0.500768 (* 1 = 0.500768 loss)
I1130 11:05:20.930717  4120 sgd_solver.cpp:105] Iteration 60200, lr = 0.0001
I1130 11:05:29.363394  4120 solver.cpp:218] Iteration 60400 (23.7171 iter/s, 8.43274s/200 iters), loss = 0.407105
I1130 11:05:29.363438  4120 solver.cpp:237]     Train net output #0: loss = 0.407105 (* 1 = 0.407105 loss)
I1130 11:05:29.363443  4120 sgd_solver.cpp:105] Iteration 60400, lr = 0.0001
I1130 11:05:33.364578  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:05:37.783388  4120 solver.cpp:218] Iteration 60600 (23.7529 iter/s, 8.42002s/200 iters), loss = 0.502483
I1130 11:05:37.783437  4120 solver.cpp:237]     Train net output #0: loss = 0.502483 (* 1 = 0.502483 loss)
I1130 11:05:37.783470  4120 sgd_solver.cpp:105] Iteration 60600, lr = 0.0001
I1130 11:05:46.218019  4120 solver.cpp:218] Iteration 60800 (23.7118 iter/s, 8.43464s/200 iters), loss = 0.482717
I1130 11:05:46.218089  4120 solver.cpp:237]     Train net output #0: loss = 0.482717 (* 1 = 0.482717 loss)
I1130 11:05:46.218094  4120 sgd_solver.cpp:105] Iteration 60800, lr = 0.0001
I1130 11:05:54.435065  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:05:54.562587  4120 solver.cpp:330] Iteration 61000, Testing net (#0)
I1130 11:05:55.362004  4136 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:05:55.393625  4120 solver.cpp:397]     Test net output #0: accuracy = 0.7882
I1130 11:05:55.393712  4120 solver.cpp:397]     Test net output #1: loss = 0.603303 (* 1 = 0.603303 loss)
I1130 11:05:55.435796  4120 solver.cpp:218] Iteration 61000 (21.6973 iter/s, 9.21776s/200 iters), loss = 0.431295
I1130 11:05:55.435854  4120 solver.cpp:237]     Train net output #0: loss = 0.431295 (* 1 = 0.431295 loss)
I1130 11:05:55.435860  4120 sgd_solver.cpp:105] Iteration 61000, lr = 0.0001
I1130 11:06:03.843180  4120 solver.cpp:218] Iteration 61200 (23.7887 iter/s, 8.40736s/200 iters), loss = 0.490491
I1130 11:06:03.843220  4120 solver.cpp:237]     Train net output #0: loss = 0.490491 (* 1 = 0.490491 loss)
I1130 11:06:03.843225  4120 sgd_solver.cpp:105] Iteration 61200, lr = 0.0001
I1130 11:06:12.248493  4120 solver.cpp:218] Iteration 61400 (23.7944 iter/s, 8.40533s/200 iters), loss = 0.411177
I1130 11:06:12.248538  4120 solver.cpp:237]     Train net output #0: loss = 0.411177 (* 1 = 0.411177 loss)
I1130 11:06:12.248541  4120 sgd_solver.cpp:105] Iteration 61400, lr = 0.0001
I1130 11:06:16.242750  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:06:20.659504  4120 solver.cpp:218] Iteration 61600 (23.7783 iter/s, 8.41102s/200 iters), loss = 0.494009
I1130 11:06:20.659531  4120 solver.cpp:237]     Train net output #0: loss = 0.494009 (* 1 = 0.494009 loss)
I1130 11:06:20.659536  4120 sgd_solver.cpp:105] Iteration 61600, lr = 0.0001
I1130 11:06:29.069675  4120 solver.cpp:218] Iteration 61800 (23.7806 iter/s, 8.4102s/200 iters), loss = 0.472745
I1130 11:06:29.069742  4120 solver.cpp:237]     Train net output #0: loss = 0.472745 (* 1 = 0.472745 loss)
I1130 11:06:29.069746  4120 sgd_solver.cpp:105] Iteration 61800, lr = 0.0001
I1130 11:06:37.270833  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:06:37.404531  4120 solver.cpp:330] Iteration 62000, Testing net (#0)
I1130 11:06:38.215173  4136 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:06:38.238414  4120 solver.cpp:397]     Test net output #0: accuracy = 0.7903
I1130 11:06:38.238453  4120 solver.cpp:397]     Test net output #1: loss = 0.602348 (* 1 = 0.602348 loss)
I1130 11:06:38.281054  4120 solver.cpp:218] Iteration 62000 (21.7123 iter/s, 9.21137s/200 iters), loss = 0.421604
I1130 11:06:38.281128  4120 solver.cpp:237]     Train net output #0: loss = 0.421604 (* 1 = 0.421604 loss)
I1130 11:06:38.281133  4120 sgd_solver.cpp:105] Iteration 62000, lr = 0.0001
I1130 11:06:46.700381  4120 solver.cpp:218] Iteration 62200 (23.7549 iter/s, 8.41931s/200 iters), loss = 0.489143
I1130 11:06:46.700531  4120 solver.cpp:237]     Train net output #0: loss = 0.489143 (* 1 = 0.489143 loss)
I1130 11:06:46.700551  4120 sgd_solver.cpp:105] Iteration 62200, lr = 0.0001
I1130 11:06:55.131265  4120 solver.cpp:218] Iteration 62400 (23.7226 iter/s, 8.43079s/200 iters), loss = 0.413502
I1130 11:06:55.131316  4120 solver.cpp:237]     Train net output #0: loss = 0.413502 (* 1 = 0.413502 loss)
I1130 11:06:55.131330  4120 sgd_solver.cpp:105] Iteration 62400, lr = 0.0001
I1130 11:06:59.128873  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:07:03.540956  4120 solver.cpp:218] Iteration 62600 (23.782 iter/s, 8.40971s/200 iters), loss = 0.490923
I1130 11:07:03.541002  4120 solver.cpp:237]     Train net output #0: loss = 0.490923 (* 1 = 0.490923 loss)
I1130 11:07:03.541005  4120 sgd_solver.cpp:105] Iteration 62600, lr = 0.0001
I1130 11:07:11.947749  4120 solver.cpp:218] Iteration 62800 (23.7902 iter/s, 8.40682s/200 iters), loss = 0.468074
I1130 11:07:11.947775  4120 solver.cpp:237]     Train net output #0: loss = 0.468074 (* 1 = 0.468074 loss)
I1130 11:07:11.947798  4120 sgd_solver.cpp:105] Iteration 62800, lr = 0.0001
I1130 11:07:20.161072  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:07:20.294813  4120 solver.cpp:330] Iteration 63000, Testing net (#0)
I1130 11:07:21.105190  4136 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:07:21.128695  4120 solver.cpp:397]     Test net output #0: accuracy = 0.7904
I1130 11:07:21.128736  4120 solver.cpp:397]     Test net output #1: loss = 0.601489 (* 1 = 0.601489 loss)
I1130 11:07:21.171084  4120 solver.cpp:218] Iteration 63000 (21.6841 iter/s, 9.22336s/200 iters), loss = 0.416533
I1130 11:07:21.171131  4120 solver.cpp:237]     Train net output #0: loss = 0.416533 (* 1 = 0.416533 loss)
I1130 11:07:21.171140  4120 sgd_solver.cpp:105] Iteration 63000, lr = 0.0001
I1130 11:07:29.595471  4120 solver.cpp:218] Iteration 63200 (23.7406 iter/s, 8.4244s/200 iters), loss = 0.486496
I1130 11:07:29.595515  4120 solver.cpp:237]     Train net output #0: loss = 0.486496 (* 1 = 0.486496 loss)
I1130 11:07:29.595520  4120 sgd_solver.cpp:105] Iteration 63200, lr = 0.0001
I1130 11:07:38.017727  4120 solver.cpp:218] Iteration 63400 (23.7466 iter/s, 8.42227s/200 iters), loss = 0.412924
I1130 11:07:38.017772  4120 solver.cpp:237]     Train net output #0: loss = 0.412924 (* 1 = 0.412924 loss)
I1130 11:07:38.017777  4120 sgd_solver.cpp:105] Iteration 63400, lr = 0.0001
I1130 11:07:42.023254  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:07:46.443431  4120 solver.cpp:218] Iteration 63600 (23.7368 iter/s, 8.42573s/200 iters), loss = 0.488312
I1130 11:07:46.443476  4120 solver.cpp:237]     Train net output #0: loss = 0.488312 (* 1 = 0.488312 loss)
I1130 11:07:46.443481  4120 sgd_solver.cpp:105] Iteration 63600, lr = 0.0001
I1130 11:07:54.880215  4120 solver.cpp:218] Iteration 63800 (23.7057 iter/s, 8.4368s/200 iters), loss = 0.464366
I1130 11:07:54.880313  4120 solver.cpp:237]     Train net output #0: loss = 0.464366 (* 1 = 0.464366 loss)
I1130 11:07:54.880319  4120 sgd_solver.cpp:105] Iteration 63800, lr = 0.0001
I1130 11:08:03.111580  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:08:03.244911  4120 solver.cpp:330] Iteration 64000, Testing net (#0)
I1130 11:08:03.910684  4120 blocking_queue.cpp:49] Waiting for data
I1130 11:08:04.063765  4136 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:08:04.079057  4120 solver.cpp:397]     Test net output #0: accuracy = 0.7913
I1130 11:08:04.079107  4120 solver.cpp:397]     Test net output #1: loss = 0.600707 (* 1 = 0.600707 loss)
I1130 11:08:04.121475  4120 solver.cpp:218] Iteration 64000 (21.6422 iter/s, 9.24122s/200 iters), loss = 0.413978
I1130 11:08:04.121527  4120 solver.cpp:237]     Train net output #0: loss = 0.413978 (* 1 = 0.413978 loss)
I1130 11:08:04.121533  4120 sgd_solver.cpp:105] Iteration 64000, lr = 0.0001
I1130 11:08:12.559262  4120 solver.cpp:218] Iteration 64200 (23.7029 iter/s, 8.43779s/200 iters), loss = 0.484437
I1130 11:08:12.559307  4120 solver.cpp:237]     Train net output #0: loss = 0.484437 (* 1 = 0.484437 loss)
I1130 11:08:12.559311  4120 sgd_solver.cpp:105] Iteration 64200, lr = 0.0001
I1130 11:08:21.000217  4120 solver.cpp:218] Iteration 64400 (23.694 iter/s, 8.44097s/200 iters), loss = 0.412574
I1130 11:08:21.000267  4120 solver.cpp:237]     Train net output #0: loss = 0.412574 (* 1 = 0.412574 loss)
I1130 11:08:21.000272  4120 sgd_solver.cpp:105] Iteration 64400, lr = 0.0001
I1130 11:08:25.013363  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:08:29.445822  4120 solver.cpp:218] Iteration 64600 (23.6809 iter/s, 8.44562s/200 iters), loss = 0.486313
I1130 11:08:29.445868  4120 solver.cpp:237]     Train net output #0: loss = 0.486313 (* 1 = 0.486313 loss)
I1130 11:08:29.445871  4120 sgd_solver.cpp:105] Iteration 64600, lr = 0.0001
I1130 11:08:37.887706  4120 solver.cpp:218] Iteration 64800 (23.6914 iter/s, 8.44189s/200 iters), loss = 0.46201
I1130 11:08:37.887749  4120 solver.cpp:237]     Train net output #0: loss = 0.46201 (* 1 = 0.46201 loss)
I1130 11:08:37.887753  4120 sgd_solver.cpp:105] Iteration 64800, lr = 0.0001
I1130 11:08:46.115680  4135 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:08:46.249603  4120 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_65000.caffemodel
I1130 11:08:46.284669  4120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_65000.solverstate
I1130 11:08:46.293242  4120 solver.cpp:310] Iteration 65000, loss = 0.411523
I1130 11:08:46.293262  4120 solver.cpp:330] Iteration 65000, Testing net (#0)
I1130 11:08:47.080981  4136 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:08:47.096171  4120 solver.cpp:397]     Test net output #0: accuracy = 0.792
I1130 11:08:47.096256  4120 solver.cpp:397]     Test net output #1: loss = 0.599956 (* 1 = 0.599956 loss)
I1130 11:08:47.096266  4120 solver.cpp:315] Optimization Done.
I1130 11:08:47.096267  4120 caffe.cpp:259] Optimization Done.
I1130 11:08:47.425022  4174 caffe.cpp:218] Using GPUs 0
I1130 11:08:47.699295  4174 caffe.cpp:223] GPU 0: GeForce GTX 1050
I1130 11:08:47.896086  4174 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 1e-05
display: 200
max_iter: 70000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 5000
snapshot_prefix: "/home/david/caffe-master/cifar10/model/cifar10_full"
solver_mode: GPU
device_id: 0
net: "/home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1130 11:08:47.896311  4174 solver.cpp:87] Creating training net from net file: /home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt
I1130 11:08:47.896582  4174 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1130 11:08:47.896592  4174 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1130 11:08:47.896747  4174 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/david/caffe-master/cifar10/data/lmdb/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1130 11:08:47.896806  4174 layer_factory.hpp:77] Creating layer cifar
I1130 11:08:47.896951  4174 db_lmdb.cpp:35] Opened lmdb /home/david/caffe-master/cifar10/data/lmdb/cifar10_train_lmdb
I1130 11:08:47.896991  4174 net.cpp:84] Creating Layer cifar
I1130 11:08:47.896997  4174 net.cpp:380] cifar -> data
I1130 11:08:47.897055  4174 net.cpp:380] cifar -> label
I1130 11:08:47.897064  4174 data_transformer.cpp:25] Loading mean file from: /home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto
I1130 11:08:47.898351  4174 data_layer.cpp:45] output data size: 100,3,32,32
I1130 11:08:47.902345  4174 net.cpp:122] Setting up cifar
I1130 11:08:47.902386  4174 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1130 11:08:47.902390  4174 net.cpp:129] Top shape: 100 (100)
I1130 11:08:47.902392  4174 net.cpp:137] Memory required for data: 1229200
I1130 11:08:47.902400  4174 layer_factory.hpp:77] Creating layer conv1
I1130 11:08:47.902439  4174 net.cpp:84] Creating Layer conv1
I1130 11:08:47.902444  4174 net.cpp:406] conv1 <- data
I1130 11:08:47.902457  4174 net.cpp:380] conv1 -> conv1
I1130 11:08:48.344063  4174 net.cpp:122] Setting up conv1
I1130 11:08:48.344106  4174 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1130 11:08:48.344110  4174 net.cpp:137] Memory required for data: 14336400
I1130 11:08:48.344149  4174 layer_factory.hpp:77] Creating layer pool1
I1130 11:08:48.344164  4174 net.cpp:84] Creating Layer pool1
I1130 11:08:48.344168  4174 net.cpp:406] pool1 <- conv1
I1130 11:08:48.344192  4174 net.cpp:380] pool1 -> pool1
I1130 11:08:48.344271  4174 net.cpp:122] Setting up pool1
I1130 11:08:48.344290  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.344293  4174 net.cpp:137] Memory required for data: 17613200
I1130 11:08:48.344295  4174 layer_factory.hpp:77] Creating layer relu1
I1130 11:08:48.344300  4174 net.cpp:84] Creating Layer relu1
I1130 11:08:48.344301  4174 net.cpp:406] relu1 <- pool1
I1130 11:08:48.344305  4174 net.cpp:367] relu1 -> pool1 (in-place)
I1130 11:08:48.344532  4174 net.cpp:122] Setting up relu1
I1130 11:08:48.344538  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.344542  4174 net.cpp:137] Memory required for data: 20890000
I1130 11:08:48.344561  4174 layer_factory.hpp:77] Creating layer norm1
I1130 11:08:48.344569  4174 net.cpp:84] Creating Layer norm1
I1130 11:08:48.344594  4174 net.cpp:406] norm1 <- pool1
I1130 11:08:48.344597  4174 net.cpp:380] norm1 -> norm1
I1130 11:08:48.345330  4174 net.cpp:122] Setting up norm1
I1130 11:08:48.345340  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.345343  4174 net.cpp:137] Memory required for data: 24166800
I1130 11:08:48.345365  4174 layer_factory.hpp:77] Creating layer conv2
I1130 11:08:48.345392  4174 net.cpp:84] Creating Layer conv2
I1130 11:08:48.345396  4174 net.cpp:406] conv2 <- norm1
I1130 11:08:48.345399  4174 net.cpp:380] conv2 -> conv2
I1130 11:08:48.347491  4174 net.cpp:122] Setting up conv2
I1130 11:08:48.347501  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.347503  4174 net.cpp:137] Memory required for data: 27443600
I1130 11:08:48.347529  4174 layer_factory.hpp:77] Creating layer relu2
I1130 11:08:48.347534  4174 net.cpp:84] Creating Layer relu2
I1130 11:08:48.347537  4174 net.cpp:406] relu2 <- conv2
I1130 11:08:48.347542  4174 net.cpp:367] relu2 -> conv2 (in-place)
I1130 11:08:48.347987  4174 net.cpp:122] Setting up relu2
I1130 11:08:48.347996  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.348018  4174 net.cpp:137] Memory required for data: 30720400
I1130 11:08:48.348021  4174 layer_factory.hpp:77] Creating layer pool2
I1130 11:08:48.348026  4174 net.cpp:84] Creating Layer pool2
I1130 11:08:48.348028  4174 net.cpp:406] pool2 <- conv2
I1130 11:08:48.348032  4174 net.cpp:380] pool2 -> pool2
I1130 11:08:48.348237  4174 net.cpp:122] Setting up pool2
I1130 11:08:48.348243  4174 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:08:48.348246  4174 net.cpp:137] Memory required for data: 31539600
I1130 11:08:48.348268  4174 layer_factory.hpp:77] Creating layer norm2
I1130 11:08:48.348273  4174 net.cpp:84] Creating Layer norm2
I1130 11:08:48.348275  4174 net.cpp:406] norm2 <- pool2
I1130 11:08:48.348299  4174 net.cpp:380] norm2 -> norm2
I1130 11:08:48.348630  4174 net.cpp:122] Setting up norm2
I1130 11:08:48.348637  4174 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:08:48.348670  4174 net.cpp:137] Memory required for data: 32358800
I1130 11:08:48.348685  4174 layer_factory.hpp:77] Creating layer conv3
I1130 11:08:48.348692  4174 net.cpp:84] Creating Layer conv3
I1130 11:08:48.348716  4174 net.cpp:406] conv3 <- norm2
I1130 11:08:48.348721  4174 net.cpp:380] conv3 -> conv3
I1130 11:08:48.349998  4174 net.cpp:122] Setting up conv3
I1130 11:08:48.350008  4174 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:08:48.350028  4174 net.cpp:137] Memory required for data: 33997200
I1130 11:08:48.350035  4174 layer_factory.hpp:77] Creating layer relu3
I1130 11:08:48.350057  4174 net.cpp:84] Creating Layer relu3
I1130 11:08:48.350061  4174 net.cpp:406] relu3 <- conv3
I1130 11:08:48.350065  4174 net.cpp:367] relu3 -> conv3 (in-place)
I1130 11:08:48.350468  4174 net.cpp:122] Setting up relu3
I1130 11:08:48.350476  4174 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:08:48.350497  4174 net.cpp:137] Memory required for data: 35635600
I1130 11:08:48.350499  4174 layer_factory.hpp:77] Creating layer pool3
I1130 11:08:48.350504  4174 net.cpp:84] Creating Layer pool3
I1130 11:08:48.350507  4174 net.cpp:406] pool3 <- conv3
I1130 11:08:48.350528  4174 net.cpp:380] pool3 -> pool3
I1130 11:08:48.350738  4174 net.cpp:122] Setting up pool3
I1130 11:08:48.350744  4174 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1130 11:08:48.350764  4174 net.cpp:137] Memory required for data: 36045200
I1130 11:08:48.350766  4174 layer_factory.hpp:77] Creating layer ip1
I1130 11:08:48.350771  4174 net.cpp:84] Creating Layer ip1
I1130 11:08:48.350775  4174 net.cpp:406] ip1 <- pool3
I1130 11:08:48.350796  4174 net.cpp:380] ip1 -> ip1
I1130 11:08:48.351594  4174 net.cpp:122] Setting up ip1
I1130 11:08:48.351603  4174 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:08:48.351626  4174 net.cpp:137] Memory required for data: 36049200
I1130 11:08:48.351631  4174 layer_factory.hpp:77] Creating layer loss
I1130 11:08:48.351636  4174 net.cpp:84] Creating Layer loss
I1130 11:08:48.351639  4174 net.cpp:406] loss <- ip1
I1130 11:08:48.351663  4174 net.cpp:406] loss <- label
I1130 11:08:48.351691  4174 net.cpp:380] loss -> loss
I1130 11:08:48.351722  4174 layer_factory.hpp:77] Creating layer loss
I1130 11:08:48.352041  4174 net.cpp:122] Setting up loss
I1130 11:08:48.352047  4174 net.cpp:129] Top shape: (1)
I1130 11:08:48.352049  4174 net.cpp:132]     with loss weight 1
I1130 11:08:48.352082  4174 net.cpp:137] Memory required for data: 36049204
I1130 11:08:48.352107  4174 net.cpp:198] loss needs backward computation.
I1130 11:08:48.352111  4174 net.cpp:198] ip1 needs backward computation.
I1130 11:08:48.352113  4174 net.cpp:198] pool3 needs backward computation.
I1130 11:08:48.352138  4174 net.cpp:198] relu3 needs backward computation.
I1130 11:08:48.352139  4174 net.cpp:198] conv3 needs backward computation.
I1130 11:08:48.352143  4174 net.cpp:198] norm2 needs backward computation.
I1130 11:08:48.352144  4174 net.cpp:198] pool2 needs backward computation.
I1130 11:08:48.352146  4174 net.cpp:198] relu2 needs backward computation.
I1130 11:08:48.352149  4174 net.cpp:198] conv2 needs backward computation.
I1130 11:08:48.352150  4174 net.cpp:198] norm1 needs backward computation.
I1130 11:08:48.352152  4174 net.cpp:198] relu1 needs backward computation.
I1130 11:08:48.352154  4174 net.cpp:198] pool1 needs backward computation.
I1130 11:08:48.352157  4174 net.cpp:198] conv1 needs backward computation.
I1130 11:08:48.352159  4174 net.cpp:200] cifar does not need backward computation.
I1130 11:08:48.352161  4174 net.cpp:242] This network produces output loss
I1130 11:08:48.352169  4174 net.cpp:255] Network initialization done.
I1130 11:08:48.352345  4174 solver.cpp:172] Creating test net (#0) specified by net file: /home/david/caffe-master/cifar10/prototxt/cifar10_full_train_test.prototxt
I1130 11:08:48.352385  4174 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1130 11:08:48.352516  4174 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/david/caffe-master/cifar10/data/lmdb/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1130 11:08:48.352622  4174 layer_factory.hpp:77] Creating layer cifar
I1130 11:08:48.352663  4174 db_lmdb.cpp:35] Opened lmdb /home/david/caffe-master/cifar10/data/lmdb/cifar10_test_lmdb
I1130 11:08:48.352674  4174 net.cpp:84] Creating Layer cifar
I1130 11:08:48.352694  4174 net.cpp:380] cifar -> data
I1130 11:08:48.352699  4174 net.cpp:380] cifar -> label
I1130 11:08:48.352708  4174 data_transformer.cpp:25] Loading mean file from: /home/david/caffe-master/cifar10/data/lmdb/mean.binaryproto
I1130 11:08:48.352862  4174 data_layer.cpp:45] output data size: 100,3,32,32
I1130 11:08:48.357434  4174 net.cpp:122] Setting up cifar
I1130 11:08:48.357477  4174 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1130 11:08:48.357481  4174 net.cpp:129] Top shape: 100 (100)
I1130 11:08:48.357483  4174 net.cpp:137] Memory required for data: 1229200
I1130 11:08:48.357487  4174 layer_factory.hpp:77] Creating layer label_cifar_1_split
I1130 11:08:48.357501  4174 net.cpp:84] Creating Layer label_cifar_1_split
I1130 11:08:48.357503  4174 net.cpp:406] label_cifar_1_split <- label
I1130 11:08:48.357509  4174 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1130 11:08:48.357518  4174 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1130 11:08:48.357640  4174 net.cpp:122] Setting up label_cifar_1_split
I1130 11:08:48.357646  4174 net.cpp:129] Top shape: 100 (100)
I1130 11:08:48.357666  4174 net.cpp:129] Top shape: 100 (100)
I1130 11:08:48.357667  4174 net.cpp:137] Memory required for data: 1230000
I1130 11:08:48.357669  4174 layer_factory.hpp:77] Creating layer conv1
I1130 11:08:48.357700  4174 net.cpp:84] Creating Layer conv1
I1130 11:08:48.357704  4174 net.cpp:406] conv1 <- data
I1130 11:08:48.357709  4174 net.cpp:380] conv1 -> conv1
I1130 11:08:48.359877  4174 net.cpp:122] Setting up conv1
I1130 11:08:48.359966  4174 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1130 11:08:48.359974  4174 net.cpp:137] Memory required for data: 14337200
I1130 11:08:48.360028  4174 layer_factory.hpp:77] Creating layer pool1
I1130 11:08:48.360059  4174 net.cpp:84] Creating Layer pool1
I1130 11:08:48.360067  4174 net.cpp:406] pool1 <- conv1
I1130 11:08:48.360080  4174 net.cpp:380] pool1 -> pool1
I1130 11:08:48.360234  4174 net.cpp:122] Setting up pool1
I1130 11:08:48.360240  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.360244  4174 net.cpp:137] Memory required for data: 17614000
I1130 11:08:48.360245  4174 layer_factory.hpp:77] Creating layer relu1
I1130 11:08:48.360285  4174 net.cpp:84] Creating Layer relu1
I1130 11:08:48.360290  4174 net.cpp:406] relu1 <- pool1
I1130 11:08:48.360294  4174 net.cpp:367] relu1 -> pool1 (in-place)
I1130 11:08:48.360668  4174 net.cpp:122] Setting up relu1
I1130 11:08:48.360676  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.360678  4174 net.cpp:137] Memory required for data: 20890800
I1130 11:08:48.360702  4174 layer_factory.hpp:77] Creating layer norm1
I1130 11:08:48.360708  4174 net.cpp:84] Creating Layer norm1
I1130 11:08:48.360711  4174 net.cpp:406] norm1 <- pool1
I1130 11:08:48.360715  4174 net.cpp:380] norm1 -> norm1
I1130 11:08:48.361901  4174 net.cpp:122] Setting up norm1
I1130 11:08:48.361910  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.361932  4174 net.cpp:137] Memory required for data: 24167600
I1130 11:08:48.361934  4174 layer_factory.hpp:77] Creating layer conv2
I1130 11:08:48.361945  4174 net.cpp:84] Creating Layer conv2
I1130 11:08:48.361968  4174 net.cpp:406] conv2 <- norm1
I1130 11:08:48.361974  4174 net.cpp:380] conv2 -> conv2
I1130 11:08:48.363446  4174 net.cpp:122] Setting up conv2
I1130 11:08:48.363469  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.363472  4174 net.cpp:137] Memory required for data: 27444400
I1130 11:08:48.363497  4174 layer_factory.hpp:77] Creating layer relu2
I1130 11:08:48.363502  4174 net.cpp:84] Creating Layer relu2
I1130 11:08:48.363505  4174 net.cpp:406] relu2 <- conv2
I1130 11:08:48.363529  4174 net.cpp:367] relu2 -> conv2 (in-place)
I1130 11:08:48.363729  4174 net.cpp:122] Setting up relu2
I1130 11:08:48.363734  4174 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1130 11:08:48.363755  4174 net.cpp:137] Memory required for data: 30721200
I1130 11:08:48.363757  4174 layer_factory.hpp:77] Creating layer pool2
I1130 11:08:48.363765  4174 net.cpp:84] Creating Layer pool2
I1130 11:08:48.363766  4174 net.cpp:406] pool2 <- conv2
I1130 11:08:48.363790  4174 net.cpp:380] pool2 -> pool2
I1130 11:08:48.363998  4174 net.cpp:122] Setting up pool2
I1130 11:08:48.364006  4174 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:08:48.364027  4174 net.cpp:137] Memory required for data: 31540400
I1130 11:08:48.364028  4174 layer_factory.hpp:77] Creating layer norm2
I1130 11:08:48.364033  4174 net.cpp:84] Creating Layer norm2
I1130 11:08:48.364037  4174 net.cpp:406] norm2 <- pool2
I1130 11:08:48.364058  4174 net.cpp:380] norm2 -> norm2
I1130 11:08:48.364660  4174 net.cpp:122] Setting up norm2
I1130 11:08:48.364670  4174 net.cpp:129] Top shape: 100 32 8 8 (204800)
I1130 11:08:48.364691  4174 net.cpp:137] Memory required for data: 32359600
I1130 11:08:48.364694  4174 layer_factory.hpp:77] Creating layer conv3
I1130 11:08:48.364702  4174 net.cpp:84] Creating Layer conv3
I1130 11:08:48.364704  4174 net.cpp:406] conv3 <- norm2
I1130 11:08:48.364737  4174 net.cpp:380] conv3 -> conv3
I1130 11:08:48.366101  4174 net.cpp:122] Setting up conv3
I1130 11:08:48.366111  4174 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:08:48.366132  4174 net.cpp:137] Memory required for data: 33998000
I1130 11:08:48.366139  4174 layer_factory.hpp:77] Creating layer relu3
I1130 11:08:48.366161  4174 net.cpp:84] Creating Layer relu3
I1130 11:08:48.366166  4174 net.cpp:406] relu3 <- conv3
I1130 11:08:48.366171  4174 net.cpp:367] relu3 -> conv3 (in-place)
I1130 11:08:48.366365  4174 net.cpp:122] Setting up relu3
I1130 11:08:48.366372  4174 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1130 11:08:48.366392  4174 net.cpp:137] Memory required for data: 35636400
I1130 11:08:48.366395  4174 layer_factory.hpp:77] Creating layer pool3
I1130 11:08:48.366400  4174 net.cpp:84] Creating Layer pool3
I1130 11:08:48.366401  4174 net.cpp:406] pool3 <- conv3
I1130 11:08:48.366405  4174 net.cpp:380] pool3 -> pool3
I1130 11:08:48.366623  4174 net.cpp:122] Setting up pool3
I1130 11:08:48.366629  4174 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1130 11:08:48.366650  4174 net.cpp:137] Memory required for data: 36046000
I1130 11:08:48.366652  4174 layer_factory.hpp:77] Creating layer ip1
I1130 11:08:48.366658  4174 net.cpp:84] Creating Layer ip1
I1130 11:08:48.366660  4174 net.cpp:406] ip1 <- pool3
I1130 11:08:48.366683  4174 net.cpp:380] ip1 -> ip1
I1130 11:08:48.366874  4174 net.cpp:122] Setting up ip1
I1130 11:08:48.366879  4174 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:08:48.366881  4174 net.cpp:137] Memory required for data: 36050000
I1130 11:08:48.366904  4174 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I1130 11:08:48.366907  4174 net.cpp:84] Creating Layer ip1_ip1_0_split
I1130 11:08:48.366910  4174 net.cpp:406] ip1_ip1_0_split <- ip1
I1130 11:08:48.366932  4174 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1130 11:08:48.366940  4174 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1130 11:08:48.366986  4174 net.cpp:122] Setting up ip1_ip1_0_split
I1130 11:08:48.366991  4174 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:08:48.366993  4174 net.cpp:129] Top shape: 100 10 (1000)
I1130 11:08:48.366996  4174 net.cpp:137] Memory required for data: 36058000
I1130 11:08:48.367010  4174 layer_factory.hpp:77] Creating layer accuracy
I1130 11:08:48.367014  4174 net.cpp:84] Creating Layer accuracy
I1130 11:08:48.367017  4174 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1130 11:08:48.367038  4174 net.cpp:406] accuracy <- label_cifar_1_split_0
I1130 11:08:48.367041  4174 net.cpp:380] accuracy -> accuracy
I1130 11:08:48.367048  4174 net.cpp:122] Setting up accuracy
I1130 11:08:48.367050  4174 net.cpp:129] Top shape: (1)
I1130 11:08:48.367070  4174 net.cpp:137] Memory required for data: 36058004
I1130 11:08:48.367072  4174 layer_factory.hpp:77] Creating layer loss
I1130 11:08:48.367079  4174 net.cpp:84] Creating Layer loss
I1130 11:08:48.367081  4174 net.cpp:406] loss <- ip1_ip1_0_split_1
I1130 11:08:48.367084  4174 net.cpp:406] loss <- label_cifar_1_split_1
I1130 11:08:48.367089  4174 net.cpp:380] loss -> loss
I1130 11:08:48.367096  4174 layer_factory.hpp:77] Creating layer loss
I1130 11:08:48.367588  4174 net.cpp:122] Setting up loss
I1130 11:08:48.367597  4174 net.cpp:129] Top shape: (1)
I1130 11:08:48.367619  4174 net.cpp:132]     with loss weight 1
I1130 11:08:48.367625  4174 net.cpp:137] Memory required for data: 36058008
I1130 11:08:48.367627  4174 net.cpp:198] loss needs backward computation.
I1130 11:08:48.367630  4174 net.cpp:200] accuracy does not need backward computation.
I1130 11:08:48.367652  4174 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1130 11:08:48.367655  4174 net.cpp:198] ip1 needs backward computation.
I1130 11:08:48.367656  4174 net.cpp:198] pool3 needs backward computation.
I1130 11:08:48.367660  4174 net.cpp:198] relu3 needs backward computation.
I1130 11:08:48.367661  4174 net.cpp:198] conv3 needs backward computation.
I1130 11:08:48.367663  4174 net.cpp:198] norm2 needs backward computation.
I1130 11:08:48.367666  4174 net.cpp:198] pool2 needs backward computation.
I1130 11:08:48.367681  4174 net.cpp:198] relu2 needs backward computation.
I1130 11:08:48.367683  4174 net.cpp:198] conv2 needs backward computation.
I1130 11:08:48.367686  4174 net.cpp:198] norm1 needs backward computation.
I1130 11:08:48.367687  4174 net.cpp:198] relu1 needs backward computation.
I1130 11:08:48.367689  4174 net.cpp:198] pool1 needs backward computation.
I1130 11:08:48.367691  4174 net.cpp:198] conv1 needs backward computation.
I1130 11:08:48.367707  4174 net.cpp:200] label_cifar_1_split does not need backward computation.
I1130 11:08:48.367710  4174 net.cpp:200] cifar does not need backward computation.
I1130 11:08:48.367712  4174 net.cpp:242] This network produces output accuracy
I1130 11:08:48.367714  4174 net.cpp:242] This network produces output loss
I1130 11:08:48.367725  4174 net.cpp:255] Network initialization done.
I1130 11:08:48.367779  4174 solver.cpp:56] Solver scaffolding done.
I1130 11:08:48.368104  4174 caffe.cpp:242] Resuming from /home/david/caffe-master/cifar10/model/cifar10_full_iter_65000.solverstate
I1130 11:08:48.368592  4174 sgd_solver.cpp:318] SGDSolver: restoring history
I1130 11:08:48.368800  4174 caffe.cpp:248] Starting Optimization
I1130 11:08:48.368805  4174 solver.cpp:272] Solving CIFAR10_full
I1130 11:08:48.368808  4174 solver.cpp:273] Learning Rate Policy: fixed
I1130 11:08:48.369204  4174 solver.cpp:330] Iteration 65000, Testing net (#0)
I1130 11:08:49.172864  4191 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:08:49.188102  4174 solver.cpp:397]     Test net output #0: accuracy = 0.792
I1130 11:08:49.188140  4174 solver.cpp:397]     Test net output #1: loss = 0.599956 (* 1 = 0.599956 loss)
I1130 11:08:49.231643  4174 solver.cpp:218] Iteration 65000 (-1.891e+32 iter/s, 0.862796s/200 iters), loss = 0.411523
I1130 11:08:49.231701  4174 solver.cpp:237]     Train net output #0: loss = 0.411523 (* 1 = 0.411523 loss)
I1130 11:08:49.231709  4174 sgd_solver.cpp:105] Iteration 65000, lr = 1e-05
I1130 11:08:57.645061  4174 solver.cpp:218] Iteration 65200 (23.7716 iter/s, 8.41342s/200 iters), loss = 0.448498
I1130 11:08:57.645107  4174 solver.cpp:237]     Train net output #0: loss = 0.448498 (* 1 = 0.448498 loss)
I1130 11:08:57.645112  4174 sgd_solver.cpp:105] Iteration 65200, lr = 1e-05
I1130 11:09:06.058845  4174 solver.cpp:218] Iteration 65400 (23.7705 iter/s, 8.41379s/200 iters), loss = 0.396457
I1130 11:09:06.058900  4174 solver.cpp:237]     Train net output #0: loss = 0.396457 (* 1 = 0.396457 loss)
I1130 11:09:06.058905  4174 sgd_solver.cpp:105] Iteration 65400, lr = 1e-05
I1130 11:09:10.056372  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:09:14.472549  4174 solver.cpp:218] Iteration 65600 (23.7707 iter/s, 8.41371s/200 iters), loss = 0.459438
I1130 11:09:14.472579  4174 solver.cpp:237]     Train net output #0: loss = 0.459438 (* 1 = 0.459438 loss)
I1130 11:09:14.472582  4174 sgd_solver.cpp:105] Iteration 65600, lr = 1e-05
I1130 11:09:22.885692  4174 solver.cpp:218] Iteration 65800 (23.7722 iter/s, 8.41317s/200 iters), loss = 0.436525
I1130 11:09:22.885766  4174 solver.cpp:237]     Train net output #0: loss = 0.436525 (* 1 = 0.436525 loss)
I1130 11:09:22.885771  4174 sgd_solver.cpp:105] Iteration 65800, lr = 1e-05
I1130 11:09:31.087364  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:09:31.221084  4174 solver.cpp:330] Iteration 66000, Testing net (#0)
I1130 11:09:32.025163  4191 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:09:32.056813  4174 solver.cpp:397]     Test net output #0: accuracy = 0.7961
I1130 11:09:32.056866  4174 solver.cpp:397]     Test net output #1: loss = 0.58214 (* 1 = 0.58214 loss)
I1130 11:09:32.098758  4174 solver.cpp:218] Iteration 66000 (21.7084 iter/s, 9.21304s/200 iters), loss = 0.379422
I1130 11:09:32.098839  4174 solver.cpp:237]     Train net output #0: loss = 0.379422 (* 1 = 0.379422 loss)
I1130 11:09:32.098845  4174 sgd_solver.cpp:105] Iteration 66000, lr = 1e-05
I1130 11:09:40.518019  4174 solver.cpp:218] Iteration 66200 (23.7551 iter/s, 8.41924s/200 iters), loss = 0.446137
I1130 11:09:40.518048  4174 solver.cpp:237]     Train net output #0: loss = 0.446137 (* 1 = 0.446137 loss)
I1130 11:09:40.518052  4174 sgd_solver.cpp:105] Iteration 66200, lr = 1e-05
I1130 11:09:48.938377  4174 solver.cpp:218] Iteration 66400 (23.7519 iter/s, 8.42039s/200 iters), loss = 0.398751
I1130 11:09:48.938405  4174 solver.cpp:237]     Train net output #0: loss = 0.398751 (* 1 = 0.398751 loss)
I1130 11:09:48.938410  4174 sgd_solver.cpp:105] Iteration 66400, lr = 1e-05
I1130 11:09:52.937425  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:09:57.357762  4174 solver.cpp:218] Iteration 66600 (23.7546 iter/s, 8.41941s/200 iters), loss = 0.459181
I1130 11:09:57.357806  4174 solver.cpp:237]     Train net output #0: loss = 0.459181 (* 1 = 0.459181 loss)
I1130 11:09:57.357811  4174 sgd_solver.cpp:105] Iteration 66600, lr = 1e-05
I1130 11:10:05.772636  4174 solver.cpp:218] Iteration 66800 (23.7674 iter/s, 8.41488s/200 iters), loss = 0.434735
I1130 11:10:05.772680  4174 solver.cpp:237]     Train net output #0: loss = 0.434735 (* 1 = 0.434735 loss)
I1130 11:10:05.772686  4174 sgd_solver.cpp:105] Iteration 66800, lr = 1e-05
I1130 11:10:13.983561  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:10:14.116228  4174 solver.cpp:330] Iteration 67000, Testing net (#0)
I1130 11:10:14.916828  4191 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:10:14.948395  4174 solver.cpp:397]     Test net output #0: accuracy = 0.7974
I1130 11:10:14.948513  4174 solver.cpp:397]     Test net output #1: loss = 0.581686 (* 1 = 0.581686 loss)
I1130 11:10:14.990667  4174 solver.cpp:218] Iteration 67000 (21.6966 iter/s, 9.21804s/200 iters), loss = 0.378987
I1130 11:10:14.990738  4174 solver.cpp:237]     Train net output #0: loss = 0.378987 (* 1 = 0.378987 loss)
I1130 11:10:14.990751  4174 sgd_solver.cpp:105] Iteration 67000, lr = 1e-05
I1130 11:10:23.408004  4174 solver.cpp:218] Iteration 67200 (23.7605 iter/s, 8.41734s/200 iters), loss = 0.446543
I1130 11:10:23.408105  4174 solver.cpp:237]     Train net output #0: loss = 0.446543 (* 1 = 0.446543 loss)
I1130 11:10:23.408110  4174 sgd_solver.cpp:105] Iteration 67200, lr = 1e-05
I1130 11:10:31.826234  4174 solver.cpp:218] Iteration 67400 (23.7581 iter/s, 8.41819s/200 iters), loss = 0.40045
I1130 11:10:31.826278  4174 solver.cpp:237]     Train net output #0: loss = 0.40045 (* 1 = 0.40045 loss)
I1130 11:10:31.826283  4174 sgd_solver.cpp:105] Iteration 67400, lr = 1e-05
I1130 11:10:35.827126  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:10:40.244444  4174 solver.cpp:218] Iteration 67600 (23.758 iter/s, 8.41822s/200 iters), loss = 0.458833
I1130 11:10:40.244472  4174 solver.cpp:237]     Train net output #0: loss = 0.458833 (* 1 = 0.458833 loss)
I1130 11:10:40.244477  4174 sgd_solver.cpp:105] Iteration 67600, lr = 1e-05
I1130 11:10:48.667815  4174 solver.cpp:218] Iteration 67800 (23.7434 iter/s, 8.4234s/200 iters), loss = 0.434708
I1130 11:10:48.667843  4174 solver.cpp:237]     Train net output #0: loss = 0.434708 (* 1 = 0.434708 loss)
I1130 11:10:48.667847  4174 sgd_solver.cpp:105] Iteration 67800, lr = 1e-05
I1130 11:10:56.886895  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:10:57.019366  4174 solver.cpp:330] Iteration 68000, Testing net (#0)
I1130 11:10:57.829740  4191 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:10:57.853117  4174 solver.cpp:397]     Test net output #0: accuracy = 0.7975
I1130 11:10:57.853160  4174 solver.cpp:397]     Test net output #1: loss = 0.581473 (* 1 = 0.581473 loss)
I1130 11:10:57.895951  4174 solver.cpp:218] Iteration 68000 (21.6728 iter/s, 9.22817s/200 iters), loss = 0.378162
I1130 11:10:57.896000  4174 solver.cpp:237]     Train net output #0: loss = 0.378162 (* 1 = 0.378162 loss)
I1130 11:10:57.896006  4174 sgd_solver.cpp:105] Iteration 68000, lr = 1e-05
I1130 11:11:06.340423  4174 solver.cpp:218] Iteration 68200 (23.6841 iter/s, 8.44448s/200 iters), loss = 0.447202
I1130 11:11:06.340466  4174 solver.cpp:237]     Train net output #0: loss = 0.447202 (* 1 = 0.447202 loss)
I1130 11:11:06.340471  4174 sgd_solver.cpp:105] Iteration 68200, lr = 1e-05
I1130 11:11:14.780771  4174 solver.cpp:218] Iteration 68400 (23.6957 iter/s, 8.44036s/200 iters), loss = 0.401528
I1130 11:11:14.780820  4174 solver.cpp:237]     Train net output #0: loss = 0.401528 (* 1 = 0.401528 loss)
I1130 11:11:14.780825  4174 sgd_solver.cpp:105] Iteration 68400, lr = 1e-05
I1130 11:11:18.789127  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:11:23.214049  4174 solver.cpp:218] Iteration 68600 (23.7155 iter/s, 8.43329s/200 iters), loss = 0.458565
I1130 11:11:23.214092  4174 solver.cpp:237]     Train net output #0: loss = 0.458565 (* 1 = 0.458565 loss)
I1130 11:11:23.214097  4174 sgd_solver.cpp:105] Iteration 68600, lr = 1e-05
I1130 11:11:31.638836  4174 solver.cpp:218] Iteration 68800 (23.7394 iter/s, 8.4248s/200 iters), loss = 0.434936
I1130 11:11:31.639022  4174 solver.cpp:237]     Train net output #0: loss = 0.434936 (* 1 = 0.434936 loss)
I1130 11:11:31.639029  4174 sgd_solver.cpp:105] Iteration 68800, lr = 1e-05
I1130 11:11:39.862015  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:11:39.995682  4174 solver.cpp:330] Iteration 69000, Testing net (#0)
I1130 11:11:40.805398  4191 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:11:40.828599  4174 solver.cpp:397]     Test net output #0: accuracy = 0.7972
I1130 11:11:40.828642  4174 solver.cpp:397]     Test net output #1: loss = 0.581347 (* 1 = 0.581347 loss)
I1130 11:11:40.871501  4174 solver.cpp:218] Iteration 69000 (21.6625 iter/s, 9.23254s/200 iters), loss = 0.37745
I1130 11:11:40.871552  4174 solver.cpp:237]     Train net output #0: loss = 0.37745 (* 1 = 0.37745 loss)
I1130 11:11:40.871558  4174 sgd_solver.cpp:105] Iteration 69000, lr = 1e-05
I1130 11:11:49.288879  4174 solver.cpp:218] Iteration 69200 (23.7604 iter/s, 8.41738s/200 iters), loss = 0.448057
I1130 11:11:49.288924  4174 solver.cpp:237]     Train net output #0: loss = 0.448057 (* 1 = 0.448057 loss)
I1130 11:11:49.288929  4174 sgd_solver.cpp:105] Iteration 69200, lr = 1e-05
I1130 11:11:57.705037  4174 solver.cpp:218] Iteration 69400 (23.7638 iter/s, 8.41617s/200 iters), loss = 0.40244
I1130 11:11:57.705080  4174 solver.cpp:237]     Train net output #0: loss = 0.40244 (* 1 = 0.40244 loss)
I1130 11:11:57.705085  4174 sgd_solver.cpp:105] Iteration 69400, lr = 1e-05
I1130 11:12:01.703366  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:12:06.119683  4174 solver.cpp:218] Iteration 69600 (23.768 iter/s, 8.41466s/200 iters), loss = 0.458493
I1130 11:12:06.119707  4174 solver.cpp:237]     Train net output #0: loss = 0.458493 (* 1 = 0.458493 loss)
I1130 11:12:06.119730  4174 sgd_solver.cpp:105] Iteration 69600, lr = 1e-05
I1130 11:12:14.526374  4174 solver.cpp:218] Iteration 69800 (23.7905 iter/s, 8.40672s/200 iters), loss = 0.435284
I1130 11:12:14.526418  4174 solver.cpp:237]     Train net output #0: loss = 0.435284 (* 1 = 0.435284 loss)
I1130 11:12:14.526423  4174 sgd_solver.cpp:105] Iteration 69800, lr = 1e-05
I1130 11:12:22.739223  4190 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:12:22.873318  4174 solver.cpp:447] Snapshotting to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_70000.caffemodel
I1130 11:12:22.908339  4174 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/david/caffe-master/cifar10/model/cifar10_full_iter_70000.solverstate
I1130 11:12:22.916918  4174 solver.cpp:310] Iteration 70000, loss = 0.376794
I1130 11:12:22.916932  4174 solver.cpp:330] Iteration 70000, Testing net (#0)
I1130 11:12:23.694898  4191 data_layer.cpp:73] Restarting data prefetching from start.
I1130 11:12:23.718160  4174 solver.cpp:397]     Test net output #0: accuracy = 0.7973
I1130 11:12:23.718207  4174 solver.cpp:397]     Test net output #1: loss = 0.581237 (* 1 = 0.581237 loss)
I1130 11:12:23.718211  4174 solver.cpp:315] Optimization Done.
I1130 11:12:23.718214  4174 caffe.cpp:259] Optimization Done.
